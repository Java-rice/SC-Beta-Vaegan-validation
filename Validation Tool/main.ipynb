{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from scipy.stats import skew, kurtosis\n",
    "from tensorflow.keras import layers, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing of files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ../test/sampleLabeled\\0_hw00001(2).svc\n",
      "Shape of data from file ../test/sampleLabeled\\0_hw00001(2).svc: (1774, 7)\n",
      "Processing file: ../test/sampleLabeled\\0_hw00001(3).svc\n",
      "Shape of data from file ../test/sampleLabeled\\0_hw00001(3).svc: (3444, 7)\n",
      "Processing file: ../test/sampleLabeled\\0_hw00002.svc\n",
      "Shape of data from file ../test/sampleLabeled\\0_hw00002.svc: (3800, 7)\n",
      "Processing file: ../test/sampleLabeled\\0_hw00003 (2).svc\n",
      "Shape of data from file ../test/sampleLabeled\\0_hw00003 (2).svc: (4276, 7)\n",
      "Processing file: ../test/sampleLabeled\\0_hw00003(2).svc\n",
      "Shape of data from file ../test/sampleLabeled\\0_hw00003(2).svc: (3959, 7)\n",
      "Processing file: ../test/sampleLabeled\\0_hw00003(3).svc\n",
      "Shape of data from file ../test/sampleLabeled\\0_hw00003(3).svc: (4401, 7)\n",
      "Processing file: ../test/sampleLabeled\\0_hw00003.svc\n",
      "Shape of data from file ../test/sampleLabeled\\0_hw00003.svc: (3102, 7)\n",
      "Processing file: ../test/sampleLabeled\\0_hw00004.svc\n",
      "Shape of data from file ../test/sampleLabeled\\0_hw00004.svc: (1111, 7)\n",
      "Processing file: ../test/sampleLabeled\\0_hw00005(2).svc\n",
      "Shape of data from file ../test/sampleLabeled\\0_hw00005(2).svc: (1852, 7)\n",
      "Processing file: ../test/sampleLabeled\\0_hw00005.svc\n",
      "Shape of data from file ../test/sampleLabeled\\0_hw00005.svc: (862, 7)\n",
      "Processing file: ../test/sampleLabeled\\0_hw00006.svc\n",
      "Shape of data from file ../test/sampleLabeled\\0_hw00006.svc: (2507, 7)\n",
      "Processing file: ../test/sampleLabeled\\1_hw00001 (2).svc\n",
      "Shape of data from file ../test/sampleLabeled\\1_hw00001 (2).svc: (1474, 7)\n",
      "Processing file: ../test/sampleLabeled\\1_hw00001 (3).svc\n",
      "Shape of data from file ../test/sampleLabeled\\1_hw00001 (3).svc: (2085, 7)\n",
      "Processing file: ../test/sampleLabeled\\1_hw00001.svc\n",
      "Shape of data from file ../test/sampleLabeled\\1_hw00001.svc: (2643, 7)\n",
      "Processing file: ../test/sampleLabeled\\1_hw00002(2).svc\n",
      "Shape of data from file ../test/sampleLabeled\\1_hw00002(2).svc: (5553, 7)\n",
      "Processing file: ../test/sampleLabeled\\1_hw00004(2).svc\n",
      "Shape of data from file ../test/sampleLabeled\\1_hw00004(2).svc: (3527, 7)\n",
      "Processing file: ../test/sampleLabeled\\1_hw00004(3).svc\n",
      "Shape of data from file ../test/sampleLabeled\\1_hw00004(3).svc: (2315, 7)\n",
      "Processing file: ../test/sampleLabeled\\1_hw00004.svc\n",
      "Shape of data from file ../test/sampleLabeled\\1_hw00004.svc: (1951, 7)\n",
      "Processing file: ../test/sampleLabeled\\1_hw00006(2).svc\n",
      "Shape of data from file ../test/sampleLabeled\\1_hw00006(2).svc: (4588, 7)\n",
      "Processing file: ../test/sampleLabeled\\1_hw00006.svc\n",
      "Shape of data from file ../test/sampleLabeled\\1_hw00006.svc: (3178, 7)\n",
      "Processing file: ../test/sampleLabeled\\2_hw00001(2).svc\n",
      "Shape of data from file ../test/sampleLabeled\\2_hw00001(2).svc: (2086, 7)\n",
      "Processing file: ../test/sampleLabeled\\2_hw00002(2).svc\n",
      "Shape of data from file ../test/sampleLabeled\\2_hw00002(2).svc: (3221, 7)\n",
      "Processing file: ../test/sampleLabeled\\2_hw00002.svc\n",
      "Shape of data from file ../test/sampleLabeled\\2_hw00002.svc: (2735, 7)\n",
      "Processing file: ../test/sampleLabeled\\2_hw00005(2).svc\n",
      "Shape of data from file ../test/sampleLabeled\\2_hw00005(2).svc: (1531, 7)\n",
      "Processing file: ../test/sampleLabeled\\2_hw00005.svc\n",
      "Shape of data from file ../test/sampleLabeled\\2_hw00005.svc: (1208, 7)\n",
      "Processing file: ../test/sampleLabeled\\2_hw00006(2).svc\n",
      "Shape of data from file ../test/sampleLabeled\\2_hw00006(2).svc: (4094, 7)\n",
      "Processing file: ../test/sampleLabeled\\2_hw00007 (2).svc\n",
      "Shape of data from file ../test/sampleLabeled\\2_hw00007 (2).svc: (2985, 7)\n",
      "Processing file: ../test/sampleLabeled\\2_hw00007(2).svc\n",
      "Shape of data from file ../test/sampleLabeled\\2_hw00007(2).svc: (3457, 7)\n",
      "Processing file: ../test/sampleLabeled\\2_hw00007(3).svc\n",
      "Shape of data from file ../test/sampleLabeled\\2_hw00007(3).svc: (3482, 7)\n",
      "Processing file: ../test/sampleLabeled\\2_hw00007.svc\n",
      "Shape of data from file ../test/sampleLabeled\\2_hw00007.svc: (3154, 7)\n",
      "Shapes of all_data before concatenation:\n",
      "Data array 0 shape: (1774, 7)\n",
      "Data array 1 shape: (3444, 7)\n",
      "Data array 2 shape: (3800, 7)\n",
      "Data array 3 shape: (4276, 7)\n",
      "Data array 4 shape: (3959, 7)\n",
      "Data array 5 shape: (4401, 7)\n",
      "Data array 6 shape: (3102, 7)\n",
      "Data array 7 shape: (1111, 7)\n",
      "Data array 8 shape: (1852, 7)\n",
      "Data array 9 shape: (862, 7)\n",
      "Data array 10 shape: (2507, 7)\n",
      "Data array 11 shape: (1474, 7)\n",
      "Data array 12 shape: (2085, 7)\n",
      "Data array 13 shape: (2643, 7)\n",
      "Data array 14 shape: (5553, 7)\n",
      "Data array 15 shape: (3527, 7)\n",
      "Data array 16 shape: (2315, 7)\n",
      "Data array 17 shape: (1951, 7)\n",
      "Data array 18 shape: (4588, 7)\n",
      "Data array 19 shape: (3178, 7)\n",
      "Data array 20 shape: (2086, 7)\n",
      "Data array 21 shape: (3221, 7)\n",
      "Data array 22 shape: (2735, 7)\n",
      "Data array 23 shape: (1531, 7)\n",
      "Data array 24 shape: (1208, 7)\n",
      "Data array 25 shape: (4094, 7)\n",
      "Data array 26 shape: (2985, 7)\n",
      "Data array 27 shape: (3457, 7)\n",
      "Data array 28 shape: (3482, 7)\n",
      "Data array 29 shape: (3154, 7)\n"
     ]
    }
   ],
   "source": [
    "def load_emothaw_data(directory_path):\n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Use glob to find all .svc files in the specified directory\n",
    "    file_paths = glob.glob(os.path.join(directory_path, \"*.svc\"))\n",
    "    if not file_paths:\n",
    "        # Raise an error if no files are found\n",
    "        raise ValueError(\"No files found in the specified directory\")\n",
    "\n",
    "    # Iterate over each file path found\n",
    "    for file_path in file_paths:\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        try:\n",
    "            # Extract the label from the filename\n",
    "            # Assuming the label is the part before the first underscore '_'\n",
    "            label = int(os.path.basename(file_path).split('_')[0])\n",
    "\n",
    "            # Load the file and strip trailing spaces\n",
    "            with open(file_path, 'r') as f:\n",
    "                lines = [line.strip() for line in f.readlines() if line.strip()]  # Ignore empty lines\n",
    "\n",
    "            # Convert the lines into a DataFrame by splitting each line by whitespace\n",
    "            df = pd.DataFrame([line.split() for line in lines])  # Split by whitespace\n",
    "\n",
    "            # Skip empty files\n",
    "            if df.empty:\n",
    "                print(f\"Warning: {file_path} is empty after processing. Skipping file.\")\n",
    "                continue\n",
    "\n",
    "            # First row contains the total number of data rows (excluding the first row)\n",
    "            total_rows = int(df.iloc[0, 0])  # Number of expected sequences\n",
    "\n",
    "            # Extract the feature data from the subsequent rows\n",
    "            data = df.iloc[1:, :].values  # All columns are treated as features\n",
    "\n",
    "            # Check if enough data rows exist as per the first row's instruction\n",
    "            if data.shape[0] < total_rows:\n",
    "                raise ValueError(f\"Insufficient data: expected {total_rows}, but found {data.shape[0]}\")\n",
    "\n",
    "            # Ensure each row has exactly 7 feature values\n",
    "            reshaped_data = []\n",
    "            for row in data:\n",
    "                if len(row) == 7:\n",
    "                    reshaped_data.append(row)\n",
    "                else:\n",
    "                    print(f\"Warning: Row does not have 7 values, skipping: {row}\")\n",
    "\n",
    "            # If valid reshaped data exists, convert it into a NumPy array\n",
    "            if reshaped_data:\n",
    "                reshaped_data = np.array(reshaped_data, dtype=float)  # Convert to float type\n",
    "\n",
    "                # Check that reshaped data has enough rows as expected\n",
    "                if reshaped_data.shape[0] < total_rows:\n",
    "                    raise ValueError(f\"Insufficient data: expected {total_rows}, but found {reshaped_data.shape[0]}\")\n",
    "\n",
    "                # Append the reshaped data and labels\n",
    "                all_data.append(reshaped_data)\n",
    "                all_labels.append([label] * reshaped_data.shape[0])  # Append the label for each data row\n",
    "\n",
    "                # Print the shape of reshaped data for debugging\n",
    "                print(f\"Shape of data from file {file_path}: {reshaped_data.shape}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # If any error occurs, display the error and continue processing the next file\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Raise an error if no valid data was processed\n",
    "    if not all_data or not all_labels:\n",
    "        raise ValueError(\"No valid data found in the directory\")\n",
    "\n",
    "    # Print the shapes of individual data entries for debugging\n",
    "    print(\"Shapes of all_data before concatenation:\")\n",
    "    for i, data_array in enumerate(all_data):\n",
    "        print(f\"Data array {i} shape: {data_array.shape}\")\n",
    "\n",
    "    # Concatenate all data arrays along the sample axis (rows)\n",
    "    try:\n",
    "        all_data = np.concatenate(all_data, axis=0)  # Concatenate data arrays\n",
    "    except Exception as e:\n",
    "        print(f\"Error during concatenation: {e}\")\n",
    "\n",
    "    # Concatenate labels\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    # Return the processed data and corresponding labels\n",
    "    return all_data, all_labels\n",
    "\n",
    "# Importing all files on the Directory\n",
    "data, labels = load_emothaw_data(r'../test/sampleLabeled/')  # Directory path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-15 16:32:23,882 - Starting time-domain feature extraction\n",
      "Extracting features: 100%|██████████| 86355/86355 [05:31<00:00, 260.63sample/s]\n",
      "2024-10-15 16:37:55,258 - Feature extraction completed in 0:05:31.374800\n"
     ]
    }
   ],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Function to extract time-domain features with progress bar and logging\n",
    "def extract_time_domain_features(data):\n",
    "    logger.info(\"Starting time-domain feature extraction\")\n",
    "    start_time = datetime.now()\n",
    "\n",
    "    time_features = []\n",
    "    \n",
    "    # Use tqdm to create a progress bar\n",
    "    for sample in tqdm(data, desc=\"Extracting features\", unit=\"sample\"):\n",
    "        sample_features = []\n",
    "        for feature in sample.T:  # Assuming the features are along the last axis\n",
    "            feature_stats = [\n",
    "                np.mean(feature),\n",
    "                np.std(feature),\n",
    "                np.min(feature),\n",
    "                np.max(feature),\n",
    "                np.percentile(feature, 25),\n",
    "                np.percentile(feature, 50),\n",
    "                np.percentile(feature, 75),\n",
    "            ]\n",
    "            sample_features.extend(feature_stats)  # Append the computed stats to sample_features\n",
    "        time_features.append(sample_features)  # Append the features for the sample\n",
    "\n",
    "    end_time = datetime.now()\n",
    "    elapsed_time = end_time - start_time\n",
    "    logger.info(f\"Feature extraction completed in {elapsed_time}\")\n",
    "\n",
    "    return np.array(time_features)\n",
    "\n",
    "# Assuming 'data' is your input 3D array (samples, sequence length, features)\n",
    "time_domain_features = extract_time_domain_features(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-15 16:37:55,703 - Starting frequency-domain feature extraction\n",
      "Extracting frequency features: 100%|██████████| 86355/86355 [00:01<00:00, 44616.77sample/s]\n",
      "2024-10-15 16:37:57,642 - Frequency-domain feature extraction completed in 0:00:01.937481\n",
      "2024-10-15 16:37:57,698 - Data: [[5.142800e+04 3.443100e+04 7.354731e+06 ... 1.850000e+03 6.000000e+02\n",
      "  1.270000e+02]\n",
      " [5.142800e+04 3.443100e+04 7.354738e+06 ... 1.850000e+03 6.000000e+02\n",
      "  2.210000e+02]\n",
      " [5.142800e+04 3.443100e+04 7.354746e+06 ... 1.850000e+03 6.000000e+02\n",
      "  2.680000e+02]\n",
      " ...\n",
      " [8.880000e+03 2.852000e+03 1.662474e+06 ... 2.550000e+03 7.500000e+02\n",
      "  1.023000e+03]\n",
      " [8.903000e+03 2.838000e+03 1.662482e+06 ... 2.550000e+03 7.500000e+02\n",
      "  9.210000e+02]\n",
      " [8.939000e+03 2.829000e+03 1.662489e+06 ... 2.560000e+03 7.400000e+02\n",
      "  1.180000e+02]]\n",
      "2024-10-15 16:37:57,699 - Frequency Domain Features: [[       0.         51483983.15708157]\n",
      " [       0.         51484032.14330792]\n",
      " [       0.         51484088.13747965]\n",
      " ...\n",
      " [       0.         11637368.85713124]\n",
      " [       0.         11637425.02835286]\n",
      " [       0.         11637474.66732682]]\n"
     ]
    }
   ],
   "source": [
    "# Extracting frequency domain features using FFT with progress bar and logging\n",
    "def extract_frequency_domain_features(data):\n",
    "    logger.info(\"Starting frequency-domain feature extraction\")\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    freq_features = []\n",
    "    \n",
    "    # Ensure the data has the correct dimensions\n",
    "    if len(data.shape) != 2:\n",
    "        raise ValueError(f\"Expected data with 2 dimensions (samples, features), but got {data.shape}\")\n",
    "    \n",
    "    # Use tqdm to create a progress bar\n",
    "    for sample in tqdm(data, desc=\"Extracting frequency features\", unit=\"sample\"):\n",
    "        sample_features = []\n",
    "        \n",
    "        # Check if the sample is a 1D array\n",
    "        if len(sample.shape) != 1:\n",
    "            raise ValueError(f\"Expected each sample to be 1D, but got {sample.shape}\")\n",
    "\n",
    "        # Apply FFT to the sample (which is already 1D, hence no need for .T)\n",
    "        freq_feature = np.fft.fft(sample)\n",
    "        freq_magnitude = np.abs(freq_feature)\n",
    "        dominant_freq = np.argmax(freq_magnitude)\n",
    "        freq_energy = np.sum(freq_magnitude)\n",
    "        \n",
    "        sample_features.extend([dominant_freq, freq_energy])\n",
    "        freq_features.append(sample_features)\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    elapsed_time = end_time - start_time\n",
    "    logger.info(f\"Frequency-domain feature extraction completed in {elapsed_time}\")\n",
    "\n",
    "    return np.array(freq_features)\n",
    "\n",
    "# Example usage: Assuming `data` is a 2D array (samples, features)\n",
    "# data = np.random.rand(100, 50)  # Example data\n",
    "frequency_domain_features = extract_frequency_domain_features(data)\n",
    "\n",
    "# Log the output\n",
    "logger.info(f\"Data: {data}\")\n",
    "logger.info(f\"Frequency Domain Features: {frequency_domain_features}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-15 16:37:57,765 - Starting statistical feature extraction\n",
      "Extracting statistical features: 100%|██████████| 86355/86355 [03:05<00:00, 466.77sample/s]\n",
      "2024-10-15 16:41:02,777 - Statistical feature extraction completed in 0:03:05.010685\n",
      "2024-10-15 16:41:03,049 - Data: [[5.142800e+04 3.443100e+04 7.354731e+06 ... 1.850000e+03 6.000000e+02\n",
      "  1.270000e+02]\n",
      " [5.142800e+04 3.443100e+04 7.354738e+06 ... 1.850000e+03 6.000000e+02\n",
      "  2.210000e+02]\n",
      " [5.142800e+04 3.443100e+04 7.354746e+06 ... 1.850000e+03 6.000000e+02\n",
      "  2.680000e+02]\n",
      " ...\n",
      " [8.880000e+03 2.852000e+03 1.662474e+06 ... 2.550000e+03 7.500000e+02\n",
      "  1.023000e+03]\n",
      " [8.903000e+03 2.838000e+03 1.662482e+06 ... 2.550000e+03 7.500000e+02\n",
      "  9.210000e+02]\n",
      " [8.939000e+03 2.829000e+03 1.662489e+06 ... 2.560000e+03 7.400000e+02\n",
      "  1.180000e+02]]\n",
      "2024-10-15 16:41:03,060 - Statistical Features: [[5.14280000e+04 5.14280000e+04 0.00000000e+00 ... 0.00000000e+00\n",
      "  2.04100695e+00 2.16615462e+00]\n",
      " [5.14280000e+04 5.14280000e+04 0.00000000e+00 ... 0.00000000e+00\n",
      "  2.04100720e+00 2.16615517e+00]\n",
      " [5.14280000e+04 5.14280000e+04 0.00000000e+00 ... 0.00000000e+00\n",
      "  2.04100733e+00 2.16615545e+00]\n",
      " ...\n",
      " [8.88000000e+03 8.88000000e+03 0.00000000e+00 ... 0.00000000e+00\n",
      "  2.04114697e+00 2.16646037e+00]\n",
      " [8.90300000e+03 8.90300000e+03 0.00000000e+00 ... 0.00000000e+00\n",
      "  2.04114583e+00 2.16645789e+00]\n",
      " [8.93900000e+03 8.93900000e+03 0.00000000e+00 ... 0.00000000e+00\n",
      "  2.04113892e+00 2.16644280e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# Function to extract statistical features with progress bar and logging\n",
    "def extract_statistical_features(data):\n",
    "    logger.info(\"Starting statistical feature extraction\")\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    statistical_features = []\n",
    "    \n",
    "    for sample in tqdm(data, desc=\"Extracting statistical features\", unit=\"sample\"):\n",
    "        sample_features = []\n",
    "        skew_value = skew(sample.T)\n",
    "        kurtosis_value = kurtosis(sample.T)\n",
    "        for feature in sample.T:\n",
    "            mean = np.mean(feature)\n",
    "            median = np.median(feature)\n",
    "            variance = np.var(feature)\n",
    "            feature_stats = [mean, median, variance, skew_value, kurtosis_value]\n",
    "            sample_features.extend(feature_stats)\n",
    "        statistical_features.append(sample_features)\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    elapsed_time = end_time - start_time\n",
    "    logger.info(f\"Statistical feature extraction completed in {elapsed_time}\")\n",
    "    \n",
    "    return np.array(statistical_features)\n",
    "\n",
    "# Example usage: Assuming 'data' is a 3D array (samples, sequence length, features)\n",
    "statistical_features = extract_statistical_features(data)\n",
    "\n",
    "# Log the output\n",
    "logger.info(f\"Data: {data}\")\n",
    "logger.info(f\"Statistical Features: {statistical_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MultiHeadSelf Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim  # Total embedding dimension\n",
    "        self.num_heads = num_heads  # Number of attention heads\n",
    "        \n",
    "        # Ensure that the embedding dimension is divisible by the number of heads\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\")\n",
    "        \n",
    "        # Calculate the dimension per head\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "        \n",
    "        # Dense layers for query, key, and value projections\n",
    "        self.query_dense = layers.Dense(embed_dim)\n",
    "        self.key_dense = layers.Dense(embed_dim)\n",
    "        self.value_dense = layers.Dense(embed_dim)\n",
    "        \n",
    "        # Dense layer to combine the heads' outputs\n",
    "        self.combine_heads = layers.Dense(embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        # Calculate the attention scores\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        \n",
    "        # Scale the scores by the square root of the key dimension\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        \n",
    "        # Apply softmax to get the attention weights\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        \n",
    "        # Compute the output as a weighted sum of the values\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        # Reshape the input tensor to separate the heads\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])  # Transpose for compatibility with attention computation\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]  # Get the batch size\n",
    "        \n",
    "        # Apply dense layers to inputs to create query, key, and value tensors\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "        \n",
    "        # Separate the heads for query, key, and value tensors\n",
    "        query = self.separate_heads(query, batch_size)\n",
    "        key = self.separate_heads(key, batch_size)\n",
    "        value = self.separate_heads(value, batch_size)\n",
    "        \n",
    "        # Calculate the attention output and weights\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        \n",
    "        # Transpose the attention output back to the original shape\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "        \n",
    "        # Combine the heads' outputs\n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim))\n",
    "        output = self.combine_heads(concat_attention)  # Final dense layer to project the output\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        \n",
    "        # Initialize the multi-head self-attention layer\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        \n",
    "        # Feedforward network: A sequential model with a ReLU activation function\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim)]\n",
    "        )\n",
    "        \n",
    "        # Layer normalization for residual connections\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        # Dropout layers for regularization\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        # Apply multi-head self-attention to the input\n",
    "        attn_output = self.att(inputs)\n",
    "        \n",
    "        # Apply dropout to the attention output (only during training)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        \n",
    "        # Add the original input (residual connection) to the attention output and apply layer normalization\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        \n",
    "        # Pass through the feedforward network\n",
    "        ffn_output = self.ffn(out1)\n",
    "        \n",
    "        # Apply dropout to the feedforward output (only during training)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        \n",
    "        # Add the output from the feedforward network to the previous output (residual connection) and apply layer normalization\n",
    "        return self.layernorm2(out1 + ffn_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1728/1728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m112s\u001b[0m 34ms/step - accuracy: 0.4069 - loss: 1.1061 - val_accuracy: 0.4880 - val_loss: 0.9949\n",
      "Epoch 2/10\n",
      "\u001b[1m1728/1728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 34ms/step - accuracy: 0.5392 - loss: 0.9284 - val_accuracy: 0.6873 - val_loss: 0.6426\n",
      "Epoch 3/10\n",
      "\u001b[1m1728/1728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 35ms/step - accuracy: 0.7294 - loss: 0.5812 - val_accuracy: 0.8380 - val_loss: 0.3195\n",
      "Epoch 4/10\n",
      "\u001b[1m1728/1728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 38ms/step - accuracy: 0.8371 - loss: 0.3803 - val_accuracy: 0.9501 - val_loss: 0.1557\n",
      "Epoch 5/10\n",
      "\u001b[1m1728/1728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 35ms/step - accuracy: 0.8799 - loss: 0.2905 - val_accuracy: 0.9600 - val_loss: 0.1502\n",
      "Epoch 6/10\n",
      "\u001b[1m1728/1728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 38ms/step - accuracy: 0.8974 - loss: 0.2553 - val_accuracy: 0.8707 - val_loss: 0.2942\n",
      "Epoch 7/10\n",
      "\u001b[1m1728/1728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 36ms/step - accuracy: 0.8824 - loss: 0.2820 - val_accuracy: 0.8396 - val_loss: 0.2968\n",
      "Epoch 8/10\n",
      "\u001b[1m1728/1728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 36ms/step - accuracy: 0.8941 - loss: 0.2581 - val_accuracy: 0.9617 - val_loss: 0.1132\n",
      "Epoch 9/10\n",
      "\u001b[1m1728/1728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 46ms/step - accuracy: 0.8943 - loss: 0.2555 - val_accuracy: 0.8414 - val_loss: 0.3872\n",
      "Epoch 10/10\n",
      "\u001b[1m1728/1728\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 49ms/step - accuracy: 0.9009 - loss: 0.2371 - val_accuracy: 0.9437 - val_loss: 0.1278\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.9433 - loss: 0.1317\n",
      "Test Loss: 0.13351444900035858, Test Accuracy: 0.9417520761489868\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "class TransformerClassifier(Model):\n",
    "    def __init__(self, num_classes, embed_dim, num_heads, ff_dim, num_layers):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "        \n",
    "        # Dense layer to project input features into the embedding dimension\n",
    "        self.dense_input = layers.Dense(embed_dim)\n",
    "        \n",
    "        # Create multiple transformer blocks as specified by num_layers\n",
    "        self.transformer_blocks = [\n",
    "            TransformerBlock(embed_dim, num_heads, ff_dim) for _ in range(num_layers)\n",
    "        ]\n",
    "        \n",
    "        # Global average pooling layer to reduce dimensionality before classification\n",
    "        self.global_average_pooling = layers.GlobalAveragePooling1D()\n",
    "        \n",
    "        # Final dense layer for classification with softmax activation\n",
    "        self.dense = layers.Dense(num_classes, activation='softmax')\n",
    "\n",
    "    def call(self, inputs, training=False):  # Include training parameter\n",
    "        # Project inputs to the embedding dimension\n",
    "        x = self.dense_input(inputs)\n",
    "        \n",
    "        # Pass the projected inputs through each transformer block\n",
    "        for transformer in self.transformer_blocks:\n",
    "            x = transformer(x, training=training)  # Forward the training parameter to transformer blocks\n",
    "            \n",
    "        # Apply global average pooling to reduce dimensionality\n",
    "        x = self.global_average_pooling(x)\n",
    "        \n",
    "        # Pass the pooled output through the final dense layer\n",
    "        return self.dense(x)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "features = np.concatenate((time_domain_features, frequency_domain_features, statistical_features), axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Defining the model parameters\n",
    "num_classes = 3  # Number of output classes for classification\n",
    "embed_dim = 128  # Embedding dimension for the transformer\n",
    "num_heads = 4    # Number of attention heads in each transformer block\n",
    "ff_dim = 128     # Dimension of the feedforward network\n",
    "num_layers = 2   # Number of transformer blocks in the model\n",
    "\n",
    "# Creating the Transformer model\n",
    "model = TransformerClassifier(num_classes, embed_dim, num_heads, ff_dim, num_layers)\n",
    "\n",
    "# Compiling the model with Adam optimizer and sparse categorical crossentropy loss\n",
    "model.compile(optimizer=Adam(clipnorm=1.0), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training the model on the training data\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluating the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REQUIRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m257s\u001b[0m 29ms/step - accuracy: 0.4229 - loss: 1.0720 - val_accuracy: 0.5674 - val_loss: 0.9246\n",
      "Epoch 2/5\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 32ms/step - accuracy: 0.5737 - loss: 0.8743 - val_accuracy: 0.7307 - val_loss: 0.5667\n",
      "Epoch 3/5\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 33ms/step - accuracy: 0.6852 - loss: 0.6505 - val_accuracy: 0.7702 - val_loss: 0.4999\n",
      "Epoch 4/5\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 38ms/step - accuracy: 0.7288 - loss: 0.5664 - val_accuracy: 0.8133 - val_loss: 0.3915\n",
      "Epoch 5/5\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 35ms/step - accuracy: 0.8336 - loss: 0.3732 - val_accuracy: 0.9074 - val_loss: 0.2669\n",
      "\u001b[1m540/540\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9080 - loss: 0.2669\n",
      "Test Accuracy: 90.74\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# Use the train_test_split function from scikit-learn to create training and testing datasets\n",
    "# Adjust the test_size parameter to control the proportion of data in the test set\n",
    "# In this case, it is set to 1, which means the entire dataset will be used for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define model parameters for the transformer classifier\n",
    "num_blocks = 3       # Number of transformer blocks to be used in the model\n",
    "embed_dim = 64       # Dimension of the embedding space\n",
    "num_heads = 4        # Number of attention heads in each transformer block\n",
    "ff_dim = 128         # Dimension of the feedforward network within each transformer block\n",
    "learning_rate = 0.001 # Learning rate for the optimizer\n",
    "\n",
    "# Instantiate the TransformerClassifier model with the defined parameters\n",
    "transformer_model = TransformerClassifier(num_classes, embed_dim, num_heads, ff_dim, num_blocks)\n",
    "\n",
    "# Compile the model with the Adam optimizer and the specified loss function\n",
    "# Metrics set to 'accuracy' to evaluate the performance during training\n",
    "transformer_model.compile(optimizer=Adam(learning_rate), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Set training parameters\n",
    "epochs = 5           # Number of epochs to train the model\n",
    "batch_size = 32      # Number of samples per gradient update\n",
    "\n",
    "# Train the model on the training data\n",
    "# The validation_data parameter is set to evaluate the model on the test set during training\n",
    "transformer_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "# This will return the loss and accuracy of the model on the unseen test data\n",
    "loss, accuracy = transformer_model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the test accuracy as a percentage\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just test code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the directory and model path for saving the trained model\n",
    "directory = './newmodels/'\n",
    "model_path = os.path.join(directory, 'testmodel.model.keras')\n",
    "\n",
    "# Create the directory if it doesn't exist to ensure the model can be saved\n",
    "os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Define the number of classes for the classification task\n",
    "# Adjust this according to your dataset (for example, emotions)\n",
    "num_classes = 3  # Example number of classes\n",
    "\n",
    "# Create a sequential model for LSTM\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Reshape the training data to add a time steps dimension\n",
    "# Assuming X_train originally has shape (num_samples, features)\n",
    "new_train = X_train.reshape((X_train.shape[0], 1, 7))  # Add a timesteps dimension\n",
    "\n",
    "# Add LSTM layers to the model\n",
    "model.add(LSTM(128, input_shape=(None, 7), return_sequences=True))  # First LSTM layer\n",
    "model.add(LSTM(128))  # Second LSTM layer (returns only the last output)\n",
    "\n",
    "# Add a dense layer for feature extraction\n",
    "model.add(Dense(64, activation='relu'))  # Fully connected layer with ReLU activation\n",
    "\n",
    "# Add the final dense layer for classification with softmax activation\n",
    "model.add(Dense(num_classes, activation='softmax'))  # Output layer for class probabilities\n",
    "\n",
    "# Compile the model with the Adam optimizer and specify the loss function and metrics\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model using the training data\n",
    "# Ensure that X_train has the appropriate shape: (batch_size, timesteps, features)\n",
    "model.fit(new_train, y_train, epochs=10)  # Train for 10 epochs\n",
    "\n",
    "# Save the trained model to the specified path\n",
    "model.save(model_path)\n",
    "\n",
    "# Optionally, recompile the model (not necessary right after training)\n",
    "# This step can be useful if you want to change the optimizer or loss function later\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REQUIRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.3532 - loss: 55225.8125\n",
      "Epoch 2/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.3664 - loss: 15547.7441\n",
      "Epoch 3/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.4489 - loss: 4983.7852\n",
      "Epoch 4/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5351 - loss: 2332.7700\n",
      "Epoch 5/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6039 - loss: 1174.6277\n",
      "Epoch 6/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6151 - loss: 809.9397\n",
      "Epoch 7/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.6599 - loss: 246.2161\n",
      "Epoch 8/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5172 - loss: 0.8354\n",
      "Epoch 9/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.5837 - loss: 0.7581\n",
      "Epoch 10/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.5170 - loss: 2.0932\n",
      "Epoch 11/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.4441 - loss: 0.9714\n",
      "Epoch 12/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.4219 - loss: 1.0194\n",
      "Epoch 13/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.3652 - loss: 1.0964\n",
      "Epoch 14/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.3594 - loss: 1.0971\n",
      "Epoch 15/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.3614 - loss: 1.0969\n",
      "Epoch 16/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.3601 - loss: 1.0971\n",
      "Epoch 17/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.3602 - loss: 1.0971\n",
      "Epoch 18/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.3591 - loss: 1.0972\n",
      "Epoch 19/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.3621 - loss: 1.0968\n",
      "Epoch 20/20\n",
      "\u001b[1m2159/2159\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - accuracy: 0.3625 - loss: 1.0968\n"
     ]
    }
   ],
   "source": [
    "# Update Sequential model to fit the 7-feature data\n",
    "directory = './newmodels/'\n",
    "model_path = os.path.join(directory, 'new_model.model.keras')\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Flatten(input_shape=(7,)))  # Input shape updated to (7,)\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))  # Adjusting num_classes\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with your training data\n",
    "model.fit(X_train, y_train, epochs=20)\n",
    "\n",
    "# Save the model\n",
    "model.save(model_path)\n",
    "\n",
    "# Recompile the model for further use if needed\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File not found: filepath=./newmodels.model.keras. Please ensure the file is an accessible `.keras` zip file.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[247], line 49\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Load the custom model for prediction\u001b[39;00m\n\u001b[0;32m     48\u001b[0m custom_objects \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransformerClassifier\u001b[39m\u001b[38;5;124m'\u001b[39m: TransformerClassifier}  \u001b[38;5;66;03m# Adjust as necessary\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./newmodels.model.keras\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(data)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Load and preprocess the .svc file\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\JM\\Desktop\\Validation Tool\\venv\\Lib\\site-packages\\keras\\src\\saving\\saving_api.py:200\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(\n\u001b[0;32m    197\u001b[0m         filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m\n\u001b[0;32m    198\u001b[0m     )\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    204\u001b[0m     )\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    207\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile format not supported: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKeras 3 only supports V3 `.keras` files and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmight have a different name).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    218\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: File not found: filepath=./newmodels.model.keras. Please ensure the file is an accessible `.keras` zip file."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Function to load and preprocess a single .svc file for prediction\n",
    "def load_single_svc_file(file_path, expected_features=7):\n",
    "    try:\n",
    "        # Open the .svc file and read its lines\n",
    "        with open(file_path, 'r') as f:\n",
    "            # Strip whitespace and filter out empty lines\n",
    "            lines = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "        # Create a DataFrame from the lines\n",
    "        df = pd.DataFrame([line.split() for line in lines])\n",
    "\n",
    "        # Raise an error if the DataFrame is empty after processing\n",
    "        if df.empty:\n",
    "            raise ValueError(f\"{file_path} is empty after processing.\")\n",
    "\n",
    "        # Extract data from the DataFrame, ignoring the first row (header)\n",
    "        data = df.iloc[1:, :].values\n",
    "        data = np.array(data, dtype=float)\n",
    "\n",
    "        # Debugging print to show the initial data loaded\n",
    "        print(f\"Initial data loaded from {file_path}:\\n{data}\")\n",
    "\n",
    "        # Ensure the data has the correct number of features\n",
    "        if data.shape[1] > expected_features:\n",
    "            data = data[:, :expected_features]  # Truncate to expected_features\n",
    "            print(f\"Truncated data to {expected_features} features:\\n{data}\")\n",
    "        elif data.shape[1] < expected_features:\n",
    "            # Pad with zeros if there are too few features\n",
    "            padding = np.zeros((data.shape[0], expected_features - data.shape[1]))\n",
    "            data = np.hstack((data, padding))\n",
    "            print(f\"Padded data to {expected_features} features:\\n{data}\")\n",
    "\n",
    "        return data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Path to the .svc file for prediction\n",
    "file_path = '../test/sampleLabeled/1_hw00002(2).svc'\n",
    "\n",
    "# Load the custom model for prediction\n",
    "custom_objects = {'TransformerClassifier': TransformerClassifier}  # Adjust as necessary\n",
    "model = tf.keras.models.load_model('./newmodels/2Emotion-detectiontest.model.keras')\n",
    "\n",
    "# Load and preprocess the .svc file\n",
    "data = load_single_svc_file(file_path)\n",
    "\n",
    "if data is not None:\n",
    "    expected_features = 7  # The number of features your model expects\n",
    "\n",
    "    # Debugging prints for data shapes\n",
    "    print(f\"Original data shape: {data.shape}\")\n",
    "    total_elements = data.size\n",
    "    print(f\"Total elements in data: {total_elements}\")\n",
    "\n",
    "    # Calculate complete samples\n",
    "    complete_samples = total_elements // expected_features\n",
    "    print(f\"Complete samples possible: {complete_samples}\")\n",
    "\n",
    "    # Adjust data to match complete samples\n",
    "    data = data[:complete_samples * expected_features]\n",
    "    print(f\"Adjusted data shape for reshaping: {data.shape}\")\n",
    "\n",
    "    # Ensure that the data can be reshaped correctly\n",
    "    if data.size % expected_features != 0:\n",
    "        raise ValueError(\"The data cannot be reshaped into the required shape.\")\n",
    "\n",
    "    # Reshape the data\n",
    "    data = data.reshape((complete_samples, expected_features))\n",
    "    print(f\"Reshaped data shape: {data.shape}\")\n",
    "\n",
    "    # Add timesteps dimension\n",
    "    data = np.expand_dims(data, axis=1)  # New shape: (samples, timesteps, features)\n",
    "    print(f\"Data shape after adding timesteps dimension: {data.shape}\")\n",
    "\n",
    "    # Predict the class probabilities\n",
    "    predictions = model.predict(data)\n",
    "    print(f\"Predictions shape: {predictions.shape}\")\n",
    "    print(f\"Predictions: {predictions}\")\n",
    "\n",
    "    # Get the predicted class\n",
    "    predicted_class = np.argmax(predictions, axis=1)\n",
    "    print(f\"Predicted class indices: {predicted_class}\")\n",
    "\n",
    "    # Output the predicted class with emotion labels\n",
    "    class_labels = ['Depression', 'Anxiety', 'Stress']  # Adjust as necessary\n",
    "    print(f\"Predicted emotion: {class_labels[predicted_class[0]]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model summary:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in predictions:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
