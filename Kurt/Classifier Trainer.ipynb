{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import logging\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from scipy.stats import skew, kurtosis\n",
    "from tensorflow.keras import layers, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import joblib\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing of files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: ../test/test_data\\0_u00003s00001hw00001.svc\n",
      "Shape of data from file ../test/test_data\\0_u00003s00001hw00001.svc: (2643, 7)\n",
      "Processing file: ../test/test_data\\0_u00003s00001hw00002.svc\n",
      "Shape of data from file ../test/test_data\\0_u00003s00001hw00002.svc: (5691, 7)\n",
      "Processing file: ../test/test_data\\0_u00003s00001hw00003.svc\n",
      "Shape of data from file ../test/test_data\\0_u00003s00001hw00003.svc: (3863, 7)\n",
      "Processing file: ../test/test_data\\0_u00003s00001hw00004.svc\n",
      "Shape of data from file ../test/test_data\\0_u00003s00001hw00004.svc: (1178, 7)\n",
      "Processing file: ../test/test_data\\0_u00003s00001hw00005.svc\n",
      "Shape of data from file ../test/test_data\\0_u00003s00001hw00005.svc: (770, 7)\n",
      "Processing file: ../test/test_data\\0_u00003s00001hw00006.svc\n",
      "Shape of data from file ../test/test_data\\0_u00003s00001hw00006.svc: (4051, 7)\n",
      "Processing file: ../test/test_data\\0_u00003s00001hw00007.svc\n",
      "Shape of data from file ../test/test_data\\0_u00003s00001hw00007.svc: (3050, 7)\n",
      "Processing file: ../test/test_data\\0_u00013s00001hw00001.svc\n",
      "Shape of data from file ../test/test_data\\0_u00013s00001hw00001.svc: (1782, 7)\n",
      "Processing file: ../test/test_data\\0_u00013s00001hw00002.svc\n",
      "Shape of data from file ../test/test_data\\0_u00013s00001hw00002.svc: (3817, 7)\n",
      "Processing file: ../test/test_data\\0_u00013s00001hw00003.svc\n",
      "Shape of data from file ../test/test_data\\0_u00013s00001hw00003.svc: (3831, 7)\n",
      "Processing file: ../test/test_data\\0_u00013s00001hw00004.svc\n",
      "Shape of data from file ../test/test_data\\0_u00013s00001hw00004.svc: (702, 7)\n",
      "Processing file: ../test/test_data\\0_u00013s00001hw00005.svc\n",
      "Shape of data from file ../test/test_data\\0_u00013s00001hw00005.svc: (584, 7)\n",
      "Processing file: ../test/test_data\\0_u00013s00001hw00006.svc\n",
      "Shape of data from file ../test/test_data\\0_u00013s00001hw00006.svc: (4462, 7)\n",
      "Processing file: ../test/test_data\\0_u00013s00001hw00007.svc\n",
      "Shape of data from file ../test/test_data\\0_u00013s00001hw00007.svc: (3885, 7)\n",
      "Processing file: ../test/test_data\\0_u00015s00001hw00001.svc\n",
      "Shape of data from file ../test/test_data\\0_u00015s00001hw00001.svc: (2387, 7)\n",
      "Processing file: ../test/test_data\\0_u00015s00001hw00002.svc\n",
      "Shape of data from file ../test/test_data\\0_u00015s00001hw00002.svc: (4257, 7)\n",
      "Processing file: ../test/test_data\\0_u00015s00001hw00003.svc\n",
      "Shape of data from file ../test/test_data\\0_u00015s00001hw00003.svc: (3759, 7)\n",
      "Processing file: ../test/test_data\\0_u00015s00001hw00004.svc\n",
      "Shape of data from file ../test/test_data\\0_u00015s00001hw00004.svc: (859, 7)\n",
      "Processing file: ../test/test_data\\0_u00015s00001hw00005.svc\n",
      "Shape of data from file ../test/test_data\\0_u00015s00001hw00005.svc: (1216, 7)\n",
      "Processing file: ../test/test_data\\0_u00015s00001hw00006.svc\n",
      "Shape of data from file ../test/test_data\\0_u00015s00001hw00006.svc: (2841, 7)\n",
      "Processing file: ../test/test_data\\0_u00015s00001hw00007.svc\n",
      "Shape of data from file ../test/test_data\\0_u00015s00001hw00007.svc: (3161, 7)\n",
      "Processing file: ../test/test_data\\0_u00027s00001hw00001.svc\n",
      "Shape of data from file ../test/test_data\\0_u00027s00001hw00001.svc: (3190, 7)\n",
      "Processing file: ../test/test_data\\0_u00027s00001hw00002.svc\n",
      "Shape of data from file ../test/test_data\\0_u00027s00001hw00002.svc: (3673, 7)\n",
      "Processing file: ../test/test_data\\0_u00027s00001hw00003.svc\n",
      "Shape of data from file ../test/test_data\\0_u00027s00001hw00003.svc: (4358, 7)\n",
      "Processing file: ../test/test_data\\0_u00027s00001hw00004.svc\n",
      "Shape of data from file ../test/test_data\\0_u00027s00001hw00004.svc: (737, 7)\n",
      "Processing file: ../test/test_data\\0_u00027s00001hw00005.svc\n",
      "Shape of data from file ../test/test_data\\0_u00027s00001hw00005.svc: (788, 7)\n",
      "Processing file: ../test/test_data\\0_u00027s00001hw00006.svc\n",
      "Shape of data from file ../test/test_data\\0_u00027s00001hw00006.svc: (3123, 7)\n",
      "Processing file: ../test/test_data\\0_u00027s00001hw00007.svc\n",
      "Shape of data from file ../test/test_data\\0_u00027s00001hw00007.svc: (2972, 7)\n",
      "Processing file: ../test/test_data\\0_u00035s00001hw00001.svc\n",
      "Shape of data from file ../test/test_data\\0_u00035s00001hw00001.svc: (1715, 7)\n",
      "Processing file: ../test/test_data\\0_u00035s00001hw00002.svc\n",
      "Shape of data from file ../test/test_data\\0_u00035s00001hw00002.svc: (3061, 7)\n",
      "Processing file: ../test/test_data\\0_u00035s00001hw00003.svc\n",
      "Shape of data from file ../test/test_data\\0_u00035s00001hw00003.svc: (3337, 7)\n",
      "Processing file: ../test/test_data\\0_u00035s00001hw00004.svc\n",
      "Shape of data from file ../test/test_data\\0_u00035s00001hw00004.svc: (352, 7)\n",
      "Processing file: ../test/test_data\\0_u00035s00001hw00005.svc\n",
      "Shape of data from file ../test/test_data\\0_u00035s00001hw00005.svc: (477, 7)\n",
      "Processing file: ../test/test_data\\0_u00035s00001hw00006.svc\n",
      "Shape of data from file ../test/test_data\\0_u00035s00001hw00006.svc: (1909, 7)\n",
      "Processing file: ../test/test_data\\0_u00035s00001hw00007.svc\n",
      "Shape of data from file ../test/test_data\\0_u00035s00001hw00007.svc: (4222, 7)\n",
      "Processing file: ../test/test_data\\0_u00040s00001hw00001.svc\n",
      "Shape of data from file ../test/test_data\\0_u00040s00001hw00001.svc: (1950, 7)\n",
      "Processing file: ../test/test_data\\0_u00040s00001hw00002.svc\n",
      "Shape of data from file ../test/test_data\\0_u00040s00001hw00002.svc: (2742, 7)\n",
      "Processing file: ../test/test_data\\0_u00040s00001hw00003.svc\n",
      "Shape of data from file ../test/test_data\\0_u00040s00001hw00003.svc: (3093, 7)\n",
      "Processing file: ../test/test_data\\0_u00040s00001hw00004.svc\n",
      "Shape of data from file ../test/test_data\\0_u00040s00001hw00004.svc: (828, 7)\n",
      "Processing file: ../test/test_data\\0_u00040s00001hw00005.svc\n",
      "Shape of data from file ../test/test_data\\0_u00040s00001hw00005.svc: (638, 7)\n",
      "Processing file: ../test/test_data\\0_u00040s00001hw00006.svc\n",
      "Shape of data from file ../test/test_data\\0_u00040s00001hw00006.svc: (2396, 7)\n",
      "Processing file: ../test/test_data\\0_u00040s00001hw00007.svc\n",
      "Shape of data from file ../test/test_data\\0_u00040s00001hw00007.svc: (2443, 7)\n",
      "Processing file: ../test/test_data\\0_u00044s00001hw00001.svc\n",
      "Shape of data from file ../test/test_data\\0_u00044s00001hw00001.svc: (2565, 7)\n",
      "Processing file: ../test/test_data\\0_u00044s00001hw00002.svc\n",
      "Shape of data from file ../test/test_data\\0_u00044s00001hw00002.svc: (4913, 7)\n",
      "Processing file: ../test/test_data\\0_u00044s00001hw00003.svc\n",
      "Shape of data from file ../test/test_data\\0_u00044s00001hw00003.svc: (2768, 7)\n",
      "Processing file: ../test/test_data\\0_u00044s00001hw00004.svc\n",
      "Shape of data from file ../test/test_data\\0_u00044s00001hw00004.svc: (234, 7)\n",
      "Processing file: ../test/test_data\\0_u00044s00001hw00005.svc\n",
      "Shape of data from file ../test/test_data\\0_u00044s00001hw00005.svc: (289, 7)\n",
      "Processing file: ../test/test_data\\0_u00044s00001hw00006.svc\n",
      "Shape of data from file ../test/test_data\\0_u00044s00001hw00006.svc: (2131, 7)\n",
      "Processing file: ../test/test_data\\0_u00044s00001hw00007.svc\n",
      "Shape of data from file ../test/test_data\\0_u00044s00001hw00007.svc: (2378, 7)\n",
      "Processing file: ../test/test_data\\1_u00010s00001hw00001.svc\n",
      "Shape of data from file ../test/test_data\\1_u00010s00001hw00001.svc: (2063, 7)\n",
      "Processing file: ../test/test_data\\1_u00010s00001hw00002.svc\n",
      "Shape of data from file ../test/test_data\\1_u00010s00001hw00002.svc: (3050, 7)\n",
      "Processing file: ../test/test_data\\1_u00010s00001hw00003.svc\n",
      "Shape of data from file ../test/test_data\\1_u00010s00001hw00003.svc: (3151, 7)\n",
      "Processing file: ../test/test_data\\1_u00010s00001hw00004.svc\n",
      "Shape of data from file ../test/test_data\\1_u00010s00001hw00004.svc: (1495, 7)\n",
      "Processing file: ../test/test_data\\1_u00010s00001hw00005.svc\n",
      "Shape of data from file ../test/test_data\\1_u00010s00001hw00005.svc: (730, 7)\n",
      "Processing file: ../test/test_data\\1_u00010s00001hw00006.svc\n",
      "Shape of data from file ../test/test_data\\1_u00010s00001hw00006.svc: (2586, 7)\n",
      "Processing file: ../test/test_data\\1_u00010s00001hw00007.svc\n",
      "Shape of data from file ../test/test_data\\1_u00010s00001hw00007.svc: (2462, 7)\n",
      "Processing file: ../test/test_data\\1_u00011s00001hw00001.svc\n",
      "Shape of data from file ../test/test_data\\1_u00011s00001hw00001.svc: (2560, 7)\n",
      "Processing file: ../test/test_data\\1_u00011s00001hw00002.svc\n",
      "Shape of data from file ../test/test_data\\1_u00011s00001hw00002.svc: (3098, 7)\n",
      "Processing file: ../test/test_data\\1_u00011s00001hw00003.svc\n",
      "Shape of data from file ../test/test_data\\1_u00011s00001hw00003.svc: (3268, 7)\n",
      "Processing file: ../test/test_data\\1_u00011s00001hw00004.svc\n",
      "Shape of data from file ../test/test_data\\1_u00011s00001hw00004.svc: (1452, 7)\n",
      "Processing file: ../test/test_data\\1_u00011s00001hw00005.svc\n",
      "Shape of data from file ../test/test_data\\1_u00011s00001hw00005.svc: (786, 7)\n",
      "Processing file: ../test/test_data\\1_u00011s00001hw00006.svc\n",
      "Shape of data from file ../test/test_data\\1_u00011s00001hw00006.svc: (1605, 7)\n",
      "Processing file: ../test/test_data\\1_u00011s00001hw00007.svc\n",
      "Shape of data from file ../test/test_data\\1_u00011s00001hw00007.svc: (2615, 7)\n",
      "Processing file: ../test/test_data\\1_u00021s00001hw00001.svc\n",
      "Shape of data from file ../test/test_data\\1_u00021s00001hw00001.svc: (2983, 7)\n",
      "Processing file: ../test/test_data\\1_u00021s00001hw00002.svc\n",
      "Shape of data from file ../test/test_data\\1_u00021s00001hw00002.svc: (5639, 7)\n",
      "Processing file: ../test/test_data\\1_u00021s00001hw00003.svc\n",
      "Shape of data from file ../test/test_data\\1_u00021s00001hw00003.svc: (3857, 7)\n",
      "Processing file: ../test/test_data\\1_u00021s00001hw00004.svc\n",
      "Shape of data from file ../test/test_data\\1_u00021s00001hw00004.svc: (1272, 7)\n",
      "Processing file: ../test/test_data\\1_u00021s00001hw00005.svc\n",
      "Shape of data from file ../test/test_data\\1_u00021s00001hw00005.svc: (990, 7)\n",
      "Processing file: ../test/test_data\\1_u00021s00001hw00006.svc\n",
      "Shape of data from file ../test/test_data\\1_u00021s00001hw00006.svc: (6790, 7)\n",
      "Processing file: ../test/test_data\\1_u00021s00001hw00007.svc\n",
      "Shape of data from file ../test/test_data\\1_u00021s00001hw00007.svc: (3661, 7)\n",
      "Processing file: ../test/test_data\\1_u00038s00001hw00001.svc\n",
      "Shape of data from file ../test/test_data\\1_u00038s00001hw00001.svc: (2398, 7)\n",
      "Processing file: ../test/test_data\\1_u00038s00001hw00002.svc\n",
      "Shape of data from file ../test/test_data\\1_u00038s00001hw00002.svc: (2943, 7)\n",
      "Processing file: ../test/test_data\\1_u00038s00001hw00003.svc\n",
      "Shape of data from file ../test/test_data\\1_u00038s00001hw00003.svc: (4438, 7)\n",
      "Processing file: ../test/test_data\\1_u00038s00001hw00004.svc\n",
      "Shape of data from file ../test/test_data\\1_u00038s00001hw00004.svc: (631, 7)\n",
      "Processing file: ../test/test_data\\1_u00038s00001hw00005.svc\n",
      "Shape of data from file ../test/test_data\\1_u00038s00001hw00005.svc: (658, 7)\n",
      "Processing file: ../test/test_data\\1_u00038s00001hw00006.svc\n",
      "Shape of data from file ../test/test_data\\1_u00038s00001hw00006.svc: (1827, 7)\n",
      "Processing file: ../test/test_data\\1_u00038s00001hw00007.svc\n",
      "Shape of data from file ../test/test_data\\1_u00038s00001hw00007.svc: (2742, 7)\n",
      "Processing file: ../test/test_data\\2_u00001s00001hw00001.svc\n",
      "Shape of data from file ../test/test_data\\2_u00001s00001hw00001.svc: (1474, 7)\n",
      "Processing file: ../test/test_data\\2_u00001s00001hw00002.svc\n",
      "Shape of data from file ../test/test_data\\2_u00001s00001hw00002.svc: (2735, 7)\n",
      "Processing file: ../test/test_data\\2_u00001s00001hw00003.svc\n",
      "Shape of data from file ../test/test_data\\2_u00001s00001hw00003.svc: (3102, 7)\n",
      "Processing file: ../test/test_data\\2_u00001s00001hw00004.svc\n",
      "Shape of data from file ../test/test_data\\2_u00001s00001hw00004.svc: (1951, 7)\n",
      "Processing file: ../test/test_data\\2_u00001s00001hw00005.svc\n",
      "Shape of data from file ../test/test_data\\2_u00001s00001hw00005.svc: (1208, 7)\n",
      "Processing file: ../test/test_data\\2_u00001s00001hw00006.svc\n",
      "Shape of data from file ../test/test_data\\2_u00001s00001hw00006.svc: (2507, 7)\n",
      "Processing file: ../test/test_data\\2_u00001s00001hw00007.svc\n",
      "Shape of data from file ../test/test_data\\2_u00001s00001hw00007.svc: (2985, 7)\n",
      "Processing file: ../test/test_data\\2_u00002s00001hw00001.svc\n",
      "Shape of data from file ../test/test_data\\2_u00002s00001hw00001.svc: (2085, 7)\n",
      "Processing file: ../test/test_data\\2_u00002s00001hw00002.svc\n",
      "Shape of data from file ../test/test_data\\2_u00002s00001hw00002.svc: (3800, 7)\n",
      "Processing file: ../test/test_data\\2_u00002s00001hw00003.svc\n",
      "Shape of data from file ../test/test_data\\2_u00002s00001hw00003.svc: (4276, 7)\n",
      "Processing file: ../test/test_data\\2_u00002s00001hw00004.svc\n",
      "Shape of data from file ../test/test_data\\2_u00002s00001hw00004.svc: (1111, 7)\n",
      "Processing file: ../test/test_data\\2_u00002s00001hw00005.svc\n",
      "Shape of data from file ../test/test_data\\2_u00002s00001hw00005.svc: (862, 7)\n",
      "Processing file: ../test/test_data\\2_u00002s00001hw00006.svc\n",
      "Shape of data from file ../test/test_data\\2_u00002s00001hw00006.svc: (3178, 7)\n",
      "Processing file: ../test/test_data\\2_u00002s00001hw00007.svc\n",
      "Shape of data from file ../test/test_data\\2_u00002s00001hw00007.svc: (3154, 7)\n",
      "Processing file: ../test/test_data\\2_u00014s00001hw00001.svc\n",
      "Shape of data from file ../test/test_data\\2_u00014s00001hw00001.svc: (1706, 7)\n",
      "Processing file: ../test/test_data\\2_u00014s00001hw00002.svc\n",
      "Shape of data from file ../test/test_data\\2_u00014s00001hw00002.svc: (3116, 7)\n",
      "Processing file: ../test/test_data\\2_u00014s00001hw00002old.svc\n",
      "Shape of data from file ../test/test_data\\2_u00014s00001hw00002old.svc: (3373, 7)\n",
      "Processing file: ../test/test_data\\2_u00014s00001hw00003.svc\n",
      "Shape of data from file ../test/test_data\\2_u00014s00001hw00003.svc: (3038, 7)\n",
      "Processing file: ../test/test_data\\2_u00014s00001hw00004.svc\n",
      "Shape of data from file ../test/test_data\\2_u00014s00001hw00004.svc: (1183, 7)\n",
      "Processing file: ../test/test_data\\2_u00014s00001hw00005.svc\n",
      "Shape of data from file ../test/test_data\\2_u00014s00001hw00005.svc: (1071, 7)\n",
      "Processing file: ../test/test_data\\2_u00014s00001hw00006.svc\n",
      "Shape of data from file ../test/test_data\\2_u00014s00001hw00006.svc: (4209, 7)\n",
      "Processing file: ../test/test_data\\2_u00014s00001hw00007.svc\n",
      "Shape of data from file ../test/test_data\\2_u00014s00001hw00007.svc: (2851, 7)\n",
      "Processing file: ../test/test_data\\2_u00025s00001hw00001.svc\n",
      "Shape of data from file ../test/test_data\\2_u00025s00001hw00001.svc: (2216, 7)\n",
      "Processing file: ../test/test_data\\2_u00025s00001hw00002.svc\n",
      "Shape of data from file ../test/test_data\\2_u00025s00001hw00002.svc: (4579, 7)\n",
      "Processing file: ../test/test_data\\2_u00025s00001hw00003.svc\n",
      "Shape of data from file ../test/test_data\\2_u00025s00001hw00003.svc: (4493, 7)\n",
      "Processing file: ../test/test_data\\2_u00025s00001hw00004.svc\n",
      "Shape of data from file ../test/test_data\\2_u00025s00001hw00004.svc: (750, 7)\n",
      "Processing file: ../test/test_data\\2_u00025s00001hw00005.svc\n",
      "Shape of data from file ../test/test_data\\2_u00025s00001hw00005.svc: (698, 7)\n",
      "Processing file: ../test/test_data\\2_u00025s00001hw00006.svc\n",
      "Shape of data from file ../test/test_data\\2_u00025s00001hw00006.svc: (3392, 7)\n",
      "Processing file: ../test/test_data\\2_u00025s00001hw00007.svc\n",
      "Shape of data from file ../test/test_data\\2_u00025s00001hw00007.svc: (3952, 7)\n",
      "Processing file: ../test/test_data\\2_u00026s00001hw00001.svc\n",
      "Shape of data from file ../test/test_data\\2_u00026s00001hw00001.svc: (1639, 7)\n",
      "Processing file: ../test/test_data\\2_u00026s00001hw00002.svc\n",
      "Shape of data from file ../test/test_data\\2_u00026s00001hw00002.svc: (2587, 7)\n",
      "Processing file: ../test/test_data\\2_u00026s00001hw00003.svc\n",
      "Shape of data from file ../test/test_data\\2_u00026s00001hw00003.svc: (2977, 7)\n",
      "Processing file: ../test/test_data\\2_u00026s00001hw00004.svc\n",
      "Shape of data from file ../test/test_data\\2_u00026s00001hw00004.svc: (722, 7)\n",
      "Processing file: ../test/test_data\\2_u00026s00001hw00005.svc\n",
      "Shape of data from file ../test/test_data\\2_u00026s00001hw00005.svc: (789, 7)\n",
      "Processing file: ../test/test_data\\2_u00026s00001hw00006.svc\n",
      "Shape of data from file ../test/test_data\\2_u00026s00001hw00006.svc: (2270, 7)\n",
      "Processing file: ../test/test_data\\2_u00026s00001hw00007.svc\n",
      "Shape of data from file ../test/test_data\\2_u00026s00001hw00007.svc: (2468, 7)\n",
      "Processing file: ../test/test_data\\2_u00029s00001hw00001.svc\n",
      "Shape of data from file ../test/test_data\\2_u00029s00001hw00001.svc: (2762, 7)\n",
      "Processing file: ../test/test_data\\2_u00029s00001hw00002.svc\n",
      "Shape of data from file ../test/test_data\\2_u00029s00001hw00002.svc: (4978, 7)\n",
      "Processing file: ../test/test_data\\2_u00029s00001hw00003.svc\n",
      "Shape of data from file ../test/test_data\\2_u00029s00001hw00003.svc: (3463, 7)\n",
      "Processing file: ../test/test_data\\2_u00029s00001hw00004.svc\n",
      "Shape of data from file ../test/test_data\\2_u00029s00001hw00004.svc: (705, 7)\n",
      "Processing file: ../test/test_data\\2_u00029s00001hw00005.svc\n",
      "Shape of data from file ../test/test_data\\2_u00029s00001hw00005.svc: (657, 7)\n",
      "Processing file: ../test/test_data\\2_u00029s00001hw00006.svc\n",
      "Shape of data from file ../test/test_data\\2_u00029s00001hw00006.svc: (2541, 7)\n",
      "Processing file: ../test/test_data\\2_u00029s00001hw00007.svc\n",
      "Shape of data from file ../test/test_data\\2_u00029s00001hw00007.svc: (3531, 7)\n",
      "Processing file: ../test/test_data\\2_u00031s00001hw00001.svc\n",
      "Shape of data from file ../test/test_data\\2_u00031s00001hw00001.svc: (3274, 7)\n",
      "Processing file: ../test/test_data\\2_u00031s00001hw00002.svc\n",
      "Shape of data from file ../test/test_data\\2_u00031s00001hw00002.svc: (5134, 7)\n",
      "Processing file: ../test/test_data\\2_u00031s00001hw00003.svc\n",
      "Shape of data from file ../test/test_data\\2_u00031s00001hw00003.svc: (4195, 7)\n",
      "Processing file: ../test/test_data\\2_u00031s00001hw00004.svc\n",
      "Shape of data from file ../test/test_data\\2_u00031s00001hw00004.svc: (340, 7)\n",
      "Processing file: ../test/test_data\\2_u00031s00001hw00005.svc\n",
      "Shape of data from file ../test/test_data\\2_u00031s00001hw00005.svc: (748, 7)\n",
      "Processing file: ../test/test_data\\2_u00031s00001hw00006.svc\n",
      "Shape of data from file ../test/test_data\\2_u00031s00001hw00006.svc: (2544, 7)\n",
      "Processing file: ../test/test_data\\2_u00031s00001hw00007.svc\n",
      "Shape of data from file ../test/test_data\\2_u00031s00001hw00007.svc: (3128, 7)\n",
      "Processing file: ../test/test_data\\2_u00032s00001hw00001.svc\n",
      "Shape of data from file ../test/test_data\\2_u00032s00001hw00001.svc: (1948, 7)\n",
      "Processing file: ../test/test_data\\2_u00032s00001hw00002.svc\n",
      "Shape of data from file ../test/test_data\\2_u00032s00001hw00002.svc: (3519, 7)\n",
      "Processing file: ../test/test_data\\2_u00032s00001hw00003.svc\n",
      "Shape of data from file ../test/test_data\\2_u00032s00001hw00003.svc: (4745, 7)\n",
      "Processing file: ../test/test_data\\2_u00032s00001hw00004.svc\n",
      "Shape of data from file ../test/test_data\\2_u00032s00001hw00004.svc: (821, 7)\n",
      "Processing file: ../test/test_data\\2_u00032s00001hw00005.svc\n",
      "Shape of data from file ../test/test_data\\2_u00032s00001hw00005.svc: (595, 7)\n",
      "Processing file: ../test/test_data\\2_u00032s00001hw00006.svc\n",
      "Shape of data from file ../test/test_data\\2_u00032s00001hw00006.svc: (2867, 7)\n",
      "Processing file: ../test/test_data\\2_u00032s00001hw00007.svc\n",
      "Shape of data from file ../test/test_data\\2_u00032s00001hw00007.svc: (4123, 7)\n",
      "Processing file: ../test/test_data\\2_u00033s00001hw00001.svc\n",
      "Shape of data from file ../test/test_data\\2_u00033s00001hw00001.svc: (2650, 7)\n",
      "Processing file: ../test/test_data\\2_u00033s00001hw00002.svc\n",
      "Shape of data from file ../test/test_data\\2_u00033s00001hw00002.svc: (4728, 7)\n",
      "Processing file: ../test/test_data\\2_u00033s00001hw00003.svc\n",
      "Shape of data from file ../test/test_data\\2_u00033s00001hw00003.svc: (3117, 7)\n",
      "Processing file: ../test/test_data\\2_u00033s00001hw00004.svc\n",
      "Shape of data from file ../test/test_data\\2_u00033s00001hw00004.svc: (1074, 7)\n",
      "Processing file: ../test/test_data\\2_u00033s00001hw00005.svc\n",
      "Shape of data from file ../test/test_data\\2_u00033s00001hw00005.svc: (1020, 7)\n",
      "Processing file: ../test/test_data\\2_u00033s00001hw00006.svc\n",
      "Shape of data from file ../test/test_data\\2_u00033s00001hw00006.svc: (8368, 7)\n",
      "Processing file: ../test/test_data\\2_u00033s00001hw00007.svc\n",
      "Shape of data from file ../test/test_data\\2_u00033s00001hw00007.svc: (3242, 7)\n",
      "Processing file: ../test/test_data\\2_u00036s00001hw00001.svc\n",
      "Shape of data from file ../test/test_data\\2_u00036s00001hw00001.svc: (2532, 7)\n",
      "Processing file: ../test/test_data\\2_u00036s00001hw00002.svc\n",
      "Shape of data from file ../test/test_data\\2_u00036s00001hw00002.svc: (5020, 7)\n",
      "Processing file: ../test/test_data\\2_u00036s00001hw00003.svc\n",
      "Shape of data from file ../test/test_data\\2_u00036s00001hw00003.svc: (6775, 7)\n",
      "Processing file: ../test/test_data\\2_u00036s00001hw00004.svc\n",
      "Shape of data from file ../test/test_data\\2_u00036s00001hw00004.svc: (289, 7)\n",
      "Processing file: ../test/test_data\\2_u00036s00001hw00005.svc\n",
      "Shape of data from file ../test/test_data\\2_u00036s00001hw00005.svc: (359, 7)\n",
      "Processing file: ../test/test_data\\2_u00036s00001hw00006.svc\n",
      "Shape of data from file ../test/test_data\\2_u00036s00001hw00006.svc: (2942, 7)\n",
      "Processing file: ../test/test_data\\2_u00036s00001hw00007.svc\n",
      "Shape of data from file ../test/test_data\\2_u00036s00001hw00007.svc: (4113, 7)\n",
      "Processing file: ../test/test_data\\2_u00041s00001hw00001.svc\n",
      "Shape of data from file ../test/test_data\\2_u00041s00001hw00001.svc: (2543, 7)\n",
      "Processing file: ../test/test_data\\2_u00041s00001hw00002.svc\n",
      "Shape of data from file ../test/test_data\\2_u00041s00001hw00002.svc: (3376, 7)\n",
      "Processing file: ../test/test_data\\2_u00041s00001hw00003.svc\n",
      "Shape of data from file ../test/test_data\\2_u00041s00001hw00003.svc: (3244, 7)\n",
      "Processing file: ../test/test_data\\2_u00041s00001hw00004.svc\n",
      "Shape of data from file ../test/test_data\\2_u00041s00001hw00004.svc: (399, 7)\n",
      "Processing file: ../test/test_data\\2_u00041s00001hw00005.svc\n",
      "Shape of data from file ../test/test_data\\2_u00041s00001hw00005.svc: (295, 7)\n",
      "Processing file: ../test/test_data\\2_u00041s00001hw00006.svc\n",
      "Shape of data from file ../test/test_data\\2_u00041s00001hw00006.svc: (2737, 7)\n",
      "Processing file: ../test/test_data\\2_u00041s00001hw00007.svc\n",
      "Shape of data from file ../test/test_data\\2_u00041s00001hw00007.svc: (3516, 7)\n",
      "Processing file: ../test/test_data\\2_u00042s00001hw00001.svc\n",
      "Shape of data from file ../test/test_data\\2_u00042s00001hw00001.svc: (1861, 7)\n",
      "Processing file: ../test/test_data\\2_u00042s00001hw00002.svc\n",
      "Shape of data from file ../test/test_data\\2_u00042s00001hw00002.svc: (4259, 7)\n",
      "Processing file: ../test/test_data\\2_u00042s00001hw00003.svc\n",
      "Shape of data from file ../test/test_data\\2_u00042s00001hw00003.svc: (4788, 7)\n",
      "Processing file: ../test/test_data\\2_u00042s00001hw00004.svc\n",
      "Shape of data from file ../test/test_data\\2_u00042s00001hw00004.svc: (534, 7)\n",
      "Processing file: ../test/test_data\\2_u00042s00001hw00005.svc\n",
      "Shape of data from file ../test/test_data\\2_u00042s00001hw00005.svc: (370, 7)\n",
      "Processing file: ../test/test_data\\2_u00042s00001hw00006.svc\n",
      "Shape of data from file ../test/test_data\\2_u00042s00001hw00006.svc: (2611, 7)\n",
      "Processing file: ../test/test_data\\2_u00042s00001hw00007.svc\n",
      "Shape of data from file ../test/test_data\\2_u00042s00001hw00007.svc: (3858, 7)\n",
      "Processing file: ../test/test_data\\2_u00043s00001hw00001.svc\n",
      "Shape of data from file ../test/test_data\\2_u00043s00001hw00001.svc: (2480, 7)\n",
      "Processing file: ../test/test_data\\2_u00043s00001hw00002.svc\n",
      "Shape of data from file ../test/test_data\\2_u00043s00001hw00002.svc: (3522, 7)\n",
      "Processing file: ../test/test_data\\2_u00043s00001hw00003.svc\n",
      "Shape of data from file ../test/test_data\\2_u00043s00001hw00003.svc: (4137, 7)\n",
      "Processing file: ../test/test_data\\2_u00043s00001hw00004.svc\n",
      "Shape of data from file ../test/test_data\\2_u00043s00001hw00004.svc: (359, 7)\n",
      "Processing file: ../test/test_data\\2_u00043s00001hw00005.svc\n",
      "Shape of data from file ../test/test_data\\2_u00043s00001hw00005.svc: (143, 7)\n",
      "Processing file: ../test/test_data\\2_u00043s00001hw00006.svc\n",
      "Shape of data from file ../test/test_data\\2_u00043s00001hw00006.svc: (2050, 7)\n",
      "Processing file: ../test/test_data\\2_u00043s00001hw00007.svc\n",
      "Shape of data from file ../test/test_data\\2_u00043s00001hw00007.svc: (2596, 7)\n",
      "Processing file: ../test/test_data\\3_u00020s00001hw00001.svc\n",
      "Shape of data from file ../test/test_data\\3_u00020s00001hw00001.svc: (2122, 7)\n",
      "Processing file: ../test/test_data\\3_u00020s00001hw00002.svc\n",
      "Shape of data from file ../test/test_data\\3_u00020s00001hw00002.svc: (3185, 7)\n",
      "Processing file: ../test/test_data\\3_u00020s00001hw00003.svc\n",
      "Shape of data from file ../test/test_data\\3_u00020s00001hw00003.svc: (3257, 7)\n",
      "Processing file: ../test/test_data\\3_u00020s00001hw00003old.svc\n",
      "Shape of data from file ../test/test_data\\3_u00020s00001hw00003old.svc: (3332, 7)\n",
      "Processing file: ../test/test_data\\3_u00020s00001hw00004.svc\n",
      "Shape of data from file ../test/test_data\\3_u00020s00001hw00004.svc: (953, 7)\n",
      "Processing file: ../test/test_data\\3_u00020s00001hw00005.svc\n",
      "Shape of data from file ../test/test_data\\3_u00020s00001hw00005.svc: (1228, 7)\n",
      "Processing file: ../test/test_data\\3_u00020s00001hw00006.svc\n",
      "Shape of data from file ../test/test_data\\3_u00020s00001hw00006.svc: (2331, 7)\n",
      "Processing file: ../test/test_data\\3_u00020s00001hw00007.svc\n",
      "Shape of data from file ../test/test_data\\3_u00020s00001hw00007.svc: (2956, 7)\n",
      "Processing file: ../test/test_data\\3_u00021s00001hw00001.svc\n",
      "Shape of data from file ../test/test_data\\3_u00021s00001hw00001.svc: (2122, 7)\n",
      "Processing file: ../test/test_data\\3_u00021s00001hw00002.svc\n",
      "Shape of data from file ../test/test_data\\3_u00021s00001hw00002.svc: (3185, 7)\n",
      "Processing file: ../test/test_data\\3_u00021s00001hw00003.svc\n",
      "Shape of data from file ../test/test_data\\3_u00021s00001hw00003.svc: (3332, 7)\n",
      "Processing file: ../test/test_data\\3_u00021s00001hw00004.svc\n",
      "Shape of data from file ../test/test_data\\3_u00021s00001hw00004.svc: (953, 7)\n",
      "Processing file: ../test/test_data\\3_u00021s00001hw00005.svc\n",
      "Shape of data from file ../test/test_data\\3_u00021s00001hw00005.svc: (1228, 7)\n",
      "Shapes of all_data before concatenation:\n",
      "Data array 0 shape: (2643, 7)\n",
      "Data array 1 shape: (5691, 7)\n",
      "Data array 2 shape: (3863, 7)\n",
      "Data array 3 shape: (1178, 7)\n",
      "Data array 4 shape: (770, 7)\n",
      "Data array 5 shape: (4051, 7)\n",
      "Data array 6 shape: (3050, 7)\n",
      "Data array 7 shape: (1782, 7)\n",
      "Data array 8 shape: (3817, 7)\n",
      "Data array 9 shape: (3831, 7)\n",
      "Data array 10 shape: (702, 7)\n",
      "Data array 11 shape: (584, 7)\n",
      "Data array 12 shape: (4462, 7)\n",
      "Data array 13 shape: (3885, 7)\n",
      "Data array 14 shape: (2387, 7)\n",
      "Data array 15 shape: (4257, 7)\n",
      "Data array 16 shape: (3759, 7)\n",
      "Data array 17 shape: (859, 7)\n",
      "Data array 18 shape: (1216, 7)\n",
      "Data array 19 shape: (2841, 7)\n",
      "Data array 20 shape: (3161, 7)\n",
      "Data array 21 shape: (3190, 7)\n",
      "Data array 22 shape: (3673, 7)\n",
      "Data array 23 shape: (4358, 7)\n",
      "Data array 24 shape: (737, 7)\n",
      "Data array 25 shape: (788, 7)\n",
      "Data array 26 shape: (3123, 7)\n",
      "Data array 27 shape: (2972, 7)\n",
      "Data array 28 shape: (1715, 7)\n",
      "Data array 29 shape: (3061, 7)\n",
      "Data array 30 shape: (3337, 7)\n",
      "Data array 31 shape: (352, 7)\n",
      "Data array 32 shape: (477, 7)\n",
      "Data array 33 shape: (1909, 7)\n",
      "Data array 34 shape: (4222, 7)\n",
      "Data array 35 shape: (1950, 7)\n",
      "Data array 36 shape: (2742, 7)\n",
      "Data array 37 shape: (3093, 7)\n",
      "Data array 38 shape: (828, 7)\n",
      "Data array 39 shape: (638, 7)\n",
      "Data array 40 shape: (2396, 7)\n",
      "Data array 41 shape: (2443, 7)\n",
      "Data array 42 shape: (2565, 7)\n",
      "Data array 43 shape: (4913, 7)\n",
      "Data array 44 shape: (2768, 7)\n",
      "Data array 45 shape: (234, 7)\n",
      "Data array 46 shape: (289, 7)\n",
      "Data array 47 shape: (2131, 7)\n",
      "Data array 48 shape: (2378, 7)\n",
      "Data array 49 shape: (2063, 7)\n",
      "Data array 50 shape: (3050, 7)\n",
      "Data array 51 shape: (3151, 7)\n",
      "Data array 52 shape: (1495, 7)\n",
      "Data array 53 shape: (730, 7)\n",
      "Data array 54 shape: (2586, 7)\n",
      "Data array 55 shape: (2462, 7)\n",
      "Data array 56 shape: (2560, 7)\n",
      "Data array 57 shape: (3098, 7)\n",
      "Data array 58 shape: (3268, 7)\n",
      "Data array 59 shape: (1452, 7)\n",
      "Data array 60 shape: (786, 7)\n",
      "Data array 61 shape: (1605, 7)\n",
      "Data array 62 shape: (2615, 7)\n",
      "Data array 63 shape: (2983, 7)\n",
      "Data array 64 shape: (5639, 7)\n",
      "Data array 65 shape: (3857, 7)\n",
      "Data array 66 shape: (1272, 7)\n",
      "Data array 67 shape: (990, 7)\n",
      "Data array 68 shape: (6790, 7)\n",
      "Data array 69 shape: (3661, 7)\n",
      "Data array 70 shape: (2398, 7)\n",
      "Data array 71 shape: (2943, 7)\n",
      "Data array 72 shape: (4438, 7)\n",
      "Data array 73 shape: (631, 7)\n",
      "Data array 74 shape: (658, 7)\n",
      "Data array 75 shape: (1827, 7)\n",
      "Data array 76 shape: (2742, 7)\n",
      "Data array 77 shape: (1474, 7)\n",
      "Data array 78 shape: (2735, 7)\n",
      "Data array 79 shape: (3102, 7)\n",
      "Data array 80 shape: (1951, 7)\n",
      "Data array 81 shape: (1208, 7)\n",
      "Data array 82 shape: (2507, 7)\n",
      "Data array 83 shape: (2985, 7)\n",
      "Data array 84 shape: (2085, 7)\n",
      "Data array 85 shape: (3800, 7)\n",
      "Data array 86 shape: (4276, 7)\n",
      "Data array 87 shape: (1111, 7)\n",
      "Data array 88 shape: (862, 7)\n",
      "Data array 89 shape: (3178, 7)\n",
      "Data array 90 shape: (3154, 7)\n",
      "Data array 91 shape: (1706, 7)\n",
      "Data array 92 shape: (3116, 7)\n",
      "Data array 93 shape: (3373, 7)\n",
      "Data array 94 shape: (3038, 7)\n",
      "Data array 95 shape: (1183, 7)\n",
      "Data array 96 shape: (1071, 7)\n",
      "Data array 97 shape: (4209, 7)\n",
      "Data array 98 shape: (2851, 7)\n",
      "Data array 99 shape: (2216, 7)\n",
      "Data array 100 shape: (4579, 7)\n",
      "Data array 101 shape: (4493, 7)\n",
      "Data array 102 shape: (750, 7)\n",
      "Data array 103 shape: (698, 7)\n",
      "Data array 104 shape: (3392, 7)\n",
      "Data array 105 shape: (3952, 7)\n",
      "Data array 106 shape: (1639, 7)\n",
      "Data array 107 shape: (2587, 7)\n",
      "Data array 108 shape: (2977, 7)\n",
      "Data array 109 shape: (722, 7)\n",
      "Data array 110 shape: (789, 7)\n",
      "Data array 111 shape: (2270, 7)\n",
      "Data array 112 shape: (2468, 7)\n",
      "Data array 113 shape: (2762, 7)\n",
      "Data array 114 shape: (4978, 7)\n",
      "Data array 115 shape: (3463, 7)\n",
      "Data array 116 shape: (705, 7)\n",
      "Data array 117 shape: (657, 7)\n",
      "Data array 118 shape: (2541, 7)\n",
      "Data array 119 shape: (3531, 7)\n",
      "Data array 120 shape: (3274, 7)\n",
      "Data array 121 shape: (5134, 7)\n",
      "Data array 122 shape: (4195, 7)\n",
      "Data array 123 shape: (340, 7)\n",
      "Data array 124 shape: (748, 7)\n",
      "Data array 125 shape: (2544, 7)\n",
      "Data array 126 shape: (3128, 7)\n",
      "Data array 127 shape: (1948, 7)\n",
      "Data array 128 shape: (3519, 7)\n",
      "Data array 129 shape: (4745, 7)\n",
      "Data array 130 shape: (821, 7)\n",
      "Data array 131 shape: (595, 7)\n",
      "Data array 132 shape: (2867, 7)\n",
      "Data array 133 shape: (4123, 7)\n",
      "Data array 134 shape: (2650, 7)\n",
      "Data array 135 shape: (4728, 7)\n",
      "Data array 136 shape: (3117, 7)\n",
      "Data array 137 shape: (1074, 7)\n",
      "Data array 138 shape: (1020, 7)\n",
      "Data array 139 shape: (8368, 7)\n",
      "Data array 140 shape: (3242, 7)\n",
      "Data array 141 shape: (2532, 7)\n",
      "Data array 142 shape: (5020, 7)\n",
      "Data array 143 shape: (6775, 7)\n",
      "Data array 144 shape: (289, 7)\n",
      "Data array 145 shape: (359, 7)\n",
      "Data array 146 shape: (2942, 7)\n",
      "Data array 147 shape: (4113, 7)\n",
      "Data array 148 shape: (2543, 7)\n",
      "Data array 149 shape: (3376, 7)\n",
      "Data array 150 shape: (3244, 7)\n",
      "Data array 151 shape: (399, 7)\n",
      "Data array 152 shape: (295, 7)\n",
      "Data array 153 shape: (2737, 7)\n",
      "Data array 154 shape: (3516, 7)\n",
      "Data array 155 shape: (1861, 7)\n",
      "Data array 156 shape: (4259, 7)\n",
      "Data array 157 shape: (4788, 7)\n",
      "Data array 158 shape: (534, 7)\n",
      "Data array 159 shape: (370, 7)\n",
      "Data array 160 shape: (2611, 7)\n",
      "Data array 161 shape: (3858, 7)\n",
      "Data array 162 shape: (2480, 7)\n",
      "Data array 163 shape: (3522, 7)\n",
      "Data array 164 shape: (4137, 7)\n",
      "Data array 165 shape: (359, 7)\n",
      "Data array 166 shape: (143, 7)\n",
      "Data array 167 shape: (2050, 7)\n",
      "Data array 168 shape: (2596, 7)\n",
      "Data array 169 shape: (2122, 7)\n",
      "Data array 170 shape: (3185, 7)\n",
      "Data array 171 shape: (3257, 7)\n",
      "Data array 172 shape: (3332, 7)\n",
      "Data array 173 shape: (953, 7)\n",
      "Data array 174 shape: (1228, 7)\n",
      "Data array 175 shape: (2331, 7)\n",
      "Data array 176 shape: (2956, 7)\n",
      "Data array 177 shape: (2122, 7)\n",
      "Data array 178 shape: (3185, 7)\n",
      "Data array 179 shape: (3332, 7)\n",
      "Data array 180 shape: (953, 7)\n",
      "Data array 181 shape: (1228, 7)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2\n",
    "def load_emothaw_data(directory_path):\n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Use glob to find all .svc files in the specified directory\n",
    "    file_paths = glob.glob(os.path.join(directory_path, \"*.svc\"))\n",
    "    if not file_paths:\n",
    "        # Raise an error if no files are found\n",
    "        raise ValueError(\"No files found in the specified directory\")\n",
    "\n",
    "    # Iterate over each file path found\n",
    "    for file_path in file_paths:\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        try:\n",
    "            # Extract the label from the filename\n",
    "            # Assuming the label is the part before the first underscore '_'\n",
    "            label = int(os.path.basename(file_path).split('_')[0])\n",
    "\n",
    "            # Load the file and strip trailing spaces\n",
    "            with open(file_path, 'r') as f:\n",
    "                lines = [line.strip() for line in f.readlines() if line.strip()]  # Ignore empty lines\n",
    "\n",
    "            # Convert the lines into a DataFrame by splitting each line by whitespace\n",
    "            df = pd.DataFrame([line.split() for line in lines])  # Split by whitespace\n",
    "\n",
    "            # Skip empty files\n",
    "            if df.empty:\n",
    "                print(f\"Warning: {file_path} is empty after processing. Skipping file.\")\n",
    "                continue\n",
    "\n",
    "            # First row contains the total number of data rows (excluding the first row)\n",
    "            total_rows = int(df.iloc[0, 0])  # Number of expected sequences\n",
    "\n",
    "            # Extract the feature data from the subsequent rows\n",
    "            data = df.iloc[1:, :].values  # All columns are treated as features\n",
    "\n",
    "            # Check if enough data rows exist as per the first row's instruction\n",
    "            if data.shape[0] < total_rows:\n",
    "                raise ValueError(f\"Insufficient data: expected {total_rows}, but found {data.shape[0]}\")\n",
    "\n",
    "            # Ensure each row has exactly 7 feature values\n",
    "            reshaped_data = []\n",
    "            for row in data:\n",
    "                if len(row) == 7:\n",
    "                    reshaped_data.append(row)\n",
    "                else:\n",
    "                    print(f\"Warning: Row does not have 7 values, skipping: {row}\")\n",
    "\n",
    "            # If valid reshaped data exists, convert it into a NumPy array\n",
    "            if reshaped_data:\n",
    "                reshaped_data = np.array(reshaped_data, dtype=float)  # Convert to float type\n",
    "\n",
    "                # Check that reshaped data has enough rows as expected\n",
    "                if reshaped_data.shape[0] < total_rows:\n",
    "                    raise ValueError(f\"Insufficient data: expected {total_rows}, but found {reshaped_data.shape[0]}\")\n",
    "\n",
    "                # Append the reshaped data and labels\n",
    "                all_data.append(reshaped_data)\n",
    "                all_labels.append([label] * reshaped_data.shape[0])  # Append the label for each data row\n",
    "\n",
    "                # Print the shape of reshaped data for debugging\n",
    "                print(f\"Shape of data from file {file_path}: {reshaped_data.shape}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # If any error occurs, display the error and continue processing the next file\n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Raise an error if no valid data was processed\n",
    "    if not all_data or not all_labels:\n",
    "        raise ValueError(\"No valid data found in the directory\")\n",
    "\n",
    "    # Print the shapes of individual data entries for debugging\n",
    "    print(\"Shapes of all_data before concatenation:\")\n",
    "    for i, data_array in enumerate(all_data):\n",
    "        print(f\"Data array {i} shape: {data_array.shape}\")\n",
    "\n",
    "    # Concatenate all data arrays along the sample axis (rows)\n",
    "    try:\n",
    "        all_data = np.concatenate(all_data, axis=0)  # Concatenate data arrays\n",
    "    except Exception as e:\n",
    "        print(f\"Error during concatenation: {e}\")\n",
    "\n",
    "    # Concatenate labels\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    # Return the processed data and corresponding labels\n",
    "    return all_data, all_labels\n",
    "\n",
    "# Importing all files on the Directory\n",
    "data, labels = load_emothaw_data(r'../test/test_data/')  # Directory path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logger = logging.getLogger()\n",
    "\n",
    "def extract_time_domain_features(data):\n",
    "    logger.info(\"Starting time-domain feature extraction\")\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    # Vectorized computation of statistics across all samples at once\n",
    "    # Compute stats for each feature across all samples\n",
    "    means = np.mean(data, axis=1)\n",
    "    stds = np.std(data, axis=1)\n",
    "    mins = np.min(data, axis=1)\n",
    "    maxs = np.max(data, axis=1)\n",
    "    percentile_25 = np.percentile(data, 25, axis=1)\n",
    "    percentile_50 = np.percentile(data, 50, axis=1)\n",
    "    percentile_75 = np.percentile(data, 75, axis=1)\n",
    "    \n",
    "    # Stack all features horizontally for each sample\n",
    "    time_features = np.column_stack([\n",
    "        means, stds, mins, maxs,\n",
    "        percentile_25, percentile_50, percentile_75\n",
    "    ])\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    elapsed_time = end_time - start_time\n",
    "    logger.info(f\"Feature extraction completed in {elapsed_time}\")\n",
    "    \n",
    "    return time_features\n",
    "\n",
    "def extract_frequency_domain_features(data):\n",
    "    logger.info(\"Starting frequency-domain feature extraction\")\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    # Apply FFT to all samples at once\n",
    "    freq_features = np.fft.fft(data, axis=1)\n",
    "    freq_magnitude = np.abs(freq_features)\n",
    "    \n",
    "    # Calculate dominant frequencies and energy\n",
    "    dominant_freqs = np.argmax(freq_magnitude, axis=1)\n",
    "    freq_energies = np.sum(freq_magnitude, axis=1)\n",
    "    \n",
    "    # Combine features\n",
    "    freq_features = np.column_stack([dominant_freqs, freq_energies])\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    elapsed_time = end_time - start_time\n",
    "    logger.info(f\"Frequency-domain feature extraction completed in {elapsed_time}\")\n",
    "    \n",
    "    return freq_features\n",
    "\n",
    "def extract_statistical_features(data):\n",
    "    logger.info(\"Starting statistical feature extraction\")\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    # Compute statistics for all samples at once\n",
    "    means = np.mean(data, axis=1)\n",
    "    medians = np.median(data, axis=1)\n",
    "    variances = np.var(data, axis=1)\n",
    "    \n",
    "    # Compute skewness and kurtosis along the feature axis\n",
    "    skewness = skew(data, axis=1)\n",
    "    kurtosis_vals = kurtosis(data, axis=1)\n",
    "    \n",
    "    # Combine all statistical features\n",
    "    statistical_features = np.column_stack([\n",
    "        means, medians, variances, skewness, kurtosis_vals\n",
    "    ])\n",
    "    \n",
    "    end_time = datetime.now()\n",
    "    elapsed_time = end_time - start_time\n",
    "    logger.info(f\"Statistical feature extraction completed in {elapsed_time}\")\n",
    "    \n",
    "    return statistical_features\n",
    "\n",
    "# Example usage:\n",
    "def process_features(data):\n",
    "    \"\"\"\n",
    "    Process all features at once and combine them\n",
    "    \"\"\"\n",
    "    time_features = extract_time_domain_features(data)\n",
    "    freq_features = extract_frequency_domain_features(data)\n",
    "    stat_features = extract_statistical_features(data)\n",
    "    \n",
    "    # Combine all features\n",
    "    combined_features = np.concatenate([\n",
    "        time_features,\n",
    "        freq_features,\n",
    "        stat_features\n",
    "    ], axis=1)\n",
    "    \n",
    "    return combined_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 21:09:39,859 - Starting time-domain feature extraction\n",
      "2024-12-01 21:09:40,495 - Feature extraction completed in 0:00:00.636009\n",
      "2024-12-01 21:09:40,504 - Starting frequency-domain feature extraction\n",
      "2024-12-01 21:09:40,819 - Frequency-domain feature extraction completed in 0:00:00.311160\n",
      "2024-12-01 21:09:40,828 - Starting statistical feature extraction\n",
      "2024-12-01 21:09:41,835 - Statistical feature extraction completed in 0:00:01.006257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Domain Features\n",
      "[[3.25247000e+05 7.62450052e+05 1.00000000e+00 ... 3.04000000e+02\n",
      "  1.87000000e+03 4.09560000e+04]\n",
      " [3.25264143e+05 7.62445522e+05 1.00000000e+00 ... 3.64500000e+02\n",
      "  1.87000000e+03 4.09520000e+04]\n",
      " [3.25276571e+05 7.62443530e+05 1.00000000e+00 ... 4.02500000e+02\n",
      "  1.87000000e+03 4.09535000e+04]\n",
      " ...\n",
      " [6.83118571e+04 1.50349954e+05 1.00000000e+00 ... 6.52000000e+02\n",
      "  2.20000000e+03 1.95310000e+04]\n",
      " [6.82805714e+04 1.50366335e+05 1.00000000e+00 ... 5.63000000e+02\n",
      "  2.20000000e+03 1.95065000e+04]\n",
      " [6.82157143e+04 1.50397191e+05 1.00000000e+00 ... 3.53500000e+02\n",
      "  2.20000000e+03 1.94855000e+04]]\n",
      "Frequency\n",
      "[[       0.         15348978.31224078]\n",
      " [       0.         15349026.54532406]\n",
      " [       0.         15349082.72993092]\n",
      " ...\n",
      " [       0.          3053305.17900412]\n",
      " [       0.          3053350.51779034]\n",
      " [       0.          3053384.25953512]]\n",
      "Statistical Features\n",
      "[[3.25247000e+05 1.87000000e+03 5.81330082e+11 2.03885544e+00\n",
      "  2.16142644e+00]\n",
      " [3.25264143e+05 1.87000000e+03 5.81323174e+11 2.03885976e+00\n",
      "  2.16143599e+00]\n",
      " [3.25276571e+05 1.87000000e+03 5.81320136e+11 2.03886182e+00\n",
      "  2.16144052e+00]\n",
      " ...\n",
      " [6.83118571e+04 2.20000000e+03 2.26051087e+10 2.01927937e+00\n",
      "  2.11634093e+00]\n",
      " [6.82805714e+04 2.20000000e+03 2.26100346e+10 2.01926279e+00\n",
      "  2.11630362e+00]\n",
      " [6.82157143e+04 2.20000000e+03 2.26193151e+10 2.01918305e+00\n",
      "  2.11612409e+00]]\n",
      "(465037, 7)\n",
      "(465037, 2)\n",
      "(465037, 5)\n"
     ]
    }
   ],
   "source": [
    "# Cell 4\n",
    "# Extract all features\n",
    "time_domain_features = extract_time_domain_features(data)\n",
    "frequency_domain_features = extract_frequency_domain_features(data)\n",
    "statistical_features = extract_statistical_features(data)\n",
    "\n",
    "# Combine features\n",
    "features = np.concatenate((time_domain_features, frequency_domain_features, statistical_features), axis=1)\n",
    "\n",
    "print(\"Time Domain Features\")\n",
    "print(time_domain_features)\n",
    "print(\"Frequency\")\n",
    "print(frequency_domain_features)\n",
    "print(\"Statistical Features\")\n",
    "print(statistical_features)\n",
    "print(time_domain_features.shape)\n",
    "print(frequency_domain_features.shape)\n",
    "print(statistical_features.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.saving import register_keras_serializable\n",
    "from tensorflow.keras.regularizers import l2\n",
    "@register_keras_serializable()\n",
    "class MultiHeadSelfAttention(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, dropout_rate=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout_rate = dropout_rate\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\")\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "        self.query_dense = layers.Dense(embed_dim, kernel_regularizer=l2(0.01))\n",
    "        self.key_dense = layers.Dense(embed_dim, kernel_regularizer=l2(0.01))\n",
    "        self.value_dense = layers.Dense(embed_dim, kernel_regularizer=l2(0.01))\n",
    "        self.combine_heads = layers.Dense(embed_dim, kernel_regularizer=l2(0.01))\n",
    "        self.dropout = layers.Dropout(dropout_rate)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dropout_rate\": self.dropout_rate,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        weights = self.dropout(weights)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)\n",
    "        key = self.key_dense(inputs)\n",
    "        value = self.value_dense(inputs)\n",
    "        query = self.separate_heads(query, batch_size)\n",
    "        key = self.separate_heads(key, batch_size)\n",
    "        value = self.separate_heads(value, batch_size)\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])\n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim))\n",
    "        output = self.combine_heads(concat_attention)\n",
    "        return output\n",
    "\n",
    "@register_keras_serializable()\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.2, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.rate = rate\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads, rate)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            layers.Dense(ff_dim, activation=\"relu\", kernel_regularizer=l2(0.01)),\n",
    "            layers.Dropout(rate),\n",
    "            layers.Dense(embed_dim, kernel_regularizer=l2(0.01))\n",
    "        ])\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"ff_dim\": self.ff_dim,\n",
    "            \"rate\": self.rate,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        attn_output = self.att(inputs, training=training)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "@register_keras_serializable()\n",
    "class TransformerClassifier(Model):\n",
    "    def __init__(self, num_classes, embed_dim, num_heads, ff_dim, num_layers, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_classes = num_classes\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Input normalization layer\n",
    "        self.input_norm = layers.BatchNormalization()\n",
    "        \n",
    "        # Initial dense layer with dropout\n",
    "        self.dense_input = layers.Dense(embed_dim, kernel_regularizer=l2(0.01))\n",
    "        self.input_dropout = layers.Dropout(0.2)\n",
    "        \n",
    "        # Transformer blocks\n",
    "        self.transformer_blocks = [\n",
    "            TransformerBlock(embed_dim, num_heads, ff_dim) for _ in range(num_layers)\n",
    "        ]\n",
    "        \n",
    "        # Output layers with regularization\n",
    "        self.global_average_pooling = layers.GlobalAveragePooling1D()\n",
    "        self.dropout1 = layers.Dropout(0.2)\n",
    "        self.dense1 = layers.Dense(128, activation='relu', kernel_regularizer=l2(0.01))\n",
    "        self.dropout2 = layers.Dropout(0.2)\n",
    "        self.dense2 = layers.Dense(num_classes, activation='softmax', kernel_regularizer=l2(0.01))\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"num_classes\": self.num_classes,\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"ff_dim\": self.ff_dim,\n",
    "            \"num_layers\": self.num_layers,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.input_norm(inputs)\n",
    "        x = self.dense_input(x)\n",
    "        x = self.input_dropout(x, training=training)\n",
    "        \n",
    "        for transformer in self.transformer_blocks:\n",
    "            x = transformer(x, training=training)\n",
    "            \n",
    "        x = self.global_average_pooling(x)\n",
    "        x = self.dropout1(x, training=training)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout2(x, training=training)\n",
    "        return self.dense2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m4651/4651\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 24ms/step - accuracy: 0.7159 - loss: 1.2100 - val_accuracy: 0.7746 - val_loss: 0.6162 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m4651/4651\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 23ms/step - accuracy: 0.7728 - loss: 0.6604 - val_accuracy: 0.7984 - val_loss: 0.5848 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m4651/4651\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 22ms/step - accuracy: 0.7812 - loss: 0.6281 - val_accuracy: 0.8154 - val_loss: 0.5430 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m4651/4651\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 25ms/step - accuracy: 0.7839 - loss: 0.6173 - val_accuracy: 0.8375 - val_loss: 0.4696 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m4651/4651\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 26ms/step - accuracy: 0.7828 - loss: 0.6162 - val_accuracy: 0.8357 - val_loss: 0.4625 - learning_rate: 0.0010\n",
      "Epoch 6/20\n",
      "\u001b[1m4651/4651\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 20ms/step - accuracy: 0.7816 - loss: 0.6120 - val_accuracy: 0.8419 - val_loss: 0.4695 - learning_rate: 0.0010\n",
      "Epoch 7/20\n",
      "\u001b[1m4651/4651\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 22ms/step - accuracy: 0.7803 - loss: 0.6115 - val_accuracy: 0.8254 - val_loss: 0.4672 - learning_rate: 0.0010\n",
      "Epoch 8/20\n",
      "\u001b[1m4651/4651\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 20ms/step - accuracy: 0.7852 - loss: 0.6031 - val_accuracy: 0.8088 - val_loss: 0.5083 - learning_rate: 0.0010\n",
      "Epoch 9/20\n",
      "\u001b[1m4651/4651\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 22ms/step - accuracy: 0.7962 - loss: 0.5719 - val_accuracy: 0.8443 - val_loss: 0.4251 - learning_rate: 2.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m4651/4651\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 22ms/step - accuracy: 0.7966 - loss: 0.5652 - val_accuracy: 0.8514 - val_loss: 0.4227 - learning_rate: 2.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m4651/4651\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 25ms/step - accuracy: 0.7960 - loss: 0.5656 - val_accuracy: 0.8385 - val_loss: 0.4425 - learning_rate: 2.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m4651/4651\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 21ms/step - accuracy: 0.7987 - loss: 0.5607 - val_accuracy: 0.8552 - val_loss: 0.4182 - learning_rate: 2.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m4651/4651\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 22ms/step - accuracy: 0.7958 - loss: 0.5628 - val_accuracy: 0.8302 - val_loss: 0.4642 - learning_rate: 2.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m4651/4651\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 23ms/step - accuracy: 0.7954 - loss: 0.5615 - val_accuracy: 0.8360 - val_loss: 0.4327 - learning_rate: 2.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m4651/4651\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 22ms/step - accuracy: 0.7968 - loss: 0.5599 - val_accuracy: 0.8419 - val_loss: 0.4272 - learning_rate: 2.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m4651/4651\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 23ms/step - accuracy: 0.8022 - loss: 0.5504 - val_accuracy: 0.8388 - val_loss: 0.4308 - learning_rate: 4.0000e-05\n",
      "Epoch 17/20\n",
      "\u001b[1m4651/4651\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 23ms/step - accuracy: 0.7999 - loss: 0.5499 - val_accuracy: 0.8367 - val_loss: 0.4325 - learning_rate: 4.0000e-05\n",
      "\u001b[1m2907/2907\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - accuracy: 0.8537 - loss: 0.4253\n",
      "Test Loss: 0.42676499485969543, Test Accuracy: 0.8518299460411072\n"
     ]
    }
   ],
   "source": [
    "# Cell 6\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Standardizing the features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "scaler_path = './saved_models/scaler.save'\n",
    "joblib.dump(scaler, scaler_path)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features_scaled, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "# Defining the model parameters\n",
    "num_classes = 4\n",
    "embed_dim = 32  # Increased embedding dimension\n",
    "num_heads = 4    # Increased number of attention heads\n",
    "ff_dim = 32    # Increased feedforward dimension\n",
    "num_layers = 1   # Increased number of transformer layers\n",
    "\n",
    "# Creating the Transformer model\n",
    "model = TransformerClassifier(num_classes, embed_dim, num_heads, ff_dim, num_layers)\n",
    "\n",
    "# Compile with modified learning rate and added metrics\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001, clipnorm=1.0),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks for training\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    min_lr=0.00001\n",
    ")\n",
    "\n",
    "# ModelCheckpoint callback to save the model at the end of each epoch\n",
    "save_directory = './saved_models/'\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=os.path.join(save_directory, 'emotion_classifier_epoch_{epoch:02d}.keras'),\n",
    "    save_freq='epoch',\n",
    "    save_best_only=False  # Change to True if only the best model should be saved\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, reduce_lr, checkpoint_callback],\n",
    "    class_weight={\n",
    "        0: 1.0,  # Normal\n",
    "        1: 1.0,  # Depression\n",
    "        2: 1.0,  # Anxiety\n",
    "        3: 1.0   # Stress\n",
    "    }\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5418/5418\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApoAAAIjCAYAAACjybtCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAACZw0lEQVR4nOzddVhU2RsH8O+AMHS3oqgoirmiInagqNi65ip2LCau3bUodmAH2N2BIgaroiIKdqOoSIso0szvD37OOgsqIJdB5/vZZ56HOffcc987LPjy3nPPFUkkEgmIiIiIiAqYkrwDICIiIqJfExNNIiIiIhIEE00iIiIiEgQTTSIiIiISBBNNIiIiIhIEE00iIiIiEgQTTSIiIiISBBNNIiIiIhIEE00iIiIiEgQTTSL6pidPnqBFixbQ1dWFSCTC4cOHC3T8Fy9eQCQSwcvLq0DH/Zk1btwYjRs3lncYREQ/jIkm0U/g2bNnGDJkCMqUKQM1NTXo6OigXr16WL58OZKSkgQ9touLC+7cuYN58+Zh27ZtqFmzpqDHK0x9+/aFSCSCjo5Ojp/jkydPIBKJIBKJsGjRojyPHx4ejpkzZyI4OLgAoiUi+vkUk3cARPRtJ06cwO+//w6xWIw+ffqgcuXKSE1NxaVLlzBu3Djcu3cP69evF+TYSUlJCAgIwJQpUzB8+HBBjlGqVCkkJSVBRUVFkPG/p1ixYvj06ROOHTuGrl27ymzbsWMH1NTUkJycnK+xw8PDMWvWLFhZWaF69eq53u/MmTP5Oh4RUVHDRJOoCAsNDUX37t1RqlQpnDt3Dubm5tJtrq6uePr0KU6cOCHY8aOjowEAenp6gh1DJBJBTU1NsPG/RywWo169eti1a1e2RHPnzp1wdnbGgQMHCiWWT58+QUNDA6qqqoVyPCIiofHSOVER5uHhgY8fP2LTpk0ySeZn1tbWGDVqlPR9eno65syZg7Jly0IsFsPKygqTJ09GSkqKzH5WVlZo06YNLl26hNq1a0NNTQ1lypTB1q1bpX1mzpyJUqVKAQDGjRsHkUgEKysrAFmXnD9//aWZM2dCJBLJtPn6+qJ+/frQ09ODlpYWbGxsMHnyZOn2r83RPHfuHBo0aABNTU3o6emhffv2ePDgQY7He/r0Kfr27Qs9PT3o6uqiX79++PTp09c/2P/o2bMnTp06hfj4eGlbYGAgnjx5gp49e2brHxcXh7/++gtVqlSBlpYWdHR00KpVK4SEhEj7XLhwAbVq1QIA9OvXT3oJ/vN5Nm7cGJUrV0ZQUBAaNmwIDQ0N6efy3zmaLi4uUFNTy3b+Tk5O0NfXR3h4eK7PlYioMDHRJCrCjh07hjJlyqBu3bq56j9w4EBMnz4dNWrUwNKlS9GoUSO4u7uje/fu2fo+ffoUXbp0QfPmzbF48WLo6+ujb9++uHfvHgCgU6dOWLp0KQCgR48e2LZtG5YtW5an+O/du4c2bdogJSUFs2fPxuLFi9GuXTtcvnz5m/udPXsWTk5OiIqKwsyZM+Hm5oYrV66gXr16ePHiRbb+Xbt2xYcPH+Du7o6uXbvCy8sLs2bNynWcnTp1gkgkwsGDB6VtO3fuRIUKFVCjRo1s/Z8/f47Dhw+jTZs2WLJkCcaNG4c7d+6gUaNG0qSvYsWKmD17NgBg8ODB2LZtG7Zt24aGDRtKx4mNjUWrVq1QvXp1LFu2DE2aNMkxvuXLl8PY2BguLi7IyMgAAKxbtw5nzpzBypUrYWFhketzJSIqVBIiKpLev38vASBp3759rvoHBwdLAEgGDhwo0/7XX39JAEjOnTsnbStVqpQEgMTf31/aFhUVJRGLxZKxY8dK20JDQyUAJAsXLpQZ08XFRVKqVKlsMcyYMUPy5a+VpUuXSgBIoqOjvxr352Ns2bJF2la9enWJiYmJJDY2VtoWEhIiUVJSkvTp0yfb8fr37y8zZseOHSWGhoZfPeaX56GpqSmRSCSSLl26SJo1ayaRSCSSjIwMiZmZmWTWrFk5fgbJycmSjIyMbOchFosls2fPlrYFBgZmO7fPGjVqJAEgWbt2bY7bGjVqJNN2+vRpCQDJ3LlzJc+fP5doaWlJOnTo8N1zJCKSJ1Y0iYqohIQEAIC2tnau+p88eRIA4ObmJtM+duxYAMg2l9PW1hYNGjSQvjc2NoaNjQ2eP3+e75j/6/PcziNHjiAzMzNX+7x9+xbBwcHo27cvDAwMpO1Vq1ZF8+bNpef5paFDh8q8b9CgAWJjY6WfYW707NkTFy5cQEREBM6dO4eIiIgcL5sDWfM6lZSyfn1mZGQgNjZWOi3g5s2buT6mWCxGv379ctW3RYsWGDJkCGbPno1OnTpBTU0N69aty/WxiIjkgYkmURGlo6MDAPjw4UOu+r98+RJKSkqwtraWaTczM4Oenh5evnwp016yZMlsY+jr6+Pdu3f5jDi7bt26oV69ehg4cCBMTU3RvXt37N2795tJ5+c4bWxssm2rWLEiYmJikJiYKNP+33PR19cHgDydS+vWraGtrY09e/Zgx44dqFWrVrbP8rPMzEwsXboU5cqVg1gshpGREYyNjXH79m28f/8+18csXrx4nm78WbRoEQwMDBAcHIwVK1bAxMQk1/sSEckDE02iIkpHRwcWFha4e/dunvb77804X6OsrJxju0QiyfcxPs8f/ExdXR3+/v44e/Ysevfujdu3b6Nbt25o3rx5tr4/4kfO5TOxWIxOnTrB29sbhw4d+mo1EwD+/vtvuLm5oWHDhti+fTtOnz4NX19fVKpUKdeVWyDr88mLW7duISoqCgBw586dPO1LRCQPTDSJirA2bdrg2bNnCAgI+G7fUqVKITMzE0+ePJFpj4yMRHx8vPQO8oKgr68vc4f2Z/+tmgKAkpISmjVrhiVLluD+/fuYN28ezp07h/Pnz+c49uc4Hz16lG3bw4cPYWRkBE1NzR87ga/o2bMnbt26hQ8fPuR4A9Vn+/fvR5MmTbBp0yZ0794dLVq0gKOjY7bPJLdJf24kJiaiX79+sLW1xeDBg+Hh4YHAwMACG5+ISAhMNImKsPHjx0NTUxMDBw5EZGRktu3Pnj3D8uXLAWRd+gWQ7c7wJUuWAACcnZ0LLK6yZcvi/fv3uH37trTt7du3OHTokEy/uLi4bPt+Xrj8v0sufWZubo7q1avD29tbJnG7e/cuzpw5Iz1PITRp0gRz5szBqlWrYGZm9tV+ysrK2aql+/btw5s3b2TaPifEOSXleTVhwgSEhYXB29sbS5YsgZWVFVxcXL76ORIRFQVcsJ2oCCtbtix27tyJbt26oWLFijJPBrpy5Qr27duHvn37AgCqVasGFxcXrF+/HvHx8WjUqBGuX78Ob29vdOjQ4atL5+RH9+7dMWHCBHTs2BEjR47Ep0+fsGbNGpQvX17mZpjZs2fD398fzs7OKFWqFKKiorB69WqUKFEC9evX/+r4CxcuRKtWreDg4IABAwYgKSkJK1euhK6uLmbOnFlg5/FfSkpKmDp16nf7tWnTBrNnz0a/fv1Qt25d3LlzBzt27ECZMmVk+pUtWxZ6enpYu3YttLW1oampCXt7e5QuXTpPcZ07dw6rV6/GjBkzpMstbdmyBY0bN8a0adPg4eGRp/GIiAoLK5pERVy7du1w+/ZtdOnSBUeOHIGrqysmTpyIFy9eYPHixVixYoW078aNGzFr1iwEBgZi9OjROHfuHCZNmoTdu3cXaEyGhoY4dOgQNDQ0MH78eHh7e8Pd3R1t27bNFnvJkiWxefNmuLq6wtPTEw0bNsS5c+egq6v71fEdHR3h4+MDQ0NDTJ8+HYsWLUKdOnVw+fLlPCdpQpg8eTLGjh2L06dPY9SoUbh58yZOnDgBS0tLmX4qKirw9vaGsrIyhg4dih49euDixYt5OtaHDx/Qv39//Pbbb5gyZYq0vUGDBhg1ahQWL16Mq1evFsh5EREVNJEkL7PliYiIiIhyiRVNIiIiIhIEE00iIiIiEgQTTSIiIiISBBNNIiIiIhIEE00iIiIiEgQTTSIiIiISBBNNIiIiIhLEL/lkIPWWS+QdAhWiqCOj5R0CFaKrz7M/1pJ+XbWs9OUdAhUiPXVluR1b/bfhgo2ddGuVYGMXdaxoEhEREZEgfsmKJhEREVGeiFh7EwITTSIiIiKRSN4R/JKYvhMRERGRIJhoEhEREYmUhHvlwcyZMyESiWReFSpUkG5PTk6Gq6srDA0NoaWlhc6dOyMyMlJmjLCwMDg7O0NDQwMmJiYYN24c0tPTZfpcuHABNWrUgFgshrW1Nby8vLLF4unpCSsrK6ipqcHe3h7Xr1/P07kATDSJiIiIipRKlSrh7du30telS5ek28aMGYNjx45h3759uHjxIsLDw9GpUyfp9oyMDDg7OyM1NRVXrlyBt7c3vLy8MH36dGmf0NBQODs7o0mTJggODsbo0aMxcOBAnD59Wtpnz549cHNzw4wZM3Dz5k1Uq1YNTk5OiIqKytO5iCQSieQHPosiicsbKRYub6RYuLyRYuHyRopFrssb1XITbOykwNznJTNnzsThw4cRHBycbdv79+9hbGyMnTt3okuXLgCAhw8fomLFiggICECdOnVw6tQptGnTBuHh4TA1NQUArF27FhMmTEB0dDRUVVUxYcIEnDhxAnfv3pWO3b17d8THx8PHxwcAYG9vj1q1amHVqqylmTIzM2FpaYkRI0Zg4sSJuT4fVjSJiIiIBJSSkoKEhASZV0pKylf7P3nyBBYWFihTpgx69eqFsLAwAEBQUBDS0tLg6Ogo7VuhQgWULFkSAQEBAICAgABUqVJFmmQCgJOTExISEnDv3j1pny/H+Nzn8xipqakICgqS6aOkpARHR0dpn9xioklEREQk4BxNd3d36Orqyrzc3d1zDMPe3h5eXl7w8fHBmjVrEBoaigYNGuDDhw+IiIiAqqoq9PT0ZPYxNTVFREQEACAiIkImyfy8/fO2b/VJSEhAUlISYmJikJGRkWOfz2PkFpc3IiIiIhLQpEmT4OYme2leLBbn2LdVq1bSr6tWrQp7e3uUKlUKe/fuhbq6uqBxCoEVTSIiIiKRSLCXWCyGjo6OzOtrieZ/6enpoXz58nj69CnMzMyQmpqK+Ph4mT6RkZEwMzMDAJiZmWW7C/3z++/10dHRgbq6OoyMjKCsrJxjn89j5BYTTSIiIqIisrzRf338+BHPnj2Dubk57OzsoKKiAj8/P+n2R48eISwsDA4ODgAABwcH3LlzR+bucF9fX+jo6MDW1lba58sxPvf5PIaqqirs7Oxk+mRmZsLPz0/aJ7eYaBIREREVEX/99RcuXryIFy9e4MqVK+jYsSOUlZXRo0cP6OrqYsCAAXBzc8P58+cRFBSEfv36wcHBAXXq1AEAtGjRAra2tujduzdCQkJw+vRpTJ06Fa6urtIq6tChQ/H8+XOMHz8eDx8+xOrVq7F3716MGTNGGoebmxs2bNgAb29vPHjwAMOGDUNiYiL69euXp/PhHE0iIiKiIvIIytevX6NHjx6IjY2FsbEx6tevj6tXr8LY2BgAsHTpUigpKaFz585ISUmBk5MTVq9eLd1fWVkZx48fx7Bhw+Dg4ABNTU24uLhg9uzZ0j6lS5fGiRMnMGbMGCxfvhwlSpTAxo0b4eTkJO3TrVs3REdHY/r06YiIiED16tXh4+OT7Qah7+E6mvTT4zqaioXraCoWrqOpWOS6jqZD7teGzKukgPmCjV3UsaJJRERE9INzKSln/FSJiIiISBCsaBIREREVkTmavxpWNImIiIhIEKxoEhEREXGOpiCYaBIRERHx0rkgmL4TERERkSBY0SQiIiLipXNB8FMlIiIiIkGwoklERETEiqYg+KkSERERkSBY0SQiIiJS4l3nQmBFk4iIiIgEwYomEREREedoCoKJJhEREREXbBcE03ciIiIiEgQrmkRERES8dC4IfqpEREREJAhWNImIiIg4R1MQrGgSERERkSDkVtFMSEjIdV8dHR0BIyEiIiKFxzmagpBboqmnpwfRd8rUEokEIpEIGRkZhRQVERERERUUuSWa58+fl9ehiYiIiGRxjqYg5JZoNmrUSF6HJiIiIpLFS+eCKFJ3nX/69AlhYWFITU2Vaa9ataqcIiIiIiKi/CoSiWZ0dDT69euHU6dO5bidczSJiIhIULx0LogiUScePXo04uPjce3aNairq8PHxwfe3t4oV64cjh49Ku/wiIiIiCgfikRF89y5czhy5Ahq1qwJJSUllCpVCs2bN4eOjg7c3d3h7Ows7xCJiIjoV8Y5moIoEp9qYmIiTExMAAD6+vqIjo4GAFSpUgU3b96UZ2hERERElE9FItG0sbHBo0ePAADVqlXDunXr8ObNG6xduxbm5uZyjo6IiIh+eSKRcC8FViQunY8aNQpv374FAMyYMQMtW7bEjh07oKqqCi8vL/kGR0RERET5UiQSzT/++EP6tZ2dHV6+fImHDx+iZMmSMDIykmNkREREpBA4R1MQRSLR/C8NDQ3UqFFD3mEQERGRomCiKYgikWhKJBLs378f58+fR1RUFDIzM2W2Hzx4UE6REREREVF+FYlEc/To0Vi3bh2aNGkCU1NTiBR84iwREREVMuYegigSiea2bdtw8OBBtG7dWt6hEBEREVEBKRKJpq6uLsqUKSPvMOTqr661MKd/A6w6dBPj1l2QtttXNMdMl3qoVcEcGRmZuP08Gm2nHERyarrM/qoqyvBf1gPVyprA/s9tuP08ay3SKX84YOofDtmOl5icBqMOKwEAxZSVMK5bbfzhaAsLIy08fv0OUzf9A9+gF4KdLwE3bwRim9dmPHhwDzHR0Vi0bCUaN3UEAKSnpWH1quW4/I8/3rx+DS1tLdS2d8CI0WNh/P81Z28EXsfQAS45ju29cy8qVa4CAPA9fQpbNq7Hy5cvoK+vj67de6FPvwGFc5IK7Om9YJw9tBNhzx4i4V0sBk10R7U6DXPsu2uNBy6fPoLO/UeiSbtuAIDHd25ixbQROfYft3AjSpWriNjIt5gxpEu27WMXrENpm8oAgMtnjuL6+VMIDwsFAJQsa4O2fwyBVXnbgjhN+opbQTew3XszHv7/59tjyQo0+v/PNwDExsbAc9kSXLt6GR8+fMBvNWpi7ITJKFnKStrn9aswrFiyECHBN5GamgqHuvUxduIUGBr+e5Ns2MsXWLF0IW4H30JaWhqsy9lgiOsI1KxlX5in+2vgHE1BFIlEc+bMmZg1axY2b94MdXV1eYdT6OzKm2JA66rS5PAz+4rmODK3ExbtuQ63NeeRnpGJqqWNkSmRZBvj7wEN8DY2EdXKyrYv238DG0+EyLSdnN8FQY8jpe9nutRDj6YV8edyXzx6FYfmdqWwZ3o7NHHbhZBnsjFRwUlKSkI5Gxu069gJ48aMlNmWnJyMhw/uY+CQYShXvgI+JLzHogXucBv5J7bt3g8AqFa9OnzO+cvst3bVCgReuwrbSv9PMv7xx9RJ4zFu4hTUqVsPL54/w9xZ0yFWU0O3Hr0K50QVVEpyEoqXtoaDozM2zJ/81X4hVy/ixaN70DWQXWGjTIUq+HuL7CN4j+/cgEe3g1DSuoJM+4hZy2FesrT0vaa2rvTrJ3dvwq5Bc/xeoTKKqYrhe3A7PGeOwZSV26FnaPwjp0jfkJT0CeXK26Bth06Y4Cb78y2RSDB+zAgUK1YMC5eugqaWFnZu88KIoQOw++AxqKtrICnpE0YOG4Ry5W3guX4LAGCd5wr8NdIVm7btgpJSVlLkNmIYLEuWguf6LRCLxdi9YxvGjvgTB4/7wNCI31+SvyKRaHbt2hW7du2CiYkJrKysoKKiIrP9V346kKaaCraMb40/l/tiYg/Zv0A9BjfG6iO3sGhvoLTtyet32cZoUdMKzWqUQo+5x9CydmmZbYnJaUhMTpO+r1LaCLaljDByhZ+0rWeziliw+xpOB2ZVPDacuI2mv5XCqM410d/jVIGcJ2VXr0FD1GuQc4VLS1sbq9dvlmkbP3kqXHp2RcTbcJiZW0BFRRVGX/xDkp6Whovnz6Fbz17Sec4njx9F4ybN0KVrdwBAiRKW6DtgMLZu3oiu3XtyPrSAKtk5oJJd9qsJX4qPjca+DUvhOmMJ1swZJ7OtmIoKdPQNpe8z0tNx+/o/aNS6S7bvm6a2jkzfL/V1mynzvpfrRIQEXMCj2zdg36RV7k+I8qRu/YaoWz/nn+9XYS9x93YIdu0/gjLW5QAAE6bMQOtmDXHm1Em079QFIbdu4W34G2zdfQBaWloAgBlz3OHYsA5uXL+K2nXqIv7dO7wKe4kpM+egXHkbAIDrKDcc2LsLz54+YaKZV/x9KIgikWi6uLggKCgIf/zxh8LdDLTMtSl8rj/H+VthMommsa46alc0x+7zD3B+SXeUNtfF41fvMNP7Eq7cC5f2M9HTwOpRzdF19lF8SknP6RAy+rWsgsev43D53htpm6qKMpJTM2T6JaWmo24liwI4QyooHz9+gEgkgpa2To7bL144j/fv49G2fSdpW2pqKtTU1WT6qYnFiIyMwNvwcFgULy5ozPR1mZmZ2LpsNpp16Anzkt+fOnT7+j9I/JCAOs2cs21b9/dEpKWlwMSiJBw79kTV2g2+Ok5qajIyMtKhoZXz/0ckvNTUVACAqlgsbVNSUoKKqipCbt1E+05dkJaWCpFIBFVVVWkfVbEYSkpKCLl1E7Xr1IWunh5KWZXGqWNHUaGiLVRUVHFo/x7oGxiigm2lQj8vopwUiUTzxIkTOH36NOrXr5/nfVNSUpCSkiLTJslMh0ipSJzaN/3eyAbVrU1Rf+SObNtKm+sByJpjOWmDP24/j0KvZrY46d4FdkO34ll4PABg/VgnbDh5GzefRKKk6bf/4RCrKKNb04pYvOe6TPvZoJcY2akGLt15jedv49Gkekm0r2sNZSXFSfiLupSUFKxcuhhOrZyl1Y3/OnJoP+rUrQdTMzNpm0O9+ljiMR/X2wWgZm17vAp7ie1bvQAAMTFRTDTlyPfgdigpKaNxm99z1T/g7HFUrF4b+kYm0jaxujo69huBshWrQCRSQnDABWxwn4RBk9y/mmwe8V4DXX0jVKhWs0DOg/LOyqo0zMzNsXrFUkycNhPq6urYtX0roiIjEBOTNV2pcpVqUFNXx6pli/HniNGQQALP5UuQkZEh7SMSibBy3SaMHzMCTerWgpKSEvQNDLB89Tro6Oh+KwTKCedoCqJIfKqWlpbQ0cnfX9fu7u7Q1dWVeaU/9/v+jnJWwkgLC4c2Rj+Pk0hJy8i2/XOOt+nkbWzzvYeQZ9EYv/4iHr95BxenrPl3f7b/Ddoaqlj4n8Txa9rXs4a2ugq2n70v0/7X2vN49iYeIRv6IuH4aCx1bYqtvveQmX0qKMlBeloaJv41BhKJBBOnzsixT2REBK5euYz2HWVvDOnY+Xd07dETY0YMg4NdVfT7owdatMxa3UGJv1TlJuzpQ1w4vg9/jJqSqys472Ki8CD4Ohwc28i0a+nooVn77rAqXwmlylVE+z7DUKuRE/wO7cxxnDMHtiHo0lkMmuQOFVVxjn1IeMVUVDB/8QqEvXyB5g0d0KiOHYICr8OhXgMo/f+Xv76BAf72WIpL/hfQuG5NNKtvjw8fPsCmoq10fqZEIsFC9znQ1zfAus3bsHn7HjRq3AxjR7oiJprz6/OMzzoXRJEo+y1evBjjx4/H2rVrYWVllad9J02aBDc3N5k2ky5rCzA6YfxWzhSm+poIWPXv4zeLKSuhfuUSGNquOqoOzJr8/SAsTma/R2FxsDTWBgA0rmYJ+wrmeH9slEyfyyt7Yfe5Bxi0+LRMe1+nKjh1LRRR8Z9k2mPeJ6Hr7KMQqyjDUEcd4bEfMbd/A4RGxBfU6VI+paelYeK4MYh4G441G7d8tZp57MhB6OrqoVHjJjLtIpEII8f8BdeRYxAbEwN9A31cv3oVAFC8hKXg8VPOnt0Pwcf37zB9YGdpW2ZmBg56rcL5Y3sxe8MBmf5X/U5AU1vnm5fEPytV3hYPQwKztZ89vBO+B7Zj+OxlKG5l/eMnQT+kom0lbN97CB8/fEBaWhr0DQzQ/49uqGBbWdqnTt16OHj8NOLfvYOysjK0dXTQqlkDWBTPmlt74/pVXPa/CF//q9LfDRWmTMe1q1dw4thhuPQfJJdzI/pSkUg0//jjD3z69Ally5aFhoZGtpuB4uLivrInIBaLIRbL/mX+M1w2Px8cBrsh3jJt68c64dGrOCzeG4jQt+8RHvMR5Uvoy/SxLq6PMzeybtoZu+Y8Znpflm4zN9TC8b87o/ffJxD46K3MfqVMddComiW6zDz81ZhS0jIQHvsRxZSV0KF+ORzwf/SDZ0k/4nOSGfbyJdZt8oaenn6O/SQSCY4dPgTntu1R7D8/O58pKyvDxNQUAHD61AlUrVYd+gYGgsVO31arcUvYVKsl0+Y5awxqN26JOs1k1xOWSCS4eu4kajduBeVi3//d9ib0SbYbg3wP7sDp/d5wnbEEpawr/vgJUIHR0s4qHIS9fIEH9+9h8J8js/XR08/62b9x/SrexcWhYeOmALJWpwAgrYJ+pqSkBMl/nrBH36dI94cUpiKRkS1btkzeIRS6j0lpuP8yVqYtMTkNcQnJ0val+wMxtXdd3HkejZBn0fijuS1sLA3Qc94xAMCr6A+yY/7/7vLnb+PxJuajzDYXp8qIiEvE6RsvssVSy8YMFkZaCHkWjeKGWpjyhwOURMCSfTcK6nQpB58+JeJVWJj0/Zs3r/Ho4QPo6urCyMgY48eOxqMH97F01RpkZP47L0tXVxcqKv/eIBB47SrevHmNDp2zr6cY/+4dzvqeRs1atZGSkoJjhw/Bz/c01m3eKvwJKriUpE+Ifvta+j42Khyvnz+GhrYODIzNoPWfOXTKysWgo2cA0+KlZNof3w5CbGQ46jZvm+0YV8+dRLFiKihRpjwAICTgAgL8TqCn60RpH9+D23Fi50a4uM2AoYk5Et5l/X4Rq6lDrK5RYOdLsj59SsTrL36+w9+8weOHD6Cjqwszcwv4nfGBnr4BzMzN8fTJYyz1cEfDJs1Qp2496T7HDh+EVZmy0NfXx53bwVji4Y4ef/RBKaus1UWqVK0ObR0dzJo2GQMGD4OamhoOH9iH8DevUbdBo0I/Z6KcyD3RTEtLw8WLFzFt2jSULl36+zsokFWHb0FNtRg8hjSGvrYa7jyPRpvJ+xH69n2exhGJgN7NK2Gb7z1k5jDxUqxaDDP61ENpc118TErD6cBQDFh4Cu8TU3IYjQrK/Xv3ZBZcX7pwAQCgTbsOGDxsOPwvnAMA9Py9o8x+azd5o2at2tL3Rw4dQNXqv8GqdM53Lp84ehjLFy+ERCJB1WrVsG6TNypXqVrQp0P/8fLpQ5kF1w9uznpAgn2TVug9amqux7ly9jjKVKgCsxKlctzus9cLcdERUFJWhmnxUuj/12z8VvffKRT/nDqE9PQ0bPKQPWarbv3h3IML9wvlwb17+HNQX+n7ZYuzfr6d23bA9Dl/IyYmGssWeyAuNgZGxsZo1aY9BgweKjNG2MsXWL1yKRLev4e5RXH0GzgEPf7493eGnr4+lnuux5pVy+E6uB/S09NRpqw1Fi5bhfI2smut0vexoikMkUSSw+rfhUxXVxfBwcEFlmiqt1xSIOPQzyHqyGh5h0CF6Orzr0+loV9PLaucp4zQr0lPXVlux9bsskWwsRP39xNs7KKuSNx22qFDBxw+fFjeYRAREZGiEgn4UmByv3QOAOXKlcPs2bNx+fJl2NnZQVNTU2b7yJHZJ0cTERERUdFWJBLNTZs2QU9PD0FBQQgKCpLZJhKJmGgSERGRoDhHUxhFItEMDQ2VdwhERESkwJhoCqNIzNH8kkQiQRG4P4mIiIiIflCRSTS3bt2KKlWqQF1dHerq6qhatSq2bdsm77CIiIhIAYhEIsFeiqxIXDpfsmQJpk2bhuHDh6NevazFai9duoShQ4ciJiYGY8aMkXOERERERJRXRSLRXLlyJdasWYM+ffpI29q1a4dKlSph5syZTDSJiIhIUIpeeRRKkbh0/vbtW9StWzdbe926dfH27dsc9iAiIiKioq5IJJrW1tbYu3dvtvY9e/agXLlycoiIiIiIFAoXbBdEkbh0PmvWLHTr1g3+/v7SOZqXL1+Gn59fjgkoERERERV9RSLR7Ny5M65du4YlS5ZIH0VZsWJFXL9+Hb/99pt8gyMiIqJfHudoCqNIJJoAYGdnhx07dsg7DCIiIiIqIHJNNJWUlL77F4RIJEJ6enohRURERESKiBVNYcg10Tx06NBXtwUEBGDFihXIzMwsxIiIiIhIETHRFIZcE8327dtna3v06BEmTpyIY8eOoVevXpg9e7YcIiMiIiKiH1UkljcCgPDwcAwaNAhVqlRBeno6goOD4e3tjVKlSsk7NCIiIvrF8RGUwpB7ovn+/XtMmDAB1tbWuHfvHvz8/HDs2DFUrlxZ3qERERER0Q+Q66VzDw8PLFiwAGZmZti1a1eOl9KJiIiIBKfYhUfByDXRnDhxItTV1WFtbQ1vb294e3vn2O/gwYOFHBkRERER/Si5Jpp9+vRR+LkLREREJH/MR4Qh10TTy8tLnocnIiIiIgEVmScDEREREckLK5rCYKJJRERECo+JpjDkvrwREREREf2aWNEkIiIiYkFTEKxoEhEREZEgWNEkIiIihcc5msJgRZOIiIiIBMGKJhERESk8VjSFwYomEREREQmCFU0iIiJSeKxoCoOJJhERESk8JprC4KVzIiIioiJq/vz5EIlEGD16tLQtOTkZrq6uMDQ0hJaWFjp37ozIyEiZ/cLCwuDs7AwNDQ2YmJhg3LhxSE9Pl+lz4cIF1KhRA2KxGNbW1vDy8sp2fE9PT1hZWUFNTQ329va4fv16nuJnoklEREQkEvCVT4GBgVi3bh2qVq0q0z5mzBgcO3YM+/btw8WLFxEeHo5OnTpJt2dkZMDZ2Rmpqam4cuUKvL294eXlhenTp0v7hIaGwtnZGU2aNEFwcDBGjx6NgQMH4vTp09I+e/bsgZubG2bMmIGbN2+iWrVqcHJyQlRUVK7PgYkmERERURHz8eNH9OrVCxs2bIC+vr60/f3799i0aROWLFmCpk2bws7ODlu2bMGVK1dw9epVAMCZM2dw//59bN++HdWrV0erVq0wZ84ceHp6IjU1FQCwdu1alC5dGosXL0bFihUxfPhwdOnSBUuXLpUea8mSJRg0aBD69esHW1tbrF27FhoaGti8eXOuz4OJJhERESk8kUgk2CslJQUJCQkyr5SUlG/G4+rqCmdnZzg6Osq0BwUFIS0tTaa9QoUKKFmyJAICAgAAAQEBqFKlCkxNTaV9nJyckJCQgHv37kn7/HdsJycn6RipqakICgqS6aOkpARHR0dpn9xgoklEREQkIHd3d+jq6sq83N3dv9p/9+7duHnzZo59IiIioKqqCj09PZl2U1NTRERESPt8mWR+3v5527f6JCQkICkpCTExMcjIyMixz+cxcoN3nRMREZHCE/Ku80mTJsHNzU2mTSwW59j31atXGDVqFHx9faGmpiZYTIWFFU0iIiIiAYnFYujo6Mi8vpZoBgUFISoqCjVq1ECxYsVQrFgxXLx4EStWrECxYsVgamqK1NRUxMfHy+wXGRkJMzMzAICZmVm2u9A/v/9eHx0dHairq8PIyAjKyso59vk8Rm4w0SQiIiKFJ+Qczbxo1qwZ7ty5g+DgYOmrZs2a6NWrl/RrFRUV+Pn5Sfd59OgRwsLC4ODgAABwcHDAnTt3ZO4O9/X1hY6ODmxtbaV9vhzjc5/PY6iqqsLOzk6mT2ZmJvz8/KR9coOXzomIiIiKyHrt2traqFy5skybpqYmDA0Npe0DBgyAm5sbDAwMoKOjgxEjRsDBwQF16tQBALRo0QK2trbo3bs3PDw8EBERgalTp8LV1VVaSR06dChWrVqF8ePHo3///jh37hz27t2LEydOSI/r5uYGFxcX1KxZE7Vr18ayZcuQmJiIfv365fp8mGgSERER/USWLl0KJSUldO7cGSkpKXBycsLq1aul25WVlXH8+HEMGzYMDg4O0NTUhIuLC2bPni3tU7p0aZw4cQJjxozB8uXLUaJECWzcuBFOTk7SPt26dUN0dDSmT5+OiIgIVK9eHT4+PtluEPoWkUQikRTMaRcd6i2XyDsEKkRRR0bLOwQqRFefx8k7BCpEtaz0v9+Jfhl66spyO3bJEUcFGztsZTvBxi7qOEeTiIiIiATBS+dERESk8IRc3kiRsaJJRERERIJgRZOIiIgUHiuawmBFk4iIiIgEwYomERERKTxWNIXBRJOIiIiIeaYgeOmciIiIiATxS1Y0Y4+OkXcIVIjuv/kg7xCoEFW20JF3CFSI1FTkt4A3KRZeOhcGK5pEREREJIhfsqJJRERElBesaAqDFU0iIiIiEgQrmkRERKTwWNAUBiuaRERERCQIVjSJiIhI4XGOpjCYaBIREZHCY54pDF46JyIiIiJBsKJJRERECo+XzoXBiiYRERERCYIVTSIiIlJ4LGgKgxVNIiIiIhIEK5pERESk8JSUWNIUAiuaRERERCQIVjSJiIhI4XGOpjCYaBIREZHC4/JGwuClcyIiIiISBCuaREREpPBY0BQGK5pEREREJAhWNImIiEjhcY6mMFjRJCIiIiJBsKJJRERECo8VTWEUmUQzPj4e169fR1RUFDIzM2W29enTR05REREREVF+FYlE89ixY+jVqxc+fvwIHR0dmb8qRCIRE00iIiISFAuawigSczTHjh2L/v374+PHj4iPj8e7d++kr7i4OHmHR0RERL84kUgk2EuRFYlE882bNxg5ciQ0NDTkHQoRERERFZAikWg6OTnhxo0b8g6DiIiIFJRIJNxLkRWJOZrOzs4YN24c7t+/jypVqkBFRUVme7t27eQUGRERERHlV5FINAcNGgQAmD17drZtIpEIGRkZhR0SERERKRBFn0splCKRaP53OSMiIiIi+vkViUSTiIiISJ5Y0BRGkbgZCAAuXryItm3bwtraGtbW1mjXrh3++ecfeYdFRERERPlUJBLN7du3w9HRERoaGhg5ciRGjhwJdXV1NGvWDDt37pR3eERERPSL4zqawhBJJBKJvIOoWLEiBg8ejDFjxsi0L1myBBs2bMCDBw/yNN6nVLmfEhWi+28+yDsEKkTFDdTkHQIVIn1NVXmHQIVITY4T+mrNuyDY2IFTGgs2dlFXJCqaz58/R9u2bbO1t2vXDqGhoXKIiIiIiBQJ19EURpFINC0tLeHn55et/ezZs7C0tJRDRERERKRIeOlcGEXirvOxY8di5MiRCA4ORt26dQEAly9fhpeXF5YvXy7n6IiIiIgoP4pEojls2DCYmZlh8eLF2Lt3L4CseZt79uxB+/bt5RwdERER/eoUvPAomCKRaAJAx44d0bFjR3mHQUREREQFpMgkmkRERETyouhzKYUit0TTwMAAjx8/hpGREfT19b/5DY6LiyvEyIiIiIioIMgt0Vy6dCm0tbWlX/MvCSIiIpIXpiHCkFui6eLiIv26b9++8gqDiIiIiARSJNbRvHnzJu7cuSN9f+TIEXTo0AGTJ09GamqqHCMjIiIiRcB1NIVRJBLNIUOG4PHjxwCynhLUrVs3aGhoYN++fRg/frycoyMiIqJfHZ8MJIwikWg+fvwY1atXBwDs27cPjRo1ws6dO+Hl5YUDBw7INzgiIiIiypcisbyRRCJBZmYmgKzHTrZp0wZA1qMpY2Ji5BkaERERKQBFv8QtlCJR0axZsybmzp2Lbdu24eLFi3B2dgYAhIaGwtTUVM7REREREVF+FImK5rJly9CrVy8cPnwYU6ZMgbW1NQBg//790mefExEREQmFFU1hFIlEs2rVqjJ3nX+2cOFCKCsryyEiIiIiIvpRReLS+atXr/D69Wvp++vXr2P06NHYunUrVFRU5BgZERERKQLedS6MIpFo9uzZE+fPnwcAREREoHnz5rh+/TqmTJmC2bNnyzk6IiIiIsqPInHp/O7du6hduzYAYO/evahcuTIuX76MM2fOYOjQoZg+fbqcI5SfqMhILF+6CJcv+SM5ORmWliUxc+7fqFSpCgBg+pSJOHb0sMw+devVh+fajdL3rZ2a4m14uEyfEaPc0H/gYMHjp389uHMTJ/ZvQ+iTh4iPi8GY6QtRs25j6fbAS+dw9uRBvHjyEB8/vMc8z+2wKmuT41gSiQQe00bh9o2AbOM8e3QPe7asQuiTh4BIhLLlK6HHwBEoVaa8tM9Vf18c2b0FEW/CoK2rjxZtu6LN772FOnX6jx3eG7HBczk6d/8DI9wmAABGDe2HkJs3ZPq17fg7xk7K+v33Pj4ec6dPxPOnj5HwPh56+gao16gJBg0bBU0tLek+vj7HsXvrFrx+FQZNLS3Y162PoSPGQldPr9DOj37M7p074L1lE2JiolHepgImTp6GKlWryjusXx7naAqjSCSaaWlpEIvFALKWN2rXrh0AoEKFCnj79q08Q5OrhPfv0bdPD9SqZY9VazZAX98AYWEvoKOjK9Ovbr0GmDX3b+l7VRXVbGMNcx2JTl1+l77X1NAULnDKUUpyEkqWLo9GLdph2ZzsDyJITk6GTaVqqNPAERuXz/vmWD6HduX4SzE56RM8po5CjToN0Nd1AjIzMrB/+3osmDICK7adQLFixRAceBmrF0xDnz/HoWoNe7wJe4GNy+dBVSxGi3ZdC+x8KWcP79/FsYP7Uda6fLZtbTp0Rr/Bw6Xv1dTUpF8rKYlQv2ETDBg6Anr6+njzKgzLFs7Dh/fvMW2uBwDgTsgtuM+cAtcx41G3fiNER0dhyfw5WPT3TMzxWCb4udGP8zl1Eos83DF1xixUqVINO7Z5Y9iQAThy3AeGhobyDu+XxjxTGEUi0axUqRLWrl0LZ2dn+Pr6Ys6cOQCA8PBwhf7B2rJ5I8zMzDFrrru0rXiJEtn6qaqqwsjI+JtjaWpqfrcPCat6rXqoXqveV7c3cGwNAIiOCP9qHwB48ewRThzcgbkrvOHas5XMtvBXL/Dxw3t06TMEhsZmAIBOvQZh0rAeiIl6CzMLS1zyOwU7h8ZwdO4MADAxL4F23fri2F5vNG/7O/+qF9CnT58wd9pE/DVlBrZtXp9tu1hNHYZGRjnuq62ji/Zduknfm5lboEOX7ti9bYu07d6dEJiZW6Bzt14AAPPiJdCuYxfs3La5gM+EhLLNews6demKDh2zfj6nzpgFf/8LOHzwAAYM4lUo+vkUiTmaCxYswLp169C4cWP06NED1apVAwAcPXpUekldEV28cA62tpUxzm0Umjaqi+6/d8TB/Xuz9btx4zqaNqqLDm1bYt6cmYiPf5etz5ZNG9C4vj26/94R3ls2IT09vTBOgQpYSnIyPBdMQ1/X8dAzyJ6QmJcoBS0dXVzwOYr0tDSkpiTj4ukjsChZGsam5gCA9LRUqKjKVr1VVcWIi4lCTKTiXkEoDMs95qFOvQaoWdshx+1nfU6gXfMG6Nu9I9Z7LkNyctJXx4qJjoL/+bOoVqOmtK1SlWqIiozA1cv+kEgkiIuNwcVzvqhTt0GBnwsVvLTUVDy4fw91HP5d1k9JSQl16tTF7ZBbcoxMMfBZ58IoEhXNxo0bIyYmBgkJCdDX15e2Dx48GBoaGt/cNyUlBSkpKTJtGSJV6aX4n9mb16+wb+8u/NGnLwYMGoJ7d+/AY/48FFNRQbv2HQEAdes3QFPHFihevDhev3qFlSuWYviwwfDevlu6NFSPnr1R0dYWOjp6CAm5hZXLliA6Ogp/jZ8kz9OjfNi+bgnKV6yKmg6NctyurqGJqR5rsXTWOBzatQkAYGZhiQnzVkJZOevHvapdHWxftxR3b12HbbWaiAx/hZMHdwAA4uNiYGxmUTgno2D8zpzC40f3sdZrd47bHZ1aw9TMAkbGxnj29DHWrVqKVy9fZLvkPXvqeFy+eB4pKcmo26Axxk2ZJd1WpdpvmDp7PmZNGYfUlFRkZKSjboPGGD1+ipCnRgXkXfw7ZGRkZLuSZ2hoiNDQ53KKiujHFIlEE8i6uSEoKAjPnj1Dz549oa2tDVVV1e8mmu7u7pg1a5ZM2+Sp0zFl2kwBoy0cmZkS2FaqhBGj3AAAFSra4unTJ9i/d7c00WzZylnav1x5G5Qrb4O2rZvjRuB12NfJqpr0dukn7VPexgYqKiqYN3sGRo4eC1XV7PM5qWgKCriIeyE38Lfn9q/2SU1Jxoalc1G+UjW4TpyLzMxMnDiwHYumj8acFd5QFauhSauOiHz7BotmuCEjPR3qGppw6tAdB7evh0ipSFzk+OVERUZg1ZL5WLRy/Vf/CG7b8d851GWsy8PQ0BhurgPx5vUrFC9hKd3mOno8XAYOxeuwl9jguRyrly3EmAlTAQAvnj/DyiUL4DJgKGrVqYvYmBisXbkYS9znYPw0ruBB9C0KXngUTJFINF++fImWLVsiLCwMKSkpaN68ObS1tbFgwQKkpKRg7dq1X9130qRJcHNzk2nLEP0ayZORsTHKlLWWaStdpiz8zp756j4lLC2hp6+PV2EvpYnmf1WpUhXp6ekIf/MaVqXLFGjMJJz7ITcQ9fY1BnVuKtO+bO4EVKhUHVMXrsOV86cRHfkWM5duhtL/k8bhE+ZicJemCArwh0PjFhCJROgxYAS69f0T8e9ioaOrj7vB1wEAJmbFC/28FMGjB/fwLi4Og/r8O8cyMyMDt28F4dC+XfC9FJTt4RQVK2etLPHmVZhMomloZARDIyOUsioDbR1djBzsgj4DhsDQyBg7vDeictXq6N4764/LsuVsoKaujpGDXTBg2AgYcp52kaavpw9lZWXExsbKtMfGxsLoK3N3iYq6IpFojho1CjVr1kRISIjMJYOOHTti0KBB39xXLBZnqxB8SpUIEmdhq179N7x8ESrTFvbiBczNv35pMzIiAu/j42FkbPLVPo8ePoSSkhIMDBT3RqufUduuLmjcsr1M28ShPfDH4DGoUSdrDl5KSjKU/jMnSKSUtWJwpiRTZl8lZWUYGGX9fxJw4QzKVawCHT19UMGzq1UHm3cdlGlbMHsaSlqVRo8+/XN8AtrTx48A4Ks3BwGAJDPre5qamgogaw7vf8dS/v8fHBLJr/F78VemoqqKiraVcO1qAJo2cwQAZGZm4tq1AHTv8Yeco/v1KbGkKYgikWj+888/uHLlSrbLuFZWVnjz5o2copK/P/r0Rd/ePbBpw1o0d2qFe3du48CBvZg2PesS2KdPiVi3xhPNHFvAyMgIr169wvIlC2FZsiTq1qsPAAgJvoW7d26jZm17aGpo4nZIMBYtdEfrNm2ho6v7rcNTAUtO+oSI8FfS99ER4Xjx7BG0tHVhZGKGjx/eIyYqAvGxMQCAt69fAgD09A2hZ2Akff2XkYmZtBJZpYY9dm1cAS/PBWjRrhskmZk4utcbysrKsK2addPIh/fxuHbJD7ZV7ZCamgL/M8dw7R8/TFu4TuiPQGFpaGqiTNlyMm1q6urQ0dVDmbLl8Ob1K/idPgH7ug2go6uH508fw3OpB6r9Zoey5bLWUr162R/v4mJhY1sZ6uoaePH8GdauXIzK1X6DuUXW99+hQSMsmjcLR/bvQS2HrEvnq5YsQMVKVb75xycVHb1d+mHa5AmoVKkyKlepiu3bvJGUlIQOHTvJOzSifCkSiWZmZiYyMjKytb9+/Rra2tpyiKhoqFS5ChYvW4mVy5Zg/drVKF68BMaNn4TWbdoCAJSUlPHk8SMcO3oYHxI+wNjEGA4O9fDn8FHSpF1VVRWnfU5i7ZpVSEtNhUXxEujV2wW9+/T71qFJAM8fP8C8CUOl77evXwoAaODojKF/zURQgD/WL/l3Ht0q96wbODr1GoTOvXO3rImFpRXGzlqCg9s3YOaY/hCJlGBlXR7j566AvuG/Seo/viewc8NyQCKBdcUqmOqxFmVtKhXEaVI+qKioIOj6VezftR1JyUkwMTVDwybN0bv/v993sVgNxw8fwKqlC5GWlgoTEzM0aNIMPV0GSPu0atMBSYmJOLRvF1YvXwQtbW38VrM2hgwfI4/Tonxo2ao13sXFYfWqFYiJiYZNhYpYvW7jNyvbVDBY0BSGSFIErqd069YNurq6WL9+PbS1tXH79m0YGxujffv2KFmyJLZs2fL9Qb7wq1w6p9y5/+aDvEOgQlTcQO37neiXoa/5a8y5p9xRk2P5y2n1NcHGPv2nvWBjF3VFoqK5aNEitGzZEra2tkhOTkbPnj3x5MkTGBkZYdeuXfIOj4iIiIjyoUgkmpaWlggJCcGePXsQEhKCjx8/YsCAAejVqxfU1dXlHR4RERH94pR46VwQck8009LSUKFCBRw/fhy9evVCr1695B0SERERERUAuSeaKioqSE5OlncYREREpMAU/VGRQikSjwFxdXXFggUL+PxtIiIiol+I3CuaABAYGAg/Pz+cOXMGVapUgaampsz2gwcPfmVPIiIioh/HgqYwikSiqaenh86dO8s7DCIiIiIqQAVy6Tw+Pv6H9t+yZcs3X0RERERCEgn4X16sWbMGVatWhY6ODnR0dODg4IBTp05JtycnJ8PV1RWGhobQ0tJC586dERkZKTNGWFgYnJ2doaGhARMTE4wbNy7b9MQLFy6gRo0aEIvFsLa2hpeXV7ZYPD09YWVlBTU1Ndjb2+P69et5OhcgH4nmggULsGfPHun7rl27wtDQEMWLF0dISEieA/hSVFQU/vnnH/zzzz+Iior6obGIiIiIcktJJNwrL0qUKIH58+cjKCgIN27cQNOmTdG+fXvcu3cPADBmzBgcO3YM+/btw8WLFxEeHo5Onf59RGlGRgacnZ2RmpqKK1euwNvbG15eXpg+fbq0T2hoKJydndGkSRMEBwdj9OjRGDhwIE6fPi3ts2fPHri5uWHGjBm4efMmqlWrBicnpzznZ3l+MlDp0qWxY8cO1K1bF76+vujatSv27NmDvXv3IiwsDGfOnMlTAACQkJAAV1dX7N69W/ooSmVlZXTr1g2enp7QzeMzuflkIMXCJwMpFj4ZSLHwyUCKRZ5PBmq3PlCwsY8OrvVD+xsYGGDhwoXo0qULjI2NsXPnTnTp0gUA8PDhQ1SsWBEBAQGoU6cOTp06hTZt2iA8PBympqYAgLVr12LChAmIjo6GqqoqJkyYgBMnTuDu3bvSY3Tv3h3x8fHw8fEBANjb26NWrVpYtWoVgKzHhVtaWmLEiBGYOHFirmPPc0UzIiIClpaWAIDjx4+ja9euaNGiBcaPH4/AwPx9kwYNGoRr167h+PHjiI+PR3x8PI4fP44bN25gyJAh+RqTiIiIKLdEIpFgr5SUFCQkJMi8UlJSvhtTRkYGdu/ejcTERDg4OCAoKAhpaWlwdHSU9qlQoQJKliyJgIAAAEBAQACqVKkiTTIBwMnJCQkJCdKqaEBAgMwYn/t8HiM1NRVBQUEyfZSUlODo6Cjtk1t5TjT19fXx6tUrAICPj480CIlEIq1G5tXx48exefNmODk5SeckODk5YcOGDTh27Fi+xiQiIiIqCtzd3aGrqyvzcnd3/2r/O3fuQEtLC2KxGEOHDsWhQ4dga2uLiIgIqKqqQk9PT6a/qakpIiIiAGQVBL9MMj9v/7ztW30SEhKQlJSEmJgYZGRk5Njn8xi5lecidadOndCzZ0+UK1cOsbGxaNWqFQDg1q1bsLa2zutwAABDQ8McL4/r6upCX18/X2MSERER5ZaQyxtNmjQJbm5uMm1isfir/W1sbBAcHIz3799j//79cHFxwcWLF4ULUEB5TjSXLl0KKysrvHr1Ch4eHtDS0gIAvH37Fn/++We+gpg6dSrc3Nywbds2mJmZAcjKtseNG4dp06bla0wiIiKiokAsFn8zsfwvVVVVafHOzs4OgYGBWL58Obp164bU1FTEx8fLVDUjIyOl+ZOZmVm2u8M/35X+ZZ//3qkeGRkJHR0dqKurQ1lZGcrKyjn2+TxGbuU50VRRUcFff/2VrX3MmDF5HUpqzZo1ePr0KUqWLImSJUsCyLo1XywWIzo6GuvWrZP2vXnzZr6PQ0RERJQTpSK8YntmZiZSUlJgZ2cHFRUV+Pn5Sdcff/ToEcLCwuDg4AAAcHBwwLx58xAVFQUTExMAgK+vL3R0dGBrayvtc/LkSZlj+Pr6SsdQVVWFnZ0d/Pz80KFDB2kMfn5+GD58eJ5iz1WiefTo0VwP2K5duzwFAEB6EkRERESKbNKkSWjVqhVKliyJDx8+YOfOnbhw4QJOnz4NXV1dDBgwAG5ubjAwMICOjg5GjBgBBwcH1KlTBwDQokUL2Nraonfv3vDw8EBERASmTp0KV1dXaVV16NChWLVqFcaPH4/+/fvj3Llz2Lt3L06cOCGNw83NDS4uLqhZsyZq166NZcuWITExEf369cvT+eQq0cxtIigSifJ1Q9CMGTPyvA8RERFRQSkqBc2oqCj06dMHb9++ha6uLqpWrYrTp0+jefPmALKmMCopKaFz585ISUmBk5MTVq9eLd1fWVkZx48fx7Bhw+Dg4ABNTU24uLhg9uzZ0j6lS5fGiRMnMGbMGCxfvhwlSpTAxo0b4eTkJO3TrVs3REdHY/r06YiIiED16tXh4+OT7Qah78nzOppCiY+Px/79+/Hs2TOMGzcOBgYGuHnzJkxNTVG8ePE8jcV1NBUL19FULFxHU7FwHU3FIs91NLtsEW5q3v5+NQQbu6j7oW9pcnIy1NR+/Jf+7du34ejoCF1dXbx48QKDBg2CgYEBDh48iLCwMGzduvWHj0FEREREhSvP62hmZGRgzpw5KF68OLS0tPD8+XMAwLRp07Bp06Z8BeHm5oa+ffviyZMnMolr69at4e/vn68xiYiIiHJLJBLupcjynGjOmzcPXl5e8PDwgKrqv5c0KleujI0bN+YriMDAwByfAFS8ePE8LwxKREREREVDnhPNrVu3Yv369ejVqxeUlZWl7dWqVcPDhw/zFYRYLEZCQkK29sePH8PY2DhfYxIRERHllpJIJNhLkeU50Xzz5k2OTwDKzMxEWlpavoJo164dZs+eLd1fJBIhLCwMEyZMkK4TRUREREQ/lzwnmra2tvjnn3+yte/fvx+//fZbvoJYvHgxPn78CGNjYyQlJaFRo0awtraGtrY25s2bl68xiYiIiHJLJOBLkeX5rvPp06fDxcUFb968QWZmJg4ePIhHjx5h69atOH78eL6C0NXVha+vLy5fvoyQkBB8/PgRNWrUgKOjY77GIyIiIiL5y3Oi2b59exw7dgyzZ8+GpqYmpk+fjho1auDYsWPSxUTzIjMzE15eXjh48CBevHgBkUiE0qVLw8zMDBKJBCIFn9tAREREwmO+IYx8raPZoEED+Pr6/vDBJRIJ2rVrh5MnT6JatWqoUqUKJBIJHjx4gL59++LgwYM4fPjwDx+HiIiI6FuUmGcKIt8Ltt+4cQMPHjwAkDVv087OLs9jeHl5wd/fH35+fmjSpInMtnPnzqFDhw7YunUr+vTpk98wiYiIiEhO8pxovn79Gj169MDly5ehp6cHIOvxkXXr1sXu3btRokSJXI+1a9cuTJ48OVuSCQBNmzbFxIkTsWPHDiaaREREJCheOhdGnu86HzhwINLS0vDgwQPExcUhLi4ODx48QGZmJgYOHJinsW7fvo2WLVt+dXurVq0QEhKS1xCJiIiIqAjIc0Xz4sWLuHLlCmxsbKRtNjY2WLlyJRo0aJCnseLi4mBqavrV7aampnj37l1eQyQiIiLKExY0hZHniqalpWWOC7NnZGTAwsIiT2NlZGSgWLGv57rKyspIT0/Pa4hEREREVATkuaK5cOFCjBgxAp6enqhZsyaArBuDRo0ahUWLFuVpLIlEgr59+0IsFue4PSUlJa/hEREREeUZ52gKI1eJpr6+vsw3IDExEfb29tJqZHp6OooVK4b+/fujQ4cOuT64i4vLd/vwRiAiIiKin1OuEs1ly5YJcvAtW7YIMi4RERFRXnAdTWHkKtHMTeWRiIiI6GfFS+fCyPeC7QCQnJyM1NRUmTYdHZ0fCoiIiIiIfg15vus8MTERw4cPh4mJCTQ1NaGvry/zIiIiIvrZiAR8KbI8J5rjx4/HuXPnsGbNGojFYmzcuBGzZs2ChYUFtm7dKkSMRERERPQTyvOl82PHjmHr1q1o3Lgx+vXrhwYNGsDa2hqlSpXCjh070KtXLyHiJCIiIhKMEudoCiLPFc24uDiUKVMGQNZ8zLi4OABA/fr14e/vX7DREREREdFPK8+JZpkyZRAaGgoAqFChAvbu3Qsgq9Kpp6dXoMERERERFQaRSLiXIstzotmvXz+EhIQAACZOnAhPT0+oqalhzJgxGDduXIEHSEREREQ/pzzP0RwzZoz0a0dHRzx8+BBBQUGwtrZG1apVCzQ4IiIiosLAdTSFkeeK5n+VKlUKnTp1goGBAQYPHlwQMRERERHRL+CHE83PYmNjsWnTpoIajoiIiKjQcI6mMH7oyUBEREREvwIubySMAqtoEhERERF9iRVNIiIiUngsaAoj14lmp06dvrk9Pj7+R2MhIiIiol9IrhNNXV3d727v06fPDwdEREREVNi4vJEwcp1obtmyRcg4iIiIiOgX80vO0bz0LEbeIVAhsiupL+8QqBCVqD9a3iFQIYq9tlLeIVChkl9VkXdHC4OfKxEREREJ4pesaBIRERHlBedoCoOJJhERESk8JeaZguClcyIiIiISRK4qmkePHs31gO3atct3MERERETywIqmMHKVaHbo0CFXg4lEImRkZPxIPERERET0i8hVopmZmSl0HERERERyw5uBhME5mkREREQkiHzddZ6YmIiLFy8iLCwMqampMttGjhxZIIERERERFRbO0RRGnhPNW7duoXXr1vj06RMSExNhYGCAmJgYaGhowMTEhIkmEREREQHIx6XzMWPGoG3btnj37h3U1dVx9epVvHz5EnZ2dli0aJEQMRIREREJSiQS7qXI8pxoBgcHY+zYsVBSUoKysjJSUlJgaWkJDw8PTJ48WYgYiYiIiASlJBIJ9lJkeU40VVRUoKSUtZuJiQnCwsIAALq6unj16lXBRkdEREREP608z9H87bffEBgYiHLlyqFRo0aYPn06YmJisG3bNlSuXFmIGImIiIgExWV4hJHnz/Xvv/+Gubk5AGDevHnQ19fHsGHDEB0djfXr1xd4gERERET0c8pzRbNmzZrSr01MTODj41OgAREREREVNgWfSikYVoqJiIiISBB5rmiWLl36m49pev78+Q8FRERERFTYFP3ucKHkOdEcPXq0zPu0tDTcunULPj4+GDduXEHFRUREREQ/uTwnmqNGjcqx3dPTEzdu3PjhgIiIiIgKGwuawiiwOZqtWrXCgQMHCmo4IiIiokKjJBLupcgKLNHcv38/DAwMCmo4IiIiIvrJ5WvB9i9vBpJIJIiIiEB0dDRWr15doMERERERFQbeDCSMPCea7du3l0k0lZSUYGxsjMaNG6NChQoFGhwRERER/bzynGjOnDlTgDCIiIiI5IcFTWHkeY6msrIyoqKisrXHxsZCWVm5QIIiIiIiop9fniuaEokkx/aUlBSoqqr+cEBEREREhU3R7w4XSq4TzRUrVgAARCIRNm7cCC0tLem2jIwM+Pv7c44mEREREUnlOtFcunQpgKyK5tq1a2Uuk6uqqsLKygpr164t+AiJiIiIBCYCS5pCyHWiGRoaCgBo0qQJDh48CH19fcGCIiIiIipMvHQujDzP0Tx//rwQcRARERHRLybPd5137twZCxYsyNbu4eGB33//vUCCIiIiIipMfASlMPKcaPr7+6N169bZ2lu1agV/f/88B5CYmJjnfYiIiIio6Mtzovnx48cclzFSUVFBQkJCngMwNTVF//79cenSpTzvS0RERFQQRCKRYC9FludEs0qVKtizZ0+29t27d8PW1jbPAWzfvh1xcXFo2rQpypcvj/nz5yM8PDzP4xARERFR0ZLnm4GmTZuGTp064dmzZ2jatCkAwM/PD7t27cK+ffvyHECHDh3QoUMHREdHY9u2bfDy8sK0adPg5OSE/v37o127dihWLM9hEhEREeWaos+lFEqeK5pt27bF4cOH8fTpU/z5558YO3YsXr9+jbNnz6JDhw75DsTY2Bhubm64ffs2lixZgrNnz6JLly6wsLDA9OnT8enTp3yPTURERESFL1+lQmdnZzg7O2drv3v3LipXrpyvQCIjI+Ht7Q0vLy+8fPkSXbp0wYABA/D69WssWLAAV69exZkzZ/I1NhEREdG3KPhUSsH88DXpDx8+YNeuXdi4cSOCgoKQkZGRp/0PHjyILVu24PTp07C1tcWff/6JP/74A3p6etI+devWRcWKFX80VCIiIqIcKTHTFES+E01/f39s3LgRBw8ehIWFBTp16gRPT888j9OvXz90794dly9fRq1atXLsY2FhgSlTpuQ3VCIiIiKSgzwlmhEREfDy8sKmTZuQkJCArl27IiUlBYcPH87XHecA8PbtW2hoaHyzj7q6OmbMmJGv8YmIiIi+hzcDCSPXNwO1bdsWNjY2uH37NpYtW4bw8HCsXLnyhwPQ1tZGVFRUtvbY2FgoKyv/8PhEREREJB+5rmieOnUKI0eOxLBhw1CuXLkCC0AikeTYnpKSkuPC8EREREQFjVM0hZHrRPPSpUvYtGkT7OzsULFiRfTu3Rvdu3fP94FXrFgBIGsl/o0bN0JLS0u6LSMjA/7+/qhQoUK+xyciIiIi+cp1olmnTh3UqVMHy5Ytw549e7B582a4ubkhMzMTvr6+sLS0hLa2dq4PvHTpUgBZFc21a9fKXCZXVVWFlZUV1q5dm4dTISIiIsofJbCkKYQ8L9iuqakpfTb5nTt3MHbsWMyfPx8mJiZo165drscJDQ1FaGgoGjVqhJCQEOn70NBQPHr0CKdPn4a9vX1ewyMiIiL6abm7u6NWrVrQ1taGiYkJOnTogEePHsn0SU5OhqurKwwNDaGlpYXOnTsjMjJSpk9YWBicnZ2hoaEBExMTjBs3Dunp6TJ9Lly4gBo1akAsFsPa2hpeXl7Z4vH09ISVlRXU1NRgb2+P69ev5+l88pxofsnGxgYeHh54/fo1du3ala8xzp8/D319faSmpuLRo0fZPgQiIiIioYlEwr3y4uLFi3B1dcXVq1fh6+uLtLQ0tGjRAomJidI+Y8aMwbFjx7Bv3z5cvHgR4eHh6NSpk3R7RkYGnJ2dkZqaiitXrkgfiDN9+nRpn9DQUDg7O6NJkyYIDg7G6NGjMXDgQJw+fVraZ8+ePXBzc8OMGTNw8+ZNVKtWDU5OTjnexP3Vz1XytbtxCklSUhKGDx8Ob29vAMDjx49RpkwZjBgxAsWLF8fEiRPzPOaZB9EFHSYVYXYl9eUdAhWiEvVHyzsEKkSx1358dRP6eWioyu/y9dqAF4KNPdTBKt/7RkdHw8TEBBcvXkTDhg3x/v17GBsbY+fOnejSpQsA4OHDh6hYsSICAgJQp04dnDp1Cm3atEF4eDhMTU0BAGvXrsWECRMQHR0NVVVVTJgwASdOnMDdu3elx+revTvi4+Ph4+MDALC3t0etWrWwatUqAEBmZiYsLS0xYsSIXOdnP1TRLAgTJ05ESEgILly4ADU1NWm7o6Mj9uzZI8fIiIiIiH5cSkoKEhISZF4pKSm52vf9+/cAAAMDAwBAUFAQ0tLS4OjoKO1ToUIFlCxZEgEBAQCAgIAAVKlSRZpkAoCTkxMSEhJw7949aZ8vx/jc5/MYqampCAoKkumjpKQER0dHaZ/ckHuiefjwYaxatQr169eH6Iv6cqVKlfDs2TM5RkZERESKQkkkEuzl7u4OXV1dmZe7u/t3Y8rMzMTo0aNRr149VK5cGUDWw3NUVVVlHtUNAKampoiIiJD2+TLJ/Lz987Zv9UlISEBSUhJiYmKQkZGRY5/PY+TGDz/r/Ed9Lgn/V2JiokziSURERPQzmjRpEtzc3GTaxGLxd/dzdXXF3bt3cenSJaFCE5zcE82aNWvixIkTGDFiBABIk8uNGzfCwcFBnqEJ7um9YPgd2omwZ4+Q8C4WAyf+jWp1GubYd/eahbh8+gg69R+JJu26SttfPXuEI1vXIOzJQ4iUlVC9TiN06j8CYvV/H+s5okP9bOP1HTsTdg3+LYc/uXMTB7esQkRYKPSMTOD0uwvqNGtdgGdL/7V18wZcOOeLsBehUBWroUq16vhzpBtKWZWW9nn9Kgyrli3C7Vs3kZqWijp168Nt/GQYGBpJ+4S9fIFVyxbhTsgtpKWlwbpceQwaNgJ2tf5dteHGtatYv2Ylnj99DDV1dbRq0x5DXEehWDG5/wr4JU0Z0hpTh8r+/DwKjUD1TnMBAP071UO3VjVRvUIJ6Gipw6zBOLz/mCTTX19HA0sm/I7WDSsjUyLBYb9g/OWxH4lJqdmOV8bSCFd3TURGZibMG46XtrdvWg3jBjihrKURVIop42lYNJZv88OuE4ECnDV9T1RkJJYvXYTLl/yRnJwMS8uSmDn3b1SqVAUAMH3KRBw7elhmn7r16sNz7UaZtn/8L2D92tV48vgRVFXFsKtZC0tXeBbWafyyhKxticXiXCWWXxo+fDiOHz8Of39/lChRQtpuZmaG1NRUxMfHy1Q1IyMjYWZmJu3z37vDP9+V/mWf/96pHhkZCR0dHairq0NZWRnKyso59vk8Rm7I/V+Zv//+G61atcL9+/eRnp6O5cuX4/79+7hy5QouXrwo7/AElZKchOKlrVHH0Rkb50/5ar+Qqxfx4tE96BoYybS/j4vBqhmjUaN+M/w+2A3JnxJxYNMKbF/xNwZMmCvTt9eIybCt8W/ioa757wL5MZHhWDt3POo5tYfLmOl4dDsIuzwXQNfAEBV/4xJTQrkVFIjOXXugYqUqyMhIx9pVyzH6z0HYeeAo1NU1kJT0CaNdB6NcORusXLcZALB+zUqMG+2KDd67oKSUNfNl3Kg/UaJkKaxcuxliNTXs2bEV40a5Yt/RUzA0MsaTxw8xduRQuAwYjOmz/0Z0dBQ85s1GZmYmRowZJ8+P4Jd272k4nIf+eyNLekam9GsNNRX4XrkP3yv3MWdk+xz33/K3C8yMdNFm2CqoFFPGull/wHNaT/Sd7CXTr1gxJWx174fLt56hTrXSMtvi3n+Cx0YfPHoRidS0DLRuUBnrZ/6B6LiPOBvwoOBOlr4r4f179O3TA7Vq2WPVmg3Q1zdAWNgL6OjoyvSrW68BZs39W/peVUX2CXlnfU9jzszpGD5qDGrXtkd6RgaePXlSKOdAhUMikWDEiBE4dOgQLly4gNKlZX+u7ezsoKKiAj8/P3Tu3BkA8OjRI4SFhUkLdA4ODpg3bx6ioqKkV419fX2ho6MDW1tbaZ+TJ0/KjO3r6ysdQ1VVFXZ2dvDz80OHDh0AZF3K9/Pzw/Dhw3N9PnJPNOvXr4/g4GDMnz8fVapUwZkzZ1CjRg3pRNZfWSU7B1Sy+3bVNj42Gvs3LMOfMxZj7ZzxMtvuBl6GsnIx/D7YTZp0dB/6F9xHuyD67WsYm//7F5C6phZ09A1zPMZln8MwNDVHp/5ZVWUzSys8f3Ab54/uYaIpoKWe62XeT501D87NGuDh/fv4za4mbgffQkT4G3jv3A/N/z85a9qsv+HU2AFBgddQy94B8e/e4VXYS0yaPgfW5W0AAMNGuuHgvt14/uwpDI2M4XfaB2XLlUf/wX8CAEqULAXXUW6YOnEs+g/+E5qamoV74goiPSMTkbEfcty2aucFAEADu5wf52tT2hRO9SqhXi8P3LwfBgBwW7APh1cOw6Slh/A2+r2078w/2+JRaCTOX3+ULdH8J0g2AfHcdQG92tqj7m9lmGgWsi2bN8LMzByz5v47L6/4F1Wqz1RVVWFkZJzjGOnp6Vg4/2+MHjsOHTt1kbaXLWtd8AErIKUiMl3P1dUVO3fuxJEjR6CtrS2dD6mrqwt1dXXo6upiwIABcHNzg4GBAXR0dDBixAg4ODigTp06AIAWLVrA1tYWvXv3hoeHByIiIjB16lS4urpKK6tDhw7FqlWrMH78ePTv3x/nzp3D3r17ceLECWksbm5ucHFxQc2aNVG7dm0sW7YMiYmJ6NevX67PR+6JJgCULVsWGzZskHcYRU5mZia2LpuDZh16wLxkmWzb09PSoFxMRZpkAoDK//8Henb/tkyiuW/9EuzyXABDMwvUd2qPOs2cpdMUQh/dg03VmjJjV/ytNg5sWiHEadFXJH7ISkp0dLMqHGmpqRCJRFBR/beioSoWQ0lJCSG3bqKWvQN09fRQ0qo0Tp04ApuKFaGiooojB/ZC38AQNhWz/mpNTUuFWFX2ko1YTQ2pKSl49OAeatSsXUhnqFisSxrj+Zl5SE5Jw7XboZi+8iheRbzL1b72VUvjXcInaZIJAOeuPUJmpgS1KpfC0fO3AQCNapVHp+a/wb77fLRvWu274zauXR7lrUwwdTlvtCxsFy+cQ9269THObRSCggJhYmKKrt16oFOXrjL9bty4jqaN6kJHRwe1ateB64hR0NPLWsLt4YP7iIqKhJJIhO6/d0RsTAzK21TAmLHjYF2uvDxOiwSwZs0aAEDjxo1l2rds2YK+ffsCyHq6opKSEjp37oyUlBQ4OTlh9erV0r7Kyso4fvw4hg0bBgcHB2hqasLFxQWzZ8+W9ildujROnDiBMWPGYPny5ShRogQ2btwIJycnaZ9u3bohOjoa06dPR0REBKpXrw4fH59sNwh9i1wSzYSEBOjo6Ei//pbP/b4mJSUl2xIBqakpUFXN21yIoujswR1QVlJGoza/57i9fNUaOLhlJc4e2onGbX5HakoSjm7NemxnwrtYaT/nHgNRvmoNqIjV8DD4OvauW4KU5CQ0/v+4CfGx0NYzkBlbW9cAyZ8SkZqSAtU8ziuhvMvMzMSyRQtQtfpvKGudVeWqVLUa1NTVsXr5YgwdPhoSSLBmxVJkZGQgNiZrrViRSIQVazZiottIONavDSUlJejrG2DJqnXSS3L2DvWwd+c2nPE5gWbNWyIuNgab12f9IouJ4ZqzQgi8+wKDp2/H45eRMDPSxZQhrXB28xjYdZmHj5++v6SJqaEOouNkq6EZGZmIS/gEU6Os34kGuprYMOsP9JvqjQ+JyV8dS0dLDc9Oz4NYpRgyMjMxyn0Pzl17+GMnSHn25vUr7Nu7C3/06YsBg4bg3t078Jg/D8VUVNCufUcAQN36DdDUsQWKFy+O169eYeWKpRg+bDC8t++GsrIyXr9+BQBYu8YTY8dNgIVFcWzz3oJB/fvg8HEf6OrqyfEMf35FpKCJ3CxvrqamBk9PT3h6fn1ubqlSpbJdGv+vxo0b49atW9/sM3z48DxdKv8vuSSa+vr6ePv2LUxMTKCnp5fj3eUSiQQikQgZGRnfHMvd3R2zZs2Safvjz7/Qe/j4r+zxcwh7+hAXju/DhCWbv3r3vXnJMug9cgoOblmFY9vWQUlJCY3adIG2ngFESv/u07JbX+nXlmXKIzU5GX6HdkkTTZK/xfPn4vmzJ1i7eZu0TV/fAHMXLMFC9znYt3tH1vplTq1hU8FWWsWWSCRYNH8u9A0MsGbTVojFajh6eD/Gj3bFpm17YGRsDHuHenAdPRYL/56NOdMmQUVFFX0HDUHIrSAoieS+wtkv6czl+9Kv7z4JR+CdF3h0cjY6t6gB78O5X3/uW1ZP64E9Pjdw+ea3q5MfElNg390dWupiNLG3wYKxnRD6OjbbZXUSVmamBLaVKmHEqKw7jytUtMXTp0+wf+9uaaLZspWztH+58jYoV94GbVs3x43A67Cv4wBJZtY834GDhsCxeVbVadZcdzg5NoLvaR906dq9kM/q18LfhsKQS6J57tw56cKj586d+6FljHJaMsA/9NtV0p/Bs/u38fH9O0wf2FnalpmZgUNeq3Dh2F7M2rAfAFCzUQvUbNQCCfFxEIvVAJEI547ugZGpxVfHLlXeFj57vZCWlgoVFVXo6BniQ3ycTJ8P7+OgpqHJamYhWDx/Li7/cxGrN3rDxFT2Tj57h3rYf9QH8e/eQbmYMrS1ddCmeUNYFG8FAAi6fg1X/rmI0xcCpPM4x1WcjsCrATh5/DD69BsEAOjxR1907+WCmJho6Gjr4G34G6xduQwWOcwRo4L3/mMSnoZFoaxlznPv/isyNgHGBtoybcrKSjDQ0UBkTNbvt0a1y8O5URWM7t0MQFZ1W1lZCR8Cl8N17i5sPXIVQNYfI89fxQAAbj9+A5vSZhjXvwUTzUJmZGyMMv+ZS1m6TFn4nT3z1X1KWFpCT18fr8Jewr6OA4yMs/7/+XIcVVVVlChhiYiIt8IETvSD5JJoNmrUSPr1f+cg5FVOSwaoquZutf2irHZjJ9hUk503uXqWG2o1dkKdZs7Z+uv8/9J3wNnjUFFRhU21Wl8d+03oE2hoaUPl/3czlraphHtBV2X6PAwORGmbSj96GvQNEokESxbMw8XzfvDc4AWL4l9P+vT0s+Zo3bh+Fe/i4lC/URMAQHJy1pI4X1awgaynN0gyZS+/iEQiGBv//+7D0ydhamYGmwq2BXY+9HWa6qooXcIIESeuf78zgGu3Q6Gvo4HfKlri1oOsy6WNa5WHkpIIgXdfZr13WQzlL+Znt2lcFWP7OqJJ3yUIj4r/6thKIhHEqkVier5CqV79N7x8ESrTFvbiBczNv14UiIyIwPv4eBj9/+e2om1lqKqq4sWLUPxWww4AkJaWhvA3b745DuUO1+4Whtx/28ycORPTp0+XuaEFyHrk0tChQ7Fr1y45RSa8lKRPiH77Rvo+NuotXj9/Ag1tbRgYm0HzP8teKCsXg46eIUyLl5S2XTxxAGUqVIZYTR0PQwJx2Gs12vUZCg2trGrIneuX8OH9O1iVrwQVVVU8DA7Emf3b0LRDD+kY9Vp2gP/JgzjstRp1HJ3x+HYQbl0+j6HTPAT+BBTbovlz4HvqJBYsXQkNDQ3pvEstLW2I//841uNHDsGqdBno6evj7u0QLFvkjm69+kjX2qxctTq0dXQwd/pk9Bs8LOvS+cH9CH/zGnUb/Lsm6w7vzahTtz5ESkq4eM4X27ZsxJwFS6CsrFz4J64A3Md0xAn/OwgLj4OFiS6mDnVGRmYm9voEAQBMDbVhaqiDsiWzliyrXM4CHxKT8SriHd4lfMKj0EicvnwPntN6YuS83VAppoylE7ti3+mb0jvOH4XKrm1Xw7YkMiUS3H/2b2Xrr/4tcPNeGJ6/joZYtRha1q+Ens61MdJ9dyF9EvTZH336om/vHti0YS2aO7XCvTu3ceDAXkybnnVzxqdPiVi3xhPNHFvAyMgIr169wvIlC2FZsiTq1staC1lLSwtdunbHWs+VMDMzg7m5Bby9spY+a96ipdzOjehb5J5obtq0CWfOnMH27dtRpkzWndUXLlxAnz598rQg6M8o7OlDrJg2Uvr+0OasNfdqN2mF3qO+vq7ml14+uY+TuzchNSkJJiVKovuwcajd5N9fOMrFiuGfkwdxcNMKSAAYmxVHx/7DUbd5O2kfI1MLDJ3qgYObV+Li8X3QMzRGD9cJXNpIYIf27QEAuA7qK9M+ZeZcOLfLmrMV9jIUa1ctRcL79zC3KA6XAYPRvZeLtK+evj6WrFqHdauWY8SQ/khPT0fpMtZYsHQVypWvIO0XcPkfeG9aj9S0VJQrZ4MFS1fBoV4D4U9SQRU31cNW934w0NVAzLuPuBL8HI36LEbMu48AgIFdGsgs6H528xgAwKDp27D92DUAQL/J3lg6sStOrhuBzMysBdvHeuzLUxyaaqpYPrkripvoISklDY9fRKL/VG/sP3OzgM6UcqtS5SpYvGwlVi5bgvVrV6N48RIYN34SWrdpCwBQUlLGk8ePcOzoYXxI+ABjE2M4ONTDn8NHQfWLlSdGu42DsrIypk6agJSUZFSuUg3rN3lJV6ug/GM9UxgiSW5ubxLQu3fvMGTIEPj4+GDx4sV4/Pgxli9fjnHjxmHWrFn5enLJmQe8k1aR2JXUl3cIVIhK1B8t7xCoEMVeW/n9TvTL0FCVX7q39cYrwcbuU9NSsLGLOrlXNPX19bF3715MnjwZQ4YMQbFixXDq1Ck0a9ZM3qERERGRgigqC7b/aorE3fwrV67E8uXL0aNHD5QpUwYjR45ESEiIvMMiIiIioh8g90SzZcuWmDVrFry9vbFjxw7cunULDRs2RJ06deDhwZtRiIiISHgiAV+KTO6JZkZGBm7fvo0uXbKe26quro41a9Zg//79WLp0qZyjIyIiIkUgEgn3UmRyn6Pp6+ubY7uzszPu3LlTyNEQERERUUGRe6L5WWpqKqKiopD5/0dsERERERUWLtguDLknmo8fP8aAAQNw5coVmfbcPuuciIiIiIomuSea/fr1Q7FixXD8+HGYm5vzLwoiIiIqdHK/aeUXJfdEMzg4GEFBQahQocL3OxMRERHRT0PuiaatrS1iYmLkHQYREREpMF5RFYbcK8ULFizA+PHjceHCBcTGxiIhIUHmRUREREQ/J7lXNB0dHQEg2yMneTMQERERFRbWM4Uh90Tz/PnzX93GdTSJiIiIfl5yTzQbNWok8/7Dhw/YtWsXNm7ciKCgIAwfPlxOkREREZGi4BxNYch9juZn/v7+cHFxgbm5ORYtWoSmTZvi6tWr8g6LiIiIFICSgC9FJteKZkREBLy8vLBp0yYkJCSga9euSElJweHDh2FrayvP0IiIiIjoB8kt0W7bti1sbGxw+/ZtLFu2DOHh4Vi5cqW8wiEiIiIFJhKJBHspMrlVNE+dOoWRI0di2LBhKFeunLzCICIiIiKByK2ieenSJXz48AF2dnawt7fHqlWruHA7ERERyYVIwJcik1uiWadOHWzYsAFv377FkCFDsHv3blhYWCAzMxO+vr748OGDvEIjIiIiogIg95uhNDU10b9/f1y6dAl37tzB2LFjMX/+fJiYmKBdu3byDo+IiIgUgEgk3EuRyT3R/JKNjQ08PDzw+vVr7Nq1S97hEBEREdEPkPuC7TlRVlZGhw4d0KFDB3mHQkRERApASeFnUwqjSCaaRERERIVJ0S9xC6VIXTonIiIiol8HK5pERESk8ES8dC4IVjSJiIiISBCsaBIREZHC4xxNYbCiSURERESCYEWTiIiIFB6XNxIGK5pEREREJAhWNImIiEjhcY6mMJhoEhERkcJjoikMXjonIiIiIkGwoklEREQKjwu2C4MVTSIiIiISBCuaREREpPCUWNAUBCuaRERERCQIVjSJiIhI4XGOpjBY0SQiIiIiQbCiSURERAqP62gKg4kmERERKTxeOhcGL50TERERkSBY0SQiIiKFx+WNhMGKJhEREREJghVNIiIiUnicoykMVjSJiIiISBCsaBIREZHC4/JGwmBFk4iIiIgEwYomERERKTwWNIXBRJOIiIgUnhKvnQuCl86JiIiISBAiiUQikXcQBS36Q7q8Q6BCpCFWlncIVIhexnySdwhUiDIzf7l/ougbKpfQktuxrz6NF2zsOtZ6go1d1LGiSURERESC4BxNIiIiIk7RFAQrmkREREQkCFY0iYiISOHxEZTCYEWTiIiIiATBiiYREREpPC6jKQwmmkRERKTwmGcKg5fOiYiIiEgQrGgSERERsaQpCFY0iYiIiEgQrGgSERGRwuPyRsJgRZOIiIiIBMGKJhERESk8Lm8kDFY0iYiIiEgQrGgSERGRwmNBUxhMNImIiIiYaQqCl86JiIiISBCsaBIREZHC4/JGwmBFk4iIiIgEwYomERERKTwubyQMVjSJiIiIihB/f3+0bdsWFhYWEIlEOHz4sMx2iUSC6dOnw9zcHOrq6nB0dMSTJ09k+sTFxaFXr17Q0dGBnp4eBgwYgI8fP8r0uX37Nho0aAA1NTVYWlrCw8MjWyz79u1DhQoVoKamhipVquDkyZN5OhcmmkRERKTwRAK+8ioxMRHVqlWDp6dnjts9PDywYsUKrF27FteuXYOmpiacnJyQnJws7dOrVy/cu3cPvr6+OH78OPz9/TF48GDp9oSEBLRo0QKlSpVCUFAQFi5ciJkzZ2L9+vXSPleuXEGPHj0wYMAA3Lp1Cx06dECHDh1w9+7dXJ+LSCKRSPLxGRRp0R/S5R0CFSINsbK8Q6BC9DLmk7xDoEKUmfnL/RNF31C5hJbcjh0S9kGwsauV1M73viKRCIcOHUKHDh0AZFUzLSwsMHbsWPz1118AgPfv38PU1BReXl7o3r07Hjx4AFtbWwQGBqJmzZoAAB8fH7Ru3RqvX7+GhYUF1qxZgylTpiAiIgKqqqoAgIkTJ+Lw4cN4+PAhAKBbt25ITEzE8ePHpfHUqVMH1atXx9q1a3MVPyuaRERERAKWNFNSUpCQkCDzSklJyVeYoaGhiIiIgKOjo7RNV1cX9vb2CAgIAAAEBARAT09PmmQCgKOjI5SUlHDt2jVpn4YNG0qTTABwcnLCo0eP8O7dO2mfL4/zuc/n4+QGE00iIiJSeCIB/3N3d4eurq7My93dPV9xRkREAABMTU1l2k1NTaXbIiIiYGJiIrO9WLFiMDAwkOmT0xhfHuNrfT5vzw3edU5EREQkoEmTJsHNzU2mTSwWyymawsVEk4iIiBSekMsbicXiAksszczMAACRkZEwNzeXtkdGRqJ69erSPlFRUTL7paenIy4uTrq/mZkZIiMjZfp8fv+9Pp+35wYvnRMRERH9JEqXLg0zMzP4+flJ2xISEnDt2jU4ODgAABwcHBAfH4+goCBpn3PnziEzMxP29vbSPv7+/khLS5P28fX1hY2NDfT19aV9vjzO5z6fj5MbTDSJiIhI4RWl5Y0+fvyI4OBgBAcHA8i6ASg4OBhhYWEQiUQYPXo05s6di6NHj+LOnTvo06cPLCwspHemV6xYES1btsSgQYNw/fp1XL58GcOHD0f37t1hYWEBAOjZsydUVVUxYMAA3Lt3D3v27MHy5ctlLvGPGjUKPj4+WLx4MR4+fIiZM2fixo0bGD58eO4/Vy5vRD87Lm+kWLi8kWLh8kaKRZ7LG919/fH7nfIpr+d14cIFNGnSJFu7i4sLvLy8IJFIMGPGDKxfvx7x8fGoX78+Vq9ejfLly0v7xsXFYfjw4Th27BiUlJTQuXNnrFixAlpa/8Zy+/ZtuLq6IjAwEEZGRhgxYgQmTJggc8x9+/Zh6tSpePHiBcqVKwcPDw+0bt061+fCRJN+ekw0FQsTTcXCRFOxyDXRfCNgollcfuclb7x0TkRERESC4F3nREREpPBE+ZpNSd/DiiYRERERCYIVTSIiIlJ4Qq6jqciYaBIREZHCY54pDF46JyIiIiJBsKJJRERExJKmIFjRJCIiIiJByD3R9PHxwaVLl6TvPT09Ub16dfTs2RPv3r2TY2RERESkKEQC/qfI5J5ojhs3DgkJCQCAO3fuYOzYsWjdujVCQ0NlnrdJRERERD8Xuc/RDA0Nha2tLQDgwIEDaNOmDf7++2/cvHkzT8/SJCIiIsovLm8kDLlXNFVVVfHpU9azi8+ePYsWLVoAAAwMDKSVTiIiIiL6+ci9olm/fn24ubmhXr16uH79Ovbs2QMAePz4MUqUKCHn6IiIiEgRsKApDLlXNFetWoVixYph//79WLNmDYoXLw4AOHXqFFq2bCnn6IiIiEghiAR8KTCRRCKRyDuIghb9IV3eIVAh0hAryzsEKkQvYz7JOwQqRJmZv9w/UfQNlUtoye3YjyOF+91S3lRDsLGLOrlXNG/evIk7d+5I3x85cgQdOnTA5MmTkZqaKsfIiIiISFFweSNhyD3RHDJkCB4/fgwAeP78Obp37w4NDQ3s27cP48ePl3N0RERERJRfck80Hz9+jOrVqwMA9u3bh4YNG2Lnzp3w8vLCgQMH5BscERERKQSRSLiXIpN7oimRSJCZmQkga3mjz2tnWlpaIiYmRp6hEREREdEPkPvyRjVr1sTcuXPh6OiIixcvYs2aNQCyFnI3NTWVc3RERESkCBS88CgYuVc0ly1bhps3b2L48OGYMmUKrK2tAQD79+9H3bp15RwdEREREeVXkV3eKDk5GcrKylBRUcnzvj/r8kaH9u/G4f178PbtGwBA6TLW6DtwGBzqNZDpJ5FI8Neoobh25RL+XrQCDRs3AwCcPHYIf8+amuPYx874Q9/AEDEx0Vi11AMPH9zDm1dh6NK9F0aNnSTsiQnsV1neKCMjA+tWr8LJE0cRGxMDY2MTtG3fEQOHDIPo/5N8/M6ewYG9u/Hg/j28f/8eu/Ydgk2FijLjHNi3Bz4nj+Phg/tITEzExcvXoa2jI49TEsTPurxRRkYG9nivw0Xfk4iPi4W+kTGaOrXF770HSr+/SUmfsG39Cly/dAEfEt7DxNwCzp16oGW7LtJxpo4ehHshQTJjt2jbGcPcpkjfd2xSI9vx3aa5o0FTJ4HOTjg/8/JGSZ8SsWvLGly7dB4J8e9Q2toG/V3/gnWFSgCAPd7rcOn8acRGR6JYMRWUKV8RPfv/ifIVq0jHCH/1ElvXL8fDu8FIT09HqTLW6N53GKr8Vivb8T68j4fb4B6Ii4nC1iMXoKmlXWjnWlDkubzRs+gkwcYua6wu2NhFndwvnQNAfHw89u/fj2fPnmHcuHEwMDDA/fv3YWpqKl3AXREYm5hi6PAxKFGyFCQSCU4dP4JJY4dj844DKFPWWtpv786tOS6X0Kx5K9g71JdpmzdrClJTUqFvYAgASEtNhZ6+AVz6D8HenVuFPSHKE6/NG7B/7y7MmjcfZcta4/69u5g5bTK0tLXQo1cfAEBSUhKq/2aH5k6tMGfmtBzHSU5ORt16DVC3XgOsXL6kME+BvuHQLi/4HNmPkRNnoWTpsnj66D5WLpgJDU0ttOncAwCwxXMx7twKxOgpc2FiZoHgwACsWzYfBobGqF2vkXSs5s4d0aP/MOl7sVgt2/FGTJiJ32r/e1XoZ0w6fnarF89BWOgzjJw0BwaGxvA/exKzxg/Dsk37YWhsAosSJTFwxASYmhdHamoKju/fgTkTXLFq6xHo6ukDAP6eMhrmJSwxc9E6qIrFOHFgJ9ynjobntiPQNzCSOZ7notkoVaYc4mKi5HG6Pz1FX4ZIKHJPNG/fvo1mzZpBT08PL168wKBBg2BgYICDBw8iLCwMW7cqTjJUv2ETmfdDXEfh8IHduH8nRJpoPnn0ALt3eGPj1j1o37KxTH+xmhrEav/+g/PuXRxuBl7DxGlzpG3mFsUx+q+sCuaJo4cEOhPKj5DgW2jUpBkaNGwMALAoXgI+p07g7hfrzLZp2x4AEP7m9VfH6dXbBQBwI/CacMFSnj28F4La9RqhpkPWFQoTMwv84+eDJw/vftHnNpo4tUXl6jUBZFUqTx87gCcP78okmmI1tWxJxn9paml/tw8JJyUlGVf9z2HinMWoVDWrwtzNZQhuBPjj9LH96Nn/TzRo1kpmn77D3OB36ghePn+CqjVqI+H9O7x9E4Y//5oOq7LlAAB/DBoBn6P7EBb6TOb763N0Hz4lfsTvvQfi1vXLhXeiRN8h9zmabm5u6NevH548eQK1L5Kk1q1bw9/fX46RyVdGRgbOnj6J5KQkVKpaDQCQnJyEWVPHw238VBgaGX93DJ8TR6Gmpo4mzVoIHS4VgGrVf8P1awF4+SIUAPD40UME37yJevUbyjkyKggVKlXD7ZvX8ebVSwBA6NPHeHA3GDVq1/uiT1UEXrmI2OgoSCQS3LkViPDXYahes47MWP5nT6FP+6YY2e93bNuwEinJ2S/5rV8+H33aN8W4Yb1x9uRhFNFZUr+szIwMZGZmQEVVLNOuKhbj4d3gbP3T0tLge+IgNDS1pEmlto4eLCxL4aLvcSQnJSEjIx1njh+Arp4Bypb/d8rMqxfPsW/bBoyYMAsikdz/Wf9pcXkjYci9ohkYGIh169Zlay9evDgiIiK+u39KSgpSUlJk21KVIRaLv7JH0fbs6WMM7dcTqampUFfXwN8LV6B0maxq5orFC1C56m9o0LhprsY6ceQAHFu2lqlyUtHVb8BgJH5MRKd2raGsrIyMjAy4jhyN1m3ayjs0KgCdevbDp0+JGOHSCUpKysjMzECvAa5o1Ly1tM+gkROwevFcDOzaEsrKxSBSEuHPsdNQqZqdtE/DZi1hbGoOAyNjvHj2BNvWr8CbVy8wcfZiaZ8e/bLm8InV1BB84yrWL5uP5KQk6SV6Ep66hiZsbKti//aNKFGyNHT1DXDp3Gk8vn8HZhaW0n43AvyxdO5kpKQkQ9/ACDM8VkNHN+uyuUgkwsyFa7Bg+lj80bYBRCIl6OrrY+r8ldDSzpp3nZaaiqXzJqPP4NEwNjVH5P/n+BMVFXJPNMViMRISErK1P378GMbG36/aubu7Y9asWTJtf02chvGTpxdYjIWpZCkrbNl5AB8/fsQFvzOYN3MyVq73wptXYbh54xo279ifq3Hu3g7Gi9DnmDp7vsARU0HxPX0Kp04cw98LFqFMWWs8evQQixf8Lb0piH5uly/4wv/sKYyZ+jdKWpVB6NNH2OS5GPqGxmjaMuuPiROHduPxgzuYPG8pjE3Ncf/2TaxfPh8GRsaoZmcPIOty+melypSDvqERZowdirdvXsG8eFYC07XPIGmfMuUqIDkpCYf3bGWiWchGTpoNz4WzMahbSygpKaNMuQqo38QJz548kPapXL0WFq3fhQ/v4+F74hAWz5mI+au8oatvAIlEgg0rFkBHzwBzl22EqqoYZ08dhvvUMfBYvRX6hsbYvnEVSpQsLfMHC+WPghceBSP3RLNdu3aYPXs29u7dCyDrL7iwsDBMmDABnTt3/s7ewKRJk+Dm5ibTlpD6896FrKKiihKWpQAAFSpWwoP7d7Fv13aI1cR48/oVWjVxkOk/dfxoVK1uh1XrvWTajx0+gHLlK6BCxUqFFTr9oGWLF6LvgEFwauUMAChX3gYR4eHYsnE9E81fgPfaZejUo6/0zu9SZcohOjICB3duQdOWbZGSkowdG1dhwuzF0nmcVmXLI/TpYxzZs1WaaP7X5zuUI75INLP3qYx92zYgLTUVKqqqApwd5cTMwhJzlm5AclISkj59hL6hMRbPmQhT839vclVTV4d5cUuYF7dEedsqcO3TAX6nDqNTz/64cysQQVf/gffh89DQzLobe3D5iggJuobzZ46jU49+uBsciLDQp/i9ud//R8yaItG3YzN07tUf3fsOLezTJpIh90Rz8eLF6NKlC0xMTJCUlIRGjRohIiICDg4OmDdv3nf3F4vF2S6Tp/ykyxvlRJKZibS0VAwY4oq27bvIbOvTvQNGuE1AvQaNZdo/fUrEubM+GOo6uvACpR+WnJwEJSXZ+VVKykrIlGTKKSIqSCkpydm/v0r/fn8z0tORnp4OUY59vj6/MvTpIwCAvuHXb/wJffYIWto6TDLlRE1dHWrq6vj4IQHBgQHoPXjUV/tm/c5PAwCkJCcDQPb/J0RKkPx/2adxMz2Q+sX0saeP7sNz4SzMXbYRZhYlCvpUfm0saQpC7ommrq4ufH19cfnyZYSEhODjx4+oUaMGHB0d5R1aoVu7ainq1G0AUzNzfPqUCF+fE7gVFIglK9fD0Mg4xxuATM3MYVFc9pfJuTM+yMjIQIvWOc/te/Io67JNUtInxL97hyePHqCYiop0LijJR8NGTbBp/VqYmZujbFlrPHz4ANu3eqF9h38r++/fxyPi7VtER2UtX/Li/zcOGRoZwej//3/ExEQjNiYGr8LCAABPnjyGpqYmzMzNoaurV7gnRVK1HBpi//ZNMDIxQ8nSZfH8yUMc3bcdzVplrSSgoamFStXs4L12GcRiMYxNzXEvJAgXzpxAvz+zrtq8ffMK//j5wM6+HrR19fDi2RNsXr0YtlVrwKpseQBA4JWLiH8Xh/K2VaCqqoqQG9dwYMdmtO/aW27nrqhuBV4BJICFZSlEvHmFreuXo3hJKzRt2RbJSUk4sGMTatVtBD1DI3x4Hw+fI3sRFxMNh0ZZ//7ZVKoCTS1trFwwA117D4Kqqhi+Jw8hKuIN7OpkLWX35XxPAEh4Hw8AKFGqNJe0oiJBrgu2p6WlQV1dHcHBwahcuXKBjfuzLtjuPnsaggKvIjYmGppa2ihbrjz+6DMAterk/ISk+jUrySzY/tnQ/r1gblEcM+Z6fHW//zIzt8D+Y74/fhJy8Kss2J6Y+BGrV63Aeb+zeBcXC2NjEzi1csbgYX9CRSWrEnX08EHMnDY5276Dh7li6J8jAABrV6/E+jWe2frMnPM32nXoJOxJFIKfdcH2pE+J2Ll5Na5dOo/3795B38gYDZo6oWufwdIHU7yLi8H2DSsRfOMqPiYkwNjUHM3bdEK733tBJBIhJioCS+dNRdiLZ0hJSoKRiSns6zfB770HSi+t3rx+Gds3rMLbN68AiQRmxS3Rsl0XNG/TKVtF9WfwMy/YfvnCGezYuAqxMVHQ0tZBnQbN0LP/n9DU0kZqagqWzZuCJw/uIiEhHto6urC2qYQuvQZIF3QHsiqUOzd74tmjB8jISIdlqTL4vfcg1LCvl+Mx7wbfwIyxQ7hgez68jE35fqd8KmX4c96gXBDk/mSgMmXK4NChQ6hWrVqBjfmzJpqUP79Kokm587MmmpQ/P3OiSXknz0QzLE64RLOkgeImmnL/83bKlCmYPHky4uLi5B0KERERERUguc/RXLVqFZ4+fQoLCwuUKlUKmpqaMttv3rwpp8iIiIhIUfBeIGHIPdFs3749RIq+bD4RERHRL0juczSFwDmaioVzNBUL52gqFs7RVCzynKP5+p1wczRL6HOOptyUKVMGsbGx2drj4+NRpkwZOURERERERAVB7pfOX7x4gYyMjGztKSkpeP36tRwiIiIiIsXDaXxCkFuiefToUenXp0+fhq6urvR9RkYG/Pz8ULp0aXmERkREREQFQG6JZocOHQBkPdvcxcVFZpuKigqsrKywePFiOURGREREiob3JQtDbolmZmbW831Lly6NwMBAGBl9/Tm9REREREJinikMud0MFBAQgOPHjyM0NFSaZG7duhWlS5eGiYkJBg8ejJQU4e4AIyIiIiJhyS3RnDVrFu7duyd9f+fOHQwYMACOjo6YOHEijh07Bnd3d3mFR0RERApEJBLupcjklmiGhISgWbNm0ve7d++Gvb09NmzYADc3N6xYsQJ79+6VV3hERERE9IPkNkfz3bt3MDU1lb6/ePEiWrVqJX1fq1YtvHr1Sh6hERERkYIRcZamIORW0TQ1NUVoaCgAIDU1FTdv3kSdOnWk2z98+AAVFRV5hUdEREREP0huiWbr1q0xceJE/PPPP5g0aRI0NDTQoEED6fbbt2+jbNmy8gqPiIiIFIlIwJcCk9ul8zlz5qBTp05o1KgRtLS04O3tDVVVVen2zZs3o0WLFvIKj4iIiIh+kEgikUjkGcD79++hpaUFZWVlmfa4uDhoaWnJJJ+5Ff0hvaDCo5+Ahlj5+53ol/Ey5pO8Q6BClJkp13+iqJBVLqElt2NHJqQJNrapjuJOBZT7s86/fPTklwwMDAo5EiIiIlJUir4MkVDkNkeTiIiIiH5tcq9oEhEREckblzcSBiuaRERERCQIVjSJiIiIWNAUBCuaRERERCQIVjSJiIhI4bGgKQxWNImIiIhIEKxoEhERkcLjOprCYKJJRERECo/LGwmDl86JiIiISBCsaBIREZHC46VzYbCiSURERESCYKJJRERERIJgoklEREREguAcTSIiIlJ4nKMpDFY0iYiIiEgQrGgSERGRwuM6msJgoklEREQKj5fOhcFL50REREQkCFY0iYiISOGxoCkMVjSJiIiISBCsaBIRERGxpCkIVjSJiIiISBCsaBIREZHC4/JGwmBFk4iIiIgEwYomERERKTyuoykMVjSJiIiISBCsaBIREZHCY0FTGEw0iYiIiJhpCoKXzomIiIhIEEw0iYiISOGJBPwvPzw9PWFlZQU1NTXY29vj+vXrBXzGhYOJJhEREVERsmfPHri5uWHGjBm4efMmqlWrBicnJ0RFRck7tDwTSSQSibyDKGjRH9LlHQIVIg2xsrxDoEL0MuaTvEOgQpSZ+cv9E0XfULmEltyOnSxg6qCWxzti7O3tUatWLaxatQoAkJmZCUtLS4wYMQITJ04UIELhsKJJREREJKCUlBQkJCTIvFJSUnLsm5qaiqCgIDg6OkrblJSU4OjoiICAgMIKucD8knedG2v/kqf1TSkpKXB3d8ekSZMgFovlHQ4JTJG/37YWmvIOodAp8vdbEfH7LR95rTrmxcy57pg1a5ZM24wZMzBz5sxsfWNiYpCRkQFTU1OZdlNTUzx8+FC4IAXyS146V0QJCQnQ1dXF+/fvoaOjI+9wSGD8fisWfr8VC7/fv56UlJRsFUyxWJzjHxLh4eEoXrw4rly5AgcHB2n7+PHjcfHiRVy7dk3weAuS4pX+iIiIiArR15LKnBgZGUFZWRmRkZEy7ZGRkTAzMxMiPEFxjiYRERFREaGqqgo7Ozv4+flJ2zIzM+Hn5ydT4fxZsKJJREREVIS4ubnBxcUFNWvWRO3atbFs2TIkJiaiX79+8g4tz5ho/iLEYjFmzJjBieMKgt9vxcLvt2Lh95u6deuG6OhoTJ8+HREREahevTp8fHyy3SD0M+DNQEREREQkCM7RJCIiIiJBMNEkIiIiIkEw0SQiIiIiQTDRpG+6cOECRCIR4uPj5R0KCcTLywt6enryDoO+gz+LRPQzYqJZiPr27QuRSIT58+fLtB8+fBgikUhOUVFufP7eiUQiqKiowNTUFM2bN8fmzZuRmZkp7/B+SLdu3fD48WN5h/FLCAgIgLKyMpydnQt87Lp16+Lt27fQ1dXN9T5WVlZYtmxZgcdCOYuOjsawYcNQsmRJiMVimJmZwcnJCZcvXwYAiEQiHD58WL5BEhUyJpqFTE1NDQsWLMC7d+8KbMzU1NQCG4u+rmXLlnj79i1evHiBU6dOoUmTJhg1ahTatGmD9PR0wY4r9PdXXV0dJiYmgh5DUWzatAkjRoyAv78/wsPDC3RsVVVVmJmZ8Y/SIqxz5864desWvL298fjxYxw9ehSNGzdGbGxsrsfg73P61fyvvTuPiuq64wD+RYYZYIaRNQKCg4IiGCRBjy141GCxcJJYUJQYUUBRQCG4UqWJSiQqmtAotrGeRJagNhIFgggBixCJoEGUwVaDSAbcsNa1GZFF+PUPD68Om7igif4+58w5vHvvu9u897i8++6DB5rPmIeHB8zNzbFhw4Zu0+zbtw8jRoyARCKBjY0N4uPjNeJtbGwQGxuLgIAAyOVyhISECNOf2dnZsLe3h76+PqZNm4aGhgakpKTAxsYGRkZGiIyMRGtrq5BXamoqRo8eDQMDA5ibm2PmzJm4evVqn7X/16z9DsXAgQPh4uKCP/3pT/jmm2+Qm5uL5ORkAMCtW7cwb948mJmZQS6XY+LEiVAqlUIeMTExeO2117B9+3ZYW1tDX18ffn5+uH37tpAmKCgIPj4+WLduHSwtLWFvbw8AuHDhAvz8/GBoaAhjY2N4e3ujtrZW2K+oqAhjxoyBVCqFoaEhxo4di7q6OgCAUqmEu7s7DAwMIJfLMWrUKBw/fhxA11Pn27Ztg62tLcRiMezt7ZGamqoRr6WlhS+++AJTpkyBvr4+hg4diqysrKfV1b9KarUae/bswYIFC/DWW28JxwTw/2nvgoICjB49Gvr6+nBzc0NVVRUAgIjg4eEBT09PtL9x7saNG7CyssLq1as18nhw6vz777/HuHHjoKenB2tra0RGRuLOnTsAgDfeeAN1dXVYsmSJcDf+zp07kMvl2Lt3r0bdMzMzIZVK8fPPP/dhD73Ybt26heLiYmzcuBHu7u5QKBQYM2YMoqOj8Yc//AE2NjYAgClTpkBLS0vYbr8mfPHFFxg8eDB0dXWF/Hq6lvR0TtfV1WHy5MkwMjKCVCrFiBEjkJOT80z7g7F2PNB8xrS1tbF+/Xps3boVFy9e7BRfXl4OPz8/zJgxA6dOnUJMTAxWrVql8UsLAD755BM4Ozvj5MmTWLVqFQCgoaEBCQkJ+Oqrr/Dtt9+iqKgIU6ZMQU5ODnJycpCamort27dr/JJpaWlBbGwslEolMjMzUVtbi6CgoL7sghfKxIkT4ezsjPT0dADA9OnTcfXqVeTm5qK8vBwuLi743e9+hxs3bgj7nDt3Dmlpadi/fz++/fZbnDx5EgsXLtTIt6CgAFVVVTh48CCys7PR0tICT09PGBgYoLi4GEeOHIFMJoOXlxeam5tx7949+Pj4YMKECaisrERpaSlCQkKEu1/+/v6wsrJCWVkZysvLsXLlSujo6HTZpoyMDCxatAjLli3DP//5T4SGhmLOnDkoLCzUSPfhhx/Cz88PlZWVePPNN+Hv76/RzpdNWloahg8fDnt7e8yaNQuJiYno+Jri999/H/Hx8Th+/DhEIhHmzp0L4P7APSUlBWVlZUhISAAAhIWFYeDAgcJAs6Oamhp4eXnB19cXlZWV2LNnD77//ntEREQAANLT02FlZYW1a9eivr4e9fX1kEqlmDFjBpKSkjTySkpKwrRp02BgYPC0u+WlIZPJIJPJkJmZiaampk7xZWVlAO73dX19vbAN3L8m7Nu3D+np6aioqADw8GtJT+d0eHg4mpqacPjwYZw6dQobN26ETCbr4x5grBvEnpnAwEDy9vYmIqLf/va3NHfuXCIiysjIoPavYubMmTRp0iSN/aKiosjR0VHYVigU5OPjo5EmKSmJANC5c+eEsNDQUNLX16eff/5ZCPP09KTQ0NBu61hWVkYAhH0KCwsJAN28efPRG/wCefC76+idd94hBwcHKi4uJrlcTo2NjRrxtra2tH37diIiWrNmDWlra9PFixeF+NzcXOrXrx/V19cLZQ0YMICampqENKmpqWRvb09tbW1CWFNTE+np6VFeXh5dv36dAFBRUVGXdTQwMKDk5OQu45KSkqh///7CtpubG82fP18jzfTp0+nNN98UtgHQBx98IGyr1WoCQLm5uV2W8TJwc3OjzZs3ExFRS0sLmZqaUmFhIRH9/zz6xz/+IaQ/cOAAAaC7d+8KYWlpaaSrq0srV64kqVRKZ8+eFeI6novBwcEUEhKiUYfi4mLq16+fkKdCoaBPP/1UI82xY8dIW1ubLl++TERE//73v0kkEnV77LDe27t3LxkZGZGuri65ublRdHQ0KZVKIR4AZWRkaOyzZs0a0tHRoatXrwphvbmW9HROOzk5UUxMzFNqFWNPhu9oPicbN25ESkoKzpw5oxF+5swZjB07ViNs7NixqK6u1pjyHj16dKc89fX1YWtrK2wPGDAANjY2Gn/JDhgwQGNqvLy8HJMnT8agQYNgYGCACRMmAADOnz//ZA18iRARtLS0oFQqoVarYWJiItzdkMlkUKlUqKmpEdIPGjQIAwcOFLZdXV3R1tYmTKMCgJOTE8RisbCtVCpx7tw5GBgYCPkaGxujsbERNTU1MDY2RlBQEDw9PTF58mRs2bIF9fX1wv5Lly7FvHnz4OHhgbi4OI36dNTdMdjxWB05cqTws1QqhVwuf2kfu6iqqsIPP/yAd999FwAgEonwzjvvYMeOHRrpHuwzCwsLANDos+nTp2PKlCmIi4vDJ598gqFDh3ZbplKpRHJyssax5unpiba2NqhUqm73GzNmDEaMGIGUlBQAwM6dO6FQKDB+/PhHbzjT4Ovri8uXLyMrKwteXl4oKiqCi4tLpxmpjhQKBczMzITt3lxLejqnIyMj8dFHH2Hs2LFYs2YNKisr+6S9jPUGDzSfk/Hjx8PT0xPR0dGPtb9UKu0U1nEqtH2FdMew9lXSd+7cgaenJ+RyOXbt2oWysjJkZGQA4AfSH8WZM2cwePBgqNVqWFhYoKKiQuNTVVWFqKioR8qz4/erVqsxatSoTnmfPXsWM2fOBHB/Sq60tBRubm7Ys2cPhg0bhqNHjwK4/xzYv/71L7z11ls4dOgQHB0dhe/6cfV0bL1sduzYgXv37sHS0hIikQgikQjbtm3Dvn37NJ6/fbDP2h9reLDPGhoaUF5eDm1tbVRXV/dYplqtRmhoqMbxoFQqUV1drfEHZ1fmzZsnDH6SkpIwZ84cXmT0lOjq6mLSpElYtWoVSkpKEBQUhDVr1vS4T1fn+8OuJT2d0/PmzcNPP/2E2bNn49SpUxg9ejS2bt3aNw1m7CF4oPkcxcXFYf/+/SgtLRXCHBwchFdhtDty5AiGDRsGbW3tp1r+jz/+iOvXryMuLg7jxo3D8OHDX9o7Uo/r0KFDOHXqFHx9feHi4oIrV65AJBLBzs5O42Nqairsc/78eY0VyUePHkW/fv2ERT9dcXFxQXV1NV555ZVOeT/4upvXX38d0dHRKCkpwauvvordu3cLccOGDcOSJUuQn5+PqVOndnpOr113x6Cjo+Mj98/L4N69e/jyyy8RHx/fadBnaWmJv//9773Oa9myZejXrx9yc3ORkJCAQ4cOdZvWxcUFp0+f7nQ82NnZCXfDxWKxxkxIu1mzZqGurg4JCQk4ffo0AgMDH73hrFccHR2FBVo6Ojpdfh8d9fZa0tM5bW1tjbCwMKSnp2PZsmX4/PPPn37jGOsFHmg+R05OTvD39xce/gfu/6IpKChAbGwszp49i5SUFPzlL3/B8uXLn3r5gwYNglgsxtatW/HTTz8hKysLsbGxT72cF0VTUxOuXLmCS5cu4cSJE1i/fj28vb3x9ttvIyAgAB4eHnB1dYWPjw/y8/NRW1uLkpISvP/++8JqUOD+HY/AwEAolUoUFxcjMjISfn5+MDc377Zsf39/mJqawtvbG8XFxVCpVCgqKkJkZCQuXrwIlUqF6OholJaWoq6uDvn5+aiuroaDgwPu3r2LiIgIFBUVoa6uDkeOHEFZWRkcHBy6LCsqKgrJycnYtm0bqqur8ec//xnp6el9cgy+CLKzs3Hz5k0EBwfj1Vdf1fj4+vp2mj7vzoEDB5CYmIhdu3Zh0qRJiIqKQmBgYLevQluxYgVKSkoQERGBiooKVFdX45tvvhEWAwH331Bx+PBhXLp0CdeuXRPCjYyMMHXqVERFReH3v/89rKysnqwTGK5fv46JEydi586dqKyshEqlwtdff41NmzbB29sbwP3vo6CgAFeuXOnxFXcPu5Y87JxevHgx8vLyoFKpcOLECRQWFnZ7vjPW5573Q6Ivk64WlKhUKhKLxfTgV7F3715ydHQkHR0dGjRoEH388cca+3T1gH/HBR1E9x8yd3Z27rEOu3fvJhsbG5JIJOTq6kpZWVkEgE6ePElEvBioXWBgIAEgACQSicjMzIw8PDwoMTGRWltbhXT//e9/6b333iNLS0vS0dEha2tr8vf3p/PnzxPR/7+Tzz77jCwtLUlXV5emTZtGN27c0Cirq4VH9fX1FBAQQKampiSRSGjIkCE0f/58un37Nl25coV8fHzIwsKCxGIxKRQKWr16NbW2tlJTUxPNmDGDrK2tSSwWk6WlJUVERAgLRro6dj777DMaMmQI6ejo0LBhw+jLL7/UiEcXixr69+9PSUlJj9/Jv1Jvv/22xkKpBx07dowA0JYtWzqdRydPniQApFKp6OrVqzRgwABav369EN/c3EyjRo0iPz8/Iur6XPzhhx9o0qRJJJPJSCqV0siRI2ndunVCfGlpKY0cOZIkEgl1vNwXFBQQAEpLS3sKvcAaGxtp5cqV5OLiQv379yd9fX2yt7enDz74gBoaGoiIKCsri+zs7EgkEpFCoSCirq/TRD1fSx52TkdERJCtrS1JJBIyMzOj2bNn07Vr155VVzCmQYuow/s3GGN9JiYmBpmZmcIrTBh7XlJTU7FkyRJcvnxZY+EZY4w9TaLnXQHGGGPPTkNDA+rr6xEXF4fQ0FAeZDLG+hQ/o8kYYy+RTZs2Yfjw4TA3N3/st14wxlhv8dQ5Y4wxxhjrE3xHkzHGGGOM9QkeaDLGGGOMsT7BA03GGGOMMdYneKDJGGOMMcb6BA80GWOMMcZYn+CBJmPssQUFBcHHx0fYfuONN7B48eJnXo+ioiJoaWnh1q1bfVZGx7Y+jmdRT8YY+yXhgSZjL5igoCBoaWlBS0sLYrEYdnZ2WLt2Le7du9fnZaenpyM2NrZXaZ/1oMvGxgabN29+JmUxxhi7j/8zEGMvIC8vLyQlJaGpqQk5OTkIDw+Hjo5Oly/obm5ufmr/HcbY2Pip5MMYY+zFwHc0GXsBSSQSmJubQ6FQYMGCBfDw8EBWVhaA/08Br1u3DpaWlrC3twcAXLhwAX5+fjA0NISxsTG8vb1RW1sr5Nna2oqlS5fC0NAQJiYm+OMf/4iO/++h49R5U1MTVqxYAWtra0gkEtjZ2WHHjh2ora2Fu7s7AMDIyAhaWloICgoCALS1tWHDhg0YPHgw9PT04OzsjL1792qUk5OTg2HDhkFPTw/u7u4a9Xwcra2tCA4OFsq0t7fHli1bukz74YcfwszMDHK5HGFhYWhubhbielP3B9XV1WHy5MkwMjKCVCrFiBEjkJOT80RtYYyxXxK+o8nYS0BPTw/Xr18XtgsKCiCXy3Hw4EEAQEtLCzw9PeHq6ori4mKIRCJ89NFH8PLyQmVlJcRiMeLj45GcnIzExEQ4ODggPj4eGRkZmDhxYrflBgQEoLS0FAkJCXB2doZKpcK1a9dgbW2Nffv2wdfXF1VVVZDL5dDT0wMAbNiwATt37sTf/vY3DB06FIcPH8asWbNgZmaGCRMm4MKFC5g6dSrCw8MREhKC48ePY9myZU/UP21tbbCyssLXX38NExMTlJSUICQkBBYWFvDz89PoN11dXRQVFaG2thZz5syBiYkJ1q1b16u6dxQeHo7m5mYcPnwYUqkUp0+fhkwme6K2MMbYLwoxxl4ogYGB5O3tTUREbW1tdPDgQZJIJLR8+XIhfsCAAdTU1CTsk5qaSvb29tTW1iaENTU1kZ6eHuXl5RERkYWFBW3atEmIb2lpISsrK6EsIqIJEybQokWLiIioqqqKANDBgwe7rGdhYSEBoJs3bwphjY2NpK+vTyUlJRppg4OD6d133yUioujoaHJ0dNSIX7FiRae8OlIoFPTpp592G99ReHg4+fr6CtuBgYFkbGxMd+7cEcK2bdtGMpmMWltbe1X3jm12cnKimJiYXteJMcZ+bfiOJmMvoOzsbMhkMrS0tKCtrQ0zZ85ETEyMEO/k5KTxXKZSqcS5c+dgYGCgkU9jYyNqampw+/Zt1NfX4ze/+Y0QJxKJMHr06E7T5+0qKiqgra3d5Z287pw7dw4NDQ2YNGmSRnhzczNef/11AMCZM2c06gEArq6uvS6jO3/961+RmJiI8+fP4+7du2hubsZrr72mkcbZ2Rn6+voa5arValy4cAFqtfqhde8oMjISCxYsQH5+Pjw8PODr64uRI0c+cVsYY+yXggeajL2A3N3dsW3bNojFYlhaWkIk0jzVpVKpxrZarcaoUaOwa9euTnmZmZk9Vh3ap8IfhVqtBgAcOHAAAwcO1IiTSCSPVY/e+Oqrr7B8+XLEx8fD1dUVBgYG+Pjjj3Hs2LFe5/E4dZ83bx48PT1x4MAB5OfnY8OGDYiPj8d77733+I1hjLFfEB5oMvYCkkqlsLOz63V6FxcX7NmzB6+88grkcnmXaSwsLHDs2DGMHz8eAHDv3j2Ul5fDxcWly/ROTk5oa2vDd999Bw8Pj07x7XdUW1tbhTBHR0dIJBKcP3++2zuhDg4OwsKmdkePHn14I3tw5MgRuLm5YeHChUJYTU1Np3RKpRJ3794VBtFHjx6FTCaDtbU1jI2NH1r3rlhbWyMsLAxhYWGIjo7G559/zgNNxtgLg1edM8bg7+8PU1NTeHt7o7i4GCqVCkVFRYiMjMTFixcBAIsWLUJcXBwyMzPx448/YuHChT2+A9PGxgaBgYGYO3cuMjMzhTzT0tIAAAqFAlpaWsjOzsZ//vMfqNVqGBgYYPny5ViyZAlSUlJQU1ODEydOYOvWrUhJSQEAhIWFobq6GlFRUaiqqsLu3buRnJzcq3ZeunQJFRUVGp+bN29i6NChOH78OPLy8nD27FmsWrUKZWVlnfZvbm5GcHAwTp8+jZycHKxZswYRERHo169fr+re0eLFi5GXlweVSoUTJ06gsLAQDg4OvWoLY4z9Kjzvh0QZY0/Xg4uBHiW+vr6eAgICyNTUlCQSCQ0ZMoTmz59Pt2/fJqL7i38WLVpEcrmcDA0NaenSpRQQENDtYiAiort379KSJUvIwsKCxGIx2dnZUWJiohC/du1aMjc3Jy0tLQoMDCSi+wuYNm/eTPb29qSjo0NmZmbk6elJ3333nbDf/v37yc7OjiQSCY0bN44SExN7tRgIQKdPamoqNTY2UlBQEPXv358MDQ1pwYIFtHLlSnJ2du7Ub6tXryYTExOSyWQ0f/58amxsFNI8rO4dFwNFRESQra0tSSQSMjMzo9mzZ9O1a9e6bQNjjP3aaBF18yQ/Y4wxxhhjT4CnzhljjDHGWJ/ggSZjjDHGGOsTPNBkjDHGGGN9ggeajDHGGGOsT/BAkzHGGGOM9QkeaDLGGGOMsT7BA03GGGOMMdYneKDJGGOMMcb6BA80GWOMMcZYn+CBJmOMMcYY6xM80GSMMcYYY33if2IVJ8P7jCZAAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell 7\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Make predictions on the test set\n",
    "y_pred_probs = model.predict(X_test)  # Predict probabilities for each class\n",
    "y_pred = np.argmax(y_pred_probs, axis=1)  # Convert probabilities to class labels\n",
    "\n",
    "# Step 2: Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_labels = ['Normal','Depression', 'Anxiety', 'Stress']\n",
    "# Step 3: Plot the confusion matrix using Seaborn for better visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.ylabel('Actual Labels')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 6\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Standardizing the features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "scaler_path = './saved_models/scaler.save'\n",
    "joblib.dump(scaler, scaler_path)\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features_scaled, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "# Defining the model parameters\n",
    "num_classes = 4\n",
    "embed_dim = 256  # Increased embedding dimension\n",
    "num_heads = 8    # Increased number of attention heads\n",
    "ff_dim = 256    # Increased feedforward dimension\n",
    "num_layers = 1   # Increased number of transformer layers\n",
    "\n",
    "# Creating the Transformer model\n",
    "model = TransformerClassifier(num_classes, embed_dim, num_heads, ff_dim, num_layers)\n",
    "\n",
    "# Compile with modified learning rate and added metrics\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001, clipnorm=1.0),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Callbacks for training\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    min_lr=0.00001\n",
    ")\n",
    "\n",
    "# ModelCheckpoint callback to save the model at the end of each epoch\n",
    "save_directory = './saved_models/'\n",
    "os.makedirs(save_directory, exist_ok=True)\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=os.path.join(save_directory, 'emotion_classifier_epoch_{epoch:02d}.keras'),\n",
    "    save_freq='epoch',\n",
    "    save_best_only=False  # Change to True if only the best model should be saved\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stopping, reduce_lr, checkpoint_callback],\n",
    "    class_weight={\n",
    "        0: 1.0,  # Normal\n",
    "        1: 1.0,  # Depression\n",
    "        2: 1.0,  # Anxiety\n",
    "        3: 1.0   # Stress\n",
    "    }\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "\n",
      " Class         Precision    Recall    F1-Score    Support   \n",
      "\n",
      " Normal        0.71         0.72      0.71        64508     \n",
      "\n",
      " Depression    0.69         0.69      0.69        16682     \n",
      "\n",
      " Anxiety       0.64         0.73      0.69        69638     \n",
      "\n",
      " Stress        0.78         0.42      0.54        22521     \n",
      "\n",
      " macro avg     0.71         0.64      0.66        173349    \n",
      "\n",
      " weighted avg  0.69         0.68      0.68        173349    \n",
      "\n",
      " Accuracy      -            -         68.30%      -         \n",
      "\n",
      "\n",
      "Overall Metrics:\n",
      "\n",
      " Metric                Score   \n",
      "\n",
      " Accuracy              68.30%  \n",
      "\n",
      " Precision (weighted)  0.69    \n",
      "\n",
      " Recall (weighted)     0.68    \n",
      "\n",
      " F1-Score (weighted)   0.68    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 8\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Print classification report with improved formatting\n",
    "print(\"Classification Report:\")\n",
    "report = classification_report(y_test, y_pred, target_names=class_labels, output_dict=True)\n",
    "\n",
    "# Convert classification report to a table\n",
    "headers = [\"Class\", \"Precision\", \"Recall\", \"F1-Score\", \"Support\"]\n",
    "rows = [[cls, \n",
    "         f\"{metrics['precision']:.2f}\", \n",
    "         f\"{metrics['recall']:.2f}\", \n",
    "         f\"{metrics['f1-score']:.2f}\", \n",
    "         int(metrics['support'])] for cls, metrics in report.items() if cls != 'accuracy']\n",
    "\n",
    "# Add accuracy row separately\n",
    "accuracy_row = [\"Accuracy\", \"-\", \"-\", f\"{accuracy_score(y_test, y_pred) * 100:.2f}%\", \"-\"]\n",
    "rows.append(accuracy_row)\n",
    "\n",
    "# Print the table\n",
    "print(tabulate(rows, headers, tablefmt=\"fancy_grid\"))\n",
    "\n",
    "# Compute and display individual scores\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Display overall metrics in a formatted style\n",
    "print(\"\\nOverall Metrics:\")\n",
    "overall_metrics = [\n",
    "    [\"Metric\", \"Score\"],\n",
    "    [\"Accuracy\", f\"{accuracy * 100:.2f}%\"],\n",
    "    [\"Precision (weighted)\", f\"{precision:.2f}\"],\n",
    "    [\"Recall (weighted)\", f\"{recall:.2f}\"],\n",
    "    [\"F1-Score (weighted)\", f\"{f1:.2f}\"]\n",
    "]\n",
    "\n",
    "print(tabulate(overall_metrics, headers=\"firstrow\", tablefmt=\"fancy_grid\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\annek\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-01 11:51:03,226 - From C:\\Users\\annek\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:204: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "C:\\Users\\annek\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.5.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing ../test/destination_undersampling\\0_u00037s00001hw00001.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00037s00001hw00002.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00037s00001hw00003.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00037s00001hw00004.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00037s00001hw00005.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00037s00001hw00006.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00037s00001hw00007.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00039s00001hw00001.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00039s00001hw00002.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00039s00001hw00003.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00039s00001hw00004.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annek\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\saving\\serialization_lib.py:730: UserWarning: Model 'transformer_classifier_6' had a build config, but the model cannot be built automatically in `build_from_config(config)`. You should implement `def build_from_config(self, config)`, and you might also want to implement the method  that generates the config at saving time, `def get_build_config(self)`. The method `build_from_config()` is meant to create the state of the model (i.e. its variables) upon deserialization.\n",
      "  instance.build_from_config(build_config)\n",
      "C:\\Users\\annek\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\saving\\saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 42 variables whereas the saved optimizer has 50 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing ../test/destination_undersampling\\0_u00039s00001hw00005.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00039s00001hw00006.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00039s00001hw00007.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00040s00001hw00001.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00040s00001hw00002.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00040s00001hw00003.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00040s00001hw00004.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00040s00001hw00005.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00040s00001hw00006.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00040s00001hw00007.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00044s00001hw00001.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00044s00001hw00002.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00044s00001hw00003.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00044s00001hw00004.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00044s00001hw00005.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00044s00001hw00006.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00044s00001hw00007.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00045s00001hw00001.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00045s00001hw00002.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00045s00001hw00003.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00045s00001hw00004.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00045s00001hw00005.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00045s00001hw00006.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\0_u00045s00001hw00007.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00010s00001hw00001.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00010s00001hw00002.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00010s00001hw00003.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00010s00001hw00004.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00010s00001hw00005.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00010s00001hw00006.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00010s00001hw00007.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00011s00001hw00001.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00011s00001hw00002.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00011s00001hw00003.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00011s00001hw00004.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00011s00001hw00005.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00011s00001hw00006.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00011s00001hw00007.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00012s00001hw00001.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00012s00001hw00002.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00012s00001hw00003.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00012s00001hw00004.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00012s00001hw00005.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00012s00001hw00006.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00012s00001hw00007.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00021s00001hw00001.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00021s00001hw00002.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00021s00001hw00003.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00021s00001hw00004.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00021s00001hw00005.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00021s00001hw00006.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00021s00001hw00007.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00038s00001hw00001.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00038s00001hw00002.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00038s00001hw00003.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00038s00001hw00004.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00038s00001hw00005.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00038s00001hw00006.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\1_u00038s00001hw00007.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00033s00001hw00001.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00033s00001hw00002.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00033s00001hw00003.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00033s00001hw00004.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00033s00001hw00005.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00033s00001hw00006.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00033s00001hw00007.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00036s00001hw00001.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00036s00001hw00002.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00036s00001hw00003.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00036s00001hw00004.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00036s00001hw00005.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00036s00001hw00006.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00036s00001hw00007.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00041s00001hw00001.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00041s00001hw00002.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00041s00001hw00003.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00041s00001hw00004.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00041s00001hw00005.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00041s00001hw00006.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00041s00001hw00007.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00042s00001hw00001.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00042s00001hw00002.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00042s00001hw00003.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00042s00001hw00004.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00042s00001hw00005.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00042s00001hw00006.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00042s00001hw00007.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00043s00001hw00001.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00043s00001hw00002.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00043s00001hw00003.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00043s00001hw00004.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00043s00001hw00005.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00043s00001hw00006.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\2_u00043s00001hw00007.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00006s00001hw00001.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00006s00001hw00002.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00006s00001hw00003.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00006s00001hw00004.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00006s00001hw00005.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00006s00001hw00006.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00006s00001hw00007.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00019s00001hw00001.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00019s00001hw00002.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00019s00001hw00003.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00019s00001hw00004.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00019s00001hw00005.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00019s00001hw00006.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00019s00001hw00007.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00020s00001hw00001.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00020s00001hw00002.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00020s00001hw00003.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00020s00001hw00004.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00020s00001hw00005.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00020s00001hw00006.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00020s00001hw00007.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00021s00001hw00001.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00021s00001hw00002.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00021s00001hw00003.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00021s00001hw00004.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00021s00001hw00005.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00023s00001hw00001.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00023s00001hw00002.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00023s00001hw00003.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00023s00001hw00004.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00023s00001hw00005.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00023s00001hw00006.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "Error processing ../test/destination_undersampling\\3_u00023s00001hw00007.svc: Classification error: load_and_preprocess_file() takes 1 positional argument but 2 were given\n",
      "\n",
      "Directory Classification Results:\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "# New Cell 9 - Classifier using saved model\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def load_and_preprocess_file(file_path):\n",
    "    \"\"\"\n",
    "    Load and preprocess a single file for classification\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the file\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame([line.split() for line in lines])\n",
    "        \n",
    "        # Skip empty files\n",
    "        if df.empty:\n",
    "            raise ValueError(f\"File is empty after processing\")\n",
    "\n",
    "        # First row contains total number of rows\n",
    "        total_rows = int(df.iloc[0, 0])\n",
    "        \n",
    "        # Extract feature data\n",
    "        data = df.iloc[1:, :].values\n",
    "        \n",
    "        # Ensure each row has 7 features\n",
    "        reshaped_data = []\n",
    "        for row in data:\n",
    "            if len(row) == 7:\n",
    "                reshaped_data.append(row)\n",
    "        \n",
    "        if not reshaped_data:\n",
    "            raise ValueError(\"No valid data rows found\")\n",
    "        \n",
    "        # Convert to numpy array\n",
    "        reshaped_data = np.array(reshaped_data, dtype=float)\n",
    "        \n",
    "        # Extract features\n",
    "        time_features = extract_time_domain_features(reshaped_data)\n",
    "        freq_features = extract_frequency_domain_features(reshaped_data)\n",
    "        stat_features = extract_statistical_features(reshaped_data)\n",
    "        \n",
    "        # Combine features\n",
    "        combined_features = np.concatenate((time_features, freq_features, stat_features), axis=1)\n",
    "        combined_features = scaler.transform(combined_features)\n",
    "        return combined_features\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "def classify_emotion(model_path, scaler_path, file_path):\n",
    "    \"\"\"\n",
    "    Classify emotion using saved model and scaler and return confidences for all emotions\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the saved model and scaler\n",
    "        model = load_model(model_path)\n",
    "        scaler = joblib.load(scaler_path)\n",
    "        \n",
    "        # Process the input file\n",
    "        features = load_and_preprocess_file(file_path, scaler)\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = model.predict(features)\n",
    "        \n",
    "        # Calculate mean probabilities across all sequences\n",
    "        mean_probabilities = np.mean(prediction, axis=0)\n",
    "        \n",
    "        # Map class indices to labels\n",
    "        class_labels = ['Normal', 'Depression', 'Anxiety', 'Stress']\n",
    "        \n",
    "        # Create sorted list of (emotion, confidence) tuples\n",
    "        emotion_confidences = [\n",
    "            (label, float(prob * 100))\n",
    "            for label, prob in zip(class_labels, mean_probabilities)\n",
    "        ]\n",
    "        # Sort by confidence in descending order\n",
    "        emotion_confidences.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # The predicted emotion is the first one (highest confidence)\n",
    "        predicted_emotion = emotion_confidences[0][0]\n",
    "        \n",
    "        return predicted_emotion, emotion_confidences\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Classification error: {e}\")\n",
    "\n",
    "def classify_directory(model_path, scaler_path, directory_path):\n",
    "    \"\"\"\n",
    "    Classify all .svc files in a directory\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Find all .svc files\n",
    "    file_paths = glob.glob(os.path.join(directory_path, \"*.svc\"))\n",
    "    \n",
    "    if not file_paths:\n",
    "        raise ValueError(\"No .svc files found in the directory\")\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            predicted_emotion, emotion_confidences = classify_emotion(\n",
    "                model_path, scaler_path, file_path\n",
    "            )\n",
    "            results.append({\n",
    "                'file': os.path.basename(file_path),\n",
    "                'predicted_emotion': predicted_emotion,\n",
    "                'confidences': emotion_confidences\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to your saved model\n",
    "    model_path = '../trainmodel/Original Only.keras'\n",
    "    scaler_path = '../trainmodel/Original Only.save'\n",
    "    # Example 1: Classify a single file\n",
    "    # try:\n",
    "    #     file_path = './input_files/u00075s00001_hw00002.svc'\n",
    "    #     emotion, confidence = classify_emotion(model_path, file_path)\n",
    "    #     print(f\"\\nFile: {os.path.basename(file_path)}\")\n",
    "    #     print(f\"Predicted Emotion: {emotion}\")\n",
    "    #     print(f\"Confidence: {confidence:.2f}%\")\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Error classifying single file: {e}\")\n",
    "    \n",
    "    # Example 2: Classify all files in a directory\n",
    "    try:\n",
    "        directory_path = '../test/destination_undersampling/'\n",
    "        # directory_path = '../test/label copy/'\n",
    "        results = classify_directory(model_path, scaler_path, directory_path)\n",
    "        \n",
    "        print(\"\\nDirectory Classification Results:\")\n",
    "        print(\"================================\")\n",
    "        for result in results:\n",
    "            print(f\"\\nFile: {result['file']}\")\n",
    "            print(f\"Predicted Emotion: {result['predicted_emotion']}\")\n",
    "            print(f\"Confidence: {result['confidence']:.2f}%\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error classifying directory: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annek\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.5.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "2024-12-01 12:03:19,571 - Starting time-domain feature extraction\n",
      "2024-12-01 12:03:19,580 - Feature extraction completed in 0:00:00.005001\n",
      "2024-12-01 12:03:19,583 - Starting frequency-domain feature extraction\n",
      "2024-12-01 12:03:19,587 - Frequency-domain feature extraction completed in 0:00:00.002002\n",
      "2024-12-01 12:03:19,589 - Starting statistical feature extraction\n",
      "2024-12-01 12:03:19,589 - Statistical feature extraction completed in 0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m55/55\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step\n",
      "0_u00037s00001hw00001.svc: Prediction - Anxiety | Confidence: 77.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annek\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.5.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "2024-12-01 12:03:23,553 - Starting time-domain feature extraction\n",
      "2024-12-01 12:03:23,555 - Feature extraction completed in 0:00:00.000408\n",
      "2024-12-01 12:03:23,555 - Starting frequency-domain feature extraction\n",
      "2024-12-01 12:03:23,555 - Frequency-domain feature extraction completed in 0:00:00\n",
      "2024-12-01 12:03:23,555 - Starting statistical feature extraction\n",
      "2024-12-01 12:03:23,575 - Statistical feature extraction completed in 0:00:00.019816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m103/103\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step\n",
      "0_u00037s00001hw00002.svc: Prediction - Depression | Confidence: 62.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annek\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.5.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "2024-12-01 12:03:28,013 - Starting time-domain feature extraction\n",
      "2024-12-01 12:03:28,019 - Feature extraction completed in 0:00:00.005697\n",
      "2024-12-01 12:03:28,021 - Starting frequency-domain feature extraction\n",
      "2024-12-01 12:03:28,024 - Frequency-domain feature extraction completed in 0:00:00.002003\n",
      "2024-12-01 12:03:28,025 - Starting statistical feature extraction\n",
      "2024-12-01 12:03:28,039 - Statistical feature extraction completed in 0:00:00.011739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m98/98\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step\n",
      "0_u00037s00001hw00003.svc: Prediction - Depression | Confidence: 62.05%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 157\u001b[0m\n\u001b[0;32m    153\u001b[0m results_txt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./classification_results.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# Classify files and export correct classifications to Excel and txt\u001b[39;00m\n\u001b[1;32m--> 157\u001b[0m     \u001b[43mclassify_directory_with_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_directory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_excel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_txt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError during classification: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[9], line 119\u001b[0m, in \u001b[0;36mclassify_directory_with_labels\u001b[1;34m(model_path, scaler_path, directory_path, output_excel, results_txt)\u001b[0m\n\u001b[0;32m    116\u001b[0m true_label \u001b[38;5;241m=\u001b[39m label_map\u001b[38;5;241m.\u001b[39mget(label_key)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;66;03m# Classify the file\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m predicted_emotion, emotion_confidences \u001b[38;5;241m=\u001b[39m \u001b[43mclassify_emotion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_txt\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Check if the prediction is correct\u001b[39;00m\n\u001b[0;32m    124\u001b[0m is_correct \u001b[38;5;241m=\u001b[39m predicted_emotion \u001b[38;5;241m==\u001b[39m true_label\n",
      "Cell \u001b[1;32mIn[9], line 50\u001b[0m, in \u001b[0;36mclassify_emotion\u001b[1;34m(model_path, scaler_path, file_path, results_file)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclassify_emotion\u001b[39m(model_path, scaler_path, file_path, results_file):\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m         model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m         scaler \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(scaler_path)\n\u001b[0;32m     53\u001b[0m         filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(file_path)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\saving\\saving_api.py:187\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    184\u001b[0m         is_keras_zip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_keras_zip \u001b[38;5;129;01mor\u001b[39;00m is_keras_dir:\n\u001b[1;32m--> 187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msaving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[43msafe_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m legacy_h5_format\u001b[38;5;241m.\u001b[39mload_model_from_hdf5(\n\u001b[0;32m    195\u001b[0m         filepath, custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects, \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m\n\u001b[0;32m    196\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\saving\\saving_lib.py:365\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    361\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid filename: expected a `.keras` extension. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m     )\n\u001b[0;32m    364\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filepath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m--> 365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_model_from_fileobj\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe_mode\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\saving\\saving_lib.py:489\u001b[0m, in \u001b[0;36m_load_model_from_fileobj\u001b[1;34m(fileobj, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    487\u001b[0m     failed_saveables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m    488\u001b[0m     error_msgs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 489\u001b[0m     \u001b[43m_load_state\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massets_store\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masset_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43minner_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvisited_saveables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfailed_saveables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfailed_saveables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_msgs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_msgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weights_store:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\saving\\saving_lib.py:740\u001b[0m, in \u001b[0;36m_load_state\u001b[1;34m(saveable, weights_store, assets_store, inner_path, skip_mismatch, visited_saveables, failed_saveables, error_msgs)\u001b[0m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child_attr, child_obj \u001b[38;5;129;01min\u001b[39;00m _walk_saveable(saveable):\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(child_obj, KerasSaveable):\n\u001b[1;32m--> 740\u001b[0m         \u001b[43m_load_state\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    741\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchild_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    742\u001b[0m \u001b[43m            \u001b[49m\u001b[43mweights_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    743\u001b[0m \u001b[43m            \u001b[49m\u001b[43massets_store\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    744\u001b[0m \u001b[43m            \u001b[49m\u001b[43minner_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild_attr\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    745\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    746\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    747\u001b[0m \u001b[43m            \u001b[49m\u001b[43mskip_mismatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_mismatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    748\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvisited_saveables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisited_saveables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfailed_saveables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfailed_saveables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m            \u001b[49m\u001b[43merror_msgs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_msgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(child_obj, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mdict\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mset\u001b[39m)):\n\u001b[0;32m    753\u001b[0m         _load_container_state(\n\u001b[0;32m    754\u001b[0m             child_obj,\n\u001b[0;32m    755\u001b[0m             weights_store,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    763\u001b[0m             error_msgs\u001b[38;5;241m=\u001b[39merror_msgs,\n\u001b[0;32m    764\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\saving\\saving_lib.py:713\u001b[0m, in \u001b[0;36m_load_state\u001b[1;34m(saveable, weights_store, assets_store, inner_path, skip_mismatch, visited_saveables, failed_saveables, error_msgs)\u001b[0m\n\u001b[0;32m    711\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m skip_mismatch \u001b[38;5;129;01mor\u001b[39;00m failed_saveables \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 713\u001b[0m         \u001b[43msaveable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_own_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43minner_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    714\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    715\u001b[0m         failed_saveables\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(saveable))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:597\u001b[0m, in \u001b[0;36mBaseOptimizer.load_own_variables\u001b[1;34m(self, store)\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, variable \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables):\n\u001b[1;32m--> 597\u001b[0m     \u001b[43mvariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\common\\variables.py:224\u001b[0m, in \u001b[0;36mKerasVariable.assign\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massign\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[1;32m--> 224\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m shape_equal(value\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape):\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    227\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe shape of the target variable and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    228\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe shape of the target value in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    232\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget variable: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    233\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:66\u001b[0m, in \u001b[0;36mVariable._convert_to_tensor\u001b[1;34m(self, value, dtype)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convert_to_tensor\u001b[39m(\u001b[38;5;28mself\u001b[39m, value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:125\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(x, dtype, sparse)\u001b[0m\n\u001b[0;32m    123\u001b[0m         x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcast(x, dtype)\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m dtype:\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, tf\u001b[38;5;241m.\u001b[39mSparseTensor):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\framework\\tensor_conversion.py:161\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m\u001b[38;5;241m.\u001b[39mtf_export(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvert_to_tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m     97\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_to_tensor_v2_with_dispatch\u001b[39m(\n\u001b[0;32m     99\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype_hint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    100\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m tensor_lib\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m    101\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m  This function converts Python objects of various types to `Tensor`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;124;03m    ValueError: If the `value` is a tensor not of given `dtype` in graph mode.\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 161\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_to_tensor_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\framework\\tensor_conversion.py:171\u001b[0m, in \u001b[0;36mconvert_to_tensor_v2\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;66;03m# preferred_dtype = preferred_dtype or dtype_hint\u001b[39;00m\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_hint\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[0;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    226\u001b[0m           _add_error_prefix(\n\u001b[0;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m    237\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\framework\\constant_tensor_conversion.py:29\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constant_op  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[0;32m     28\u001b[0m _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    144\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\framework\\constant_op.py:276\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(\n\u001b[0;32m    179\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    180\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ops\u001b[38;5;241m.\u001b[39mOperation, ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase]:\n\u001b[0;32m    181\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 276\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\framework\\constant_op.py:289\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    288\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> 289\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    291\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39m_create_graph_constant(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    292\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[0;32m    293\u001b[0m )\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\framework\\constant_op.py:301\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(\n\u001b[0;32m    298\u001b[0m     ctx, value, dtype, shape, verify_shape\n\u001b[0;32m    299\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase:\n\u001b[0;32m    300\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 301\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow\\python\\framework\\constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\h5py\\_hl\\dataset.py:1063\u001b[0m, in \u001b[0;36mDataset.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1061\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\n\u001b[1;32m-> 1063\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_direct\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\h5py\\_hl\\dataset.py:1024\u001b[0m, in \u001b[0;36mDataset.read_direct\u001b[1;34m(self, dest, source_sel, dest_sel)\u001b[0m\n\u001b[0;32m   1021\u001b[0m     dest_sel \u001b[38;5;241m=\u001b[39m sel\u001b[38;5;241m.\u001b[39mselect(dest\u001b[38;5;241m.\u001b[39mshape, dest_sel)\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mspace \u001b[38;5;129;01min\u001b[39;00m dest_sel\u001b[38;5;241m.\u001b[39mbroadcast(source_sel\u001b[38;5;241m.\u001b[39marray_shape):\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdxpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dxpl\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Cell 4 - Define preprocessing and classification functions\n",
    "def load_and_preprocess_file(file_path, scaler):\n",
    "    \"\"\"\n",
    "    Load and preprocess a single file for classification\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the file\n",
    "        with open(file_path, 'r') as f:\n",
    "            lines = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame([line.split() for line in lines])\n",
    "        \n",
    "        if df.empty:\n",
    "            raise ValueError(f\"File is empty after processing\")\n",
    "\n",
    "        # First row contains total number of rows\n",
    "        total_rows = int(df.iloc[0, 0])\n",
    "        \n",
    "        # Extract feature data\n",
    "        data = df.iloc[1:, :].values\n",
    "        \n",
    "        # Ensure each row has 7 features\n",
    "        reshaped_data = []\n",
    "        for row in data:\n",
    "            if len(row) == 7:\n",
    "                reshaped_data.append(row)\n",
    "        \n",
    "        if not reshaped_data:\n",
    "            raise ValueError(\"No valid data rows found\")\n",
    "        \n",
    "        # Convert to numpy array\n",
    "        reshaped_data = np.array(reshaped_data, dtype=float)\n",
    "        \n",
    "        # Extract features\n",
    "        time_features = extract_time_domain_features(reshaped_data)\n",
    "        freq_features = extract_frequency_domain_features(reshaped_data)\n",
    "        stat_features = extract_statistical_features(reshaped_data)\n",
    "        \n",
    "        # Combine features\n",
    "        combined_features = np.concatenate((time_features, freq_features, stat_features), axis=1)\n",
    "        combined_features = scaler.transform(combined_features)\n",
    "        return combined_features\n",
    "        \n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Error processing file {file_path}: {e}\")\n",
    "\n",
    "def classify_emotion(model_path, scaler_path, file_path, results_file):\n",
    "    \"\"\"\n",
    "    Classify emotion using saved model and scaler with detailed logging\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the saved model and scaler\n",
    "        model = load_model(model_path)\n",
    "        scaler = joblib.load(scaler_path)\n",
    "        \n",
    "        # Get filename\n",
    "        filename = os.path.basename(file_path)\n",
    "        \n",
    "        # Process the input file\n",
    "        features = load_and_preprocess_file(file_path, scaler)\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = model.predict(features)\n",
    "        \n",
    "        # Calculate mean probabilities across all sequences\n",
    "        mean_probabilities = np.mean(prediction, axis=0)\n",
    "        \n",
    "        # Map class indices to labels\n",
    "        class_labels = ['Normal', 'Depression', 'Anxiety', 'Stress']\n",
    "        \n",
    "        # Create sorted list of (emotion, confidence) tuples\n",
    "        emotion_confidences = sorted(\n",
    "            [(label, float(prob * 100)) for label, prob in zip(class_labels, mean_probabilities)], \n",
    "            key=lambda x: x[1], \n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        # Prepare results string\n",
    "        results_str = f\"{filename}: Overall Prediction - {emotion_confidences[0][0]} | Confidence Levels: \" + \\\n",
    "                      \", \".join([f\"{emotion}: {conf:.2f}%\" for emotion, conf in emotion_confidences])\n",
    "        \n",
    "        # Print results\n",
    "        print(results_str)\n",
    "        \n",
    "        # Append results to file\n",
    "        with open(results_file, 'a') as f:\n",
    "            f.write(results_str + '\\n')\n",
    "        \n",
    "        return emotion_confidences[0][0], emotion_confidences\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error processing {filename}: {e}\"\n",
    "        print(error_msg)\n",
    "        \n",
    "        # Log errors to file\n",
    "        with open(results_file, 'a') as f:\n",
    "            f.write(error_msg + '\\n')\n",
    "        \n",
    "        raise\n",
    "\n",
    "\n",
    "# Cell 6 - Import additional library for exporting to Excel\n",
    "import xlsxwriter\n",
    "\n",
    "# Update the classify_directory function to include label verification and export to Excel\n",
    "def classify_directory_with_labels(model_path, scaler_path, directory_path, output_excel, results_txt):\n",
    "    \"\"\"\n",
    "    Classify all .svc files in a directory, verify classifications against labels in filenames,\n",
    "    and export results to Excel and txt\n",
    "    \"\"\"\n",
    "    # Clear existing results file\n",
    "    open(results_txt, 'w').close()\n",
    "    \n",
    "    results = []\n",
    "    label_map = {'0': 'Normal', '1': 'Depression', '2': 'Anxiety', '3': 'Stress'}\n",
    "    \n",
    "    # Find all .svc files\n",
    "    file_paths = glob.glob(os.path.join(directory_path, \"*.svc\"))\n",
    "    \n",
    "    if not file_paths:\n",
    "        raise ValueError(\"No .svc files found in the directory\")\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        try:\n",
    "            # Extract true label from filename\n",
    "            filename = os.path.basename(file_path)\n",
    "            label_key = filename[0]\n",
    "            true_label = label_map.get(label_key)\n",
    "            \n",
    "            # Classify the file\n",
    "            predicted_emotion, emotion_confidences = classify_emotion(\n",
    "                model_path, scaler_path, file_path, results_txt\n",
    "            )\n",
    "            \n",
    "            # Check if the prediction is correct\n",
    "            is_correct = predicted_emotion == true_label\n",
    "            \n",
    "            # Store the result if classification was correct\n",
    "            if is_correct:\n",
    "                confidence = next(conf[1] for conf in emotion_confidences if conf[0] == predicted_emotion)\n",
    "                results.append({\n",
    "                    'file': filename,\n",
    "                    'true_label': true_label,\n",
    "                    'predicted_emotion': predicted_emotion,\n",
    "                    'confidence': confidence\n",
    "                })\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_path}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Convert results to a DataFrame and export to Excel\n",
    "    df_results = pd.DataFrame(results)\n",
    "    with pd.ExcelWriter(output_excel, engine='xlsxwriter') as writer:\n",
    "        df_results.to_excel(writer, sheet_name='Correct Classifications', index=False)\n",
    "    \n",
    "    print(f\"Results saved to {output_excel} and {results_txt}\")\n",
    "\n",
    "# Cell 7 - Run the classifier with directory and export results\n",
    "# Set the paths\n",
    "model_path = '../trainmodel/Original-with-synthetic.keras'\n",
    "scaler_path = '../trainmodel/Original-with-synthetic.save'\n",
    "input_directory = '../test/destination_undersampling/'\n",
    "output_excel = './classification_results.xlsx'\n",
    "results_txt = './classification_results.txt'\n",
    "\n",
    "try:\n",
    "    # Classify files and export correct classifications to Excel and txt\n",
    "    classify_directory_with_labels(model_path, scaler_path, input_directory, output_excel, results_txt)\n",
    "except Exception as e:\n",
    "    print(f\"Error during classification: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
